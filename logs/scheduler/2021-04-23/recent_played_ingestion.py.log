[2021-04-23 13:46:56,832] {scheduler_job.py:182} INFO - Started process (PID=22) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:46:56,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:46:56,840] {logging_mixin.py:104} INFO - [2021-04-23 13:46:56,840] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:47:02,013] {logging_mixin.py:104} INFO - [2021-04-23 13:47:01,988] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:47:02,025] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:47:02,443] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 5.656 seconds
[2021-04-23 13:47:33,683] {scheduler_job.py:182} INFO - Started process (PID=24) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:47:33,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:47:33,711] {logging_mixin.py:104} INFO - [2021-04-23 13:47:33,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:47:37,396] {logging_mixin.py:104} INFO - [2021-04-23 13:47:37,372] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:47:37,455] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:47:37,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.941 seconds
[2021-04-23 13:48:10,717] {scheduler_job.py:182} INFO - Started process (PID=26) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:48:10,785] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:48:10,802] {logging_mixin.py:104} INFO - [2021-04-23 13:48:10,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:48:12,651] {logging_mixin.py:104} INFO - [2021-04-23 13:48:12,641] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:48:12,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:48:12,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.012 seconds
[2021-04-23 13:48:42,854] {scheduler_job.py:182} INFO - Started process (PID=28) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:48:42,857] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:48:42,861] {logging_mixin.py:104} INFO - [2021-04-23 13:48:42,860] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:48:43,889] {logging_mixin.py:104} INFO - [2021-04-23 13:48:43,884] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:48:43,894] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:48:44,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.167 seconds
[2021-04-23 13:49:14,268] {scheduler_job.py:182} INFO - Started process (PID=30) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:49:14,272] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:49:14,274] {logging_mixin.py:104} INFO - [2021-04-23 13:49:14,274] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:49:15,099] {logging_mixin.py:104} INFO - [2021-04-23 13:49:15,095] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:49:15,105] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:49:15,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.899 seconds
[2021-04-23 13:49:45,353] {scheduler_job.py:182} INFO - Started process (PID=32) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:49:45,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:49:45,362] {logging_mixin.py:104} INFO - [2021-04-23 13:49:45,361] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:49:45,945] {logging_mixin.py:104} INFO - [2021-04-23 13:49:45,941] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:49:45,947] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:49:45,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.622 seconds
[2021-04-23 13:50:16,084] {scheduler_job.py:182} INFO - Started process (PID=34) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:50:16,095] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:50:16,100] {logging_mixin.py:104} INFO - [2021-04-23 13:50:16,099] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:50:17,296] {logging_mixin.py:104} INFO - [2021-04-23 13:50:17,290] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:50:17,305] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:50:17,341] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.266 seconds
[2021-04-23 13:50:48,273] {scheduler_job.py:182} INFO - Started process (PID=36) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:50:48,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:50:48,319] {logging_mixin.py:104} INFO - [2021-04-23 13:50:48,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:50:49,852] {logging_mixin.py:104} INFO - [2021-04-23 13:50:49,844] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 11, in <module>
    START_DATETIME = datetime.strptime('{{ ts }}', "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:50:49,856] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:50:49,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.626 seconds
[2021-04-23 13:51:20,607] {scheduler_job.py:182} INFO - Started process (PID=38) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:51:20,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:51:20,613] {logging_mixin.py:104} INFO - [2021-04-23 13:51:20,612] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:51:21,445] {logging_mixin.py:104} INFO - [2021-04-23 13:51:21,437] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:51:21,448] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:51:21,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.872 seconds
[2021-04-23 13:51:51,680] {scheduler_job.py:182} INFO - Started process (PID=40) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:51:51,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:51:51,694] {logging_mixin.py:104} INFO - [2021-04-23 13:51:51,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:51:52,442] {logging_mixin.py:104} INFO - [2021-04-23 13:51:52,439] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:51:52,445] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:51:52,465] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.791 seconds
[2021-04-23 13:52:22,551] {scheduler_job.py:182} INFO - Started process (PID=42) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:52:22,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:52:22,555] {logging_mixin.py:104} INFO - [2021-04-23 13:52:22,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:52:23,639] {logging_mixin.py:104} INFO - [2021-04-23 13:52:23,616] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:52:23,644] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:52:23,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.149 seconds
[2021-04-23 13:52:54,717] {scheduler_job.py:182} INFO - Started process (PID=44) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:52:54,725] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:52:54,727] {logging_mixin.py:104} INFO - [2021-04-23 13:52:54,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:52:55,600] {logging_mixin.py:104} INFO - [2021-04-23 13:52:55,592] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:52:55,605] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:52:55,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.968 seconds
[2021-04-23 13:53:25,798] {scheduler_job.py:182} INFO - Started process (PID=46) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:53:25,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:53:25,806] {logging_mixin.py:104} INFO - [2021-04-23 13:53:25,805] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:53:26,654] {logging_mixin.py:104} INFO - [2021-04-23 13:53:26,650] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:53:26,656] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:53:26,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.899 seconds
[2021-04-23 13:53:56,799] {scheduler_job.py:182} INFO - Started process (PID=48) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:53:56,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:53:56,811] {logging_mixin.py:104} INFO - [2021-04-23 13:53:56,809] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:53:57,872] {logging_mixin.py:104} INFO - [2021-04-23 13:53:57,869] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:53:57,876] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:53:57,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.100 seconds
[2021-04-23 13:54:29,401] {scheduler_job.py:182} INFO - Started process (PID=50) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:54:29,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:54:29,431] {logging_mixin.py:104} INFO - [2021-04-23 13:54:29,431] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:54:31,272] {logging_mixin.py:104} INFO - [2021-04-23 13:54:31,262] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:54:31,283] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:54:31,366] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.983 seconds
[2021-04-23 13:55:01,565] {scheduler_job.py:182} INFO - Started process (PID=52) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:55:01,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:55:01,569] {logging_mixin.py:104} INFO - [2021-04-23 13:55:01,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:55:02,421] {logging_mixin.py:104} INFO - [2021-04-23 13:55:02,417] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S%z'
[2021-04-23 13:55:02,425] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:55:02,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.897 seconds
[2021-04-23 13:55:32,605] {scheduler_job.py:182} INFO - Started process (PID=54) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:55:32,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:55:32,620] {logging_mixin.py:104} INFO - [2021-04-23 13:55:32,619] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:55:33,397] {logging_mixin.py:104} INFO - [2021-04-23 13:55:33,392] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S.%f%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S.%f%z'
[2021-04-23 13:55:33,399] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:55:33,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.832 seconds
[2021-04-23 13:56:03,708] {scheduler_job.py:182} INFO - Started process (PID=56) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:56:03,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:56:03,752] {logging_mixin.py:104} INFO - [2021-04-23 13:56:03,752] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:56:04,712] {logging_mixin.py:104} INFO - [2021-04-23 13:56:04,706] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S.%f%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S.%f%z'
[2021-04-23 13:56:04,717] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:56:04,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.070 seconds
[2021-04-23 13:56:34,897] {scheduler_job.py:182} INFO - Started process (PID=58) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:56:34,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:56:34,901] {logging_mixin.py:104} INFO - [2021-04-23 13:56:34,901] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:56:35,681] {logging_mixin.py:104} INFO - [2021-04-23 13:56:35,676] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S.%f%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S.%f%z'
[2021-04-23 13:56:35,684] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:56:35,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.829 seconds
[2021-04-23 13:57:06,158] {scheduler_job.py:182} INFO - Started process (PID=60) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:57:06,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:57:06,167] {logging_mixin.py:104} INFO - [2021-04-23 13:57:06,167] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:57:06,915] {logging_mixin.py:104} INFO - [2021-04-23 13:57:06,907] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y-%m-%dT%H:%M:%S.%f%z")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts }}' does not match format '%Y-%m-%dT%H:%M:%S.%f%z'
[2021-04-23 13:57:06,919] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:57:06,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-23 13:57:37,476] {scheduler_job.py:182} INFO - Started process (PID=62) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:57:37,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:57:37,482] {logging_mixin.py:104} INFO - [2021-04-23 13:57:37,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:57:38,306] {logging_mixin.py:104} INFO - [2021-04-23 13:57:38,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts_nodash }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 13:57:38,313] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:57:38,339] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.867 seconds
[2021-04-23 13:58:08,429] {scheduler_job.py:182} INFO - Started process (PID=64) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:58:08,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:58:08,438] {logging_mixin.py:104} INFO - [2021-04-23 13:58:08,437] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:58:09,047] {logging_mixin.py:104} INFO - [2021-04-23 13:58:09,044] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts_nodash }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 13:58:09,050] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:58:09,075] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.657 seconds
[2021-04-23 13:58:39,176] {scheduler_job.py:182} INFO - Started process (PID=66) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:58:39,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:58:39,185] {logging_mixin.py:104} INFO - [2021-04-23 13:58:39,184] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:58:40,487] {logging_mixin.py:104} INFO - [2021-04-23 13:58:40,478] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts_nodash }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 13:58:40,494] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:58:40,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.371 seconds
[2021-04-23 13:59:10,614] {scheduler_job.py:182} INFO - Started process (PID=68) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:59:10,617] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:59:10,618] {logging_mixin.py:104} INFO - [2021-04-23 13:59:10,618] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:59:11,301] {logging_mixin.py:104} INFO - [2021-04-23 13:59:11,296] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts_nodash }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 13:59:11,304] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:59:11,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.729 seconds
[2021-04-23 13:59:41,464] {scheduler_job.py:182} INFO - Started process (PID=70) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:59:41,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 13:59:41,470] {logging_mixin.py:104} INFO - [2021-04-23 13:59:41,470] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:59:42,199] {logging_mixin.py:104} INFO - [2021-04-23 13:59:42,196] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ ts_nodash }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 13:59:42,201] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 13:59:42,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.770 seconds
[2021-04-23 14:00:12,346] {scheduler_job.py:182} INFO - Started process (PID=72) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:00:12,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:00:12,356] {logging_mixin.py:104} INFO - [2021-04-23 14:00:12,356] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:00:13,112] {logging_mixin.py:104} INFO - [2021-04-23 14:00:13,109] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ execution_date }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 14:00:13,114] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:00:13,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.798 seconds
[2021-04-23 14:00:43,281] {scheduler_job.py:182} INFO - Started process (PID=74) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:00:43,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:00:43,296] {logging_mixin.py:104} INFO - [2021-04-23 14:00:43,295] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:00:44,150] {logging_mixin.py:104} INFO - [2021-04-23 14:00:44,146] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.strptime(EXECUTION_DATETIME, "%Y%m%dT%H%M%S")  # Start datetime
  File "/usr/local/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/usr/local/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '{{ execution_date }}' does not match format '%Y%m%dT%H%M%S'
[2021-04-23 14:00:44,152] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:00:44,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.919 seconds
[2021-04-23 14:01:14,338] {scheduler_job.py:182} INFO - Started process (PID=76) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:01:14,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:01:14,342] {logging_mixin.py:104} INFO - [2021-04-23 14:01:14,342] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:01:15,078] {logging_mixin.py:104} INFO - [2021-04-23 14:01:15,075] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.fromtimestamp(EXECUTION_DATETIME.timestamp())  # Start datetime
AttributeError: 'str' object has no attribute 'timestamp'
[2021-04-23 14:01:15,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:01:15,106] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.773 seconds
[2021-04-23 14:01:45,275] {scheduler_job.py:182} INFO - Started process (PID=78) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:01:45,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:01:45,288] {logging_mixin.py:104} INFO - [2021-04-23 14:01:45,288] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:01:45,964] {logging_mixin.py:104} INFO - [2021-04-23 14:01:45,962] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.fromtimestamp(EXECUTION_DATETIME.timestamp())  # Start datetime
AttributeError: 'str' object has no attribute 'timestamp'
[2021-04-23 14:01:45,966] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:01:45,983] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-23 14:02:16,443] {scheduler_job.py:182} INFO - Started process (PID=80) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:02:16,446] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:02:16,448] {logging_mixin.py:104} INFO - [2021-04-23 14:02:16,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:02:17,009] {logging_mixin.py:104} INFO - [2021-04-23 14:02:17,005] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.fromtimestamp(EXECUTION_DATETIME.timestamp())  # Start datetime
AttributeError: 'str' object has no attribute 'timestamp'
[2021-04-23 14:02:17,012] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:02:17,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.592 seconds
[2021-04-23 14:02:47,547] {scheduler_job.py:182} INFO - Started process (PID=82) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:02:47,578] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:02:47,583] {logging_mixin.py:104} INFO - [2021-04-23 14:02:47,583] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:02:48,857] {logging_mixin.py:104} INFO - [2021-04-23 14:02:48,851] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.fromtimestamp(EXECUTION_DATETIME.timestamp())  # Start datetime
AttributeError: 'str' object has no attribute 'timestamp'
[2021-04-23 14:02:48,864] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:02:48,923] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.390 seconds
[2021-04-23 14:03:19,207] {scheduler_job.py:182} INFO - Started process (PID=84) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:03:19,210] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:03:19,212] {logging_mixin.py:104} INFO - [2021-04-23 14:03:19,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:03:20,054] {logging_mixin.py:104} INFO - [2021-04-23 14:03:20,049] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.fromtimestamp(EXECUTION_DATETIME.timestamp())  # Start datetime
AttributeError: 'str' object has no attribute 'timestamp'
[2021-04-23 14:03:20,059] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:03:20,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.886 seconds
[2021-04-23 14:03:50,723] {scheduler_job.py:182} INFO - Started process (PID=86) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:03:50,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:03:50,734] {logging_mixin.py:104} INFO - [2021-04-23 14:03:50,734] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:03:53,140] {logging_mixin.py:104} INFO - [2021-04-23 14:03:53,126] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 12, in <module>
    START_DATETIME = datetime.fromtimestamp(EXECUTION_DATETIME.timestamp())  # Start datetime
AttributeError: 'str' object has no attribute 'timestamp'
[2021-04-23 14:03:53,157] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:03:53,198] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.504 seconds
[2021-04-23 14:04:23,863] {scheduler_job.py:182} INFO - Started process (PID=88) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:04:23,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:04:23,871] {logging_mixin.py:104} INFO - [2021-04-23 14:04:23,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:04:25,447] {logging_mixin.py:104} INFO - [2021-04-23 14:04:25,438] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 111, in <module>
    START_DATETIME,
NameError: name 'START_DATETIME' is not defined
[2021-04-23 14:04:25,459] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:04:25,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.655 seconds
[2021-04-23 14:04:55,645] {scheduler_job.py:182} INFO - Started process (PID=90) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:04:55,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:04:55,653] {logging_mixin.py:104} INFO - [2021-04-23 14:04:55,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:04:56,452] {logging_mixin.py:104} INFO - [2021-04-23 14:04:56,449] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 111, in <module>
    START_DATETIME,
NameError: name 'START_DATETIME' is not defined
[2021-04-23 14:04:56,454] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:04:56,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.822 seconds
[2021-04-23 14:05:26,612] {scheduler_job.py:182} INFO - Started process (PID=92) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:05:26,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:05:26,621] {logging_mixin.py:104} INFO - [2021-04-23 14:05:26,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:05:27,635] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:05:27,689] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:05:27,712] {logging_mixin.py:104} INFO - [2021-04-23 14:05:27,710] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:05:27,735] {logging_mixin.py:104} INFO - [2021-04-23 14:05:27,733] {dag.py:1837} INFO - Creating ORM DAG for recent_played_ingestion
[2021-04-23 14:05:27,755] {logging_mixin.py:104} INFO - [2021-04-23 14:05:27,755] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T12:00:00+00:00
[2021-04-23 14:05:27,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.203 seconds
[2021-04-23 14:05:58,033] {scheduler_job.py:182} INFO - Started process (PID=99) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:05:58,045] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:05:58,051] {logging_mixin.py:104} INFO - [2021-04-23 14:05:58,051] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:05:59,492] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:05:59,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:05:59,573] {logging_mixin.py:104} INFO - [2021-04-23 14:05:59,571] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:05:59,602] {logging_mixin.py:104} INFO - [2021-04-23 14:05:59,601] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:05:59,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.647 seconds
[2021-04-23 14:06:30,183] {scheduler_job.py:182} INFO - Started process (PID=101) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:06:30,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:06:30,192] {logging_mixin.py:104} INFO - [2021-04-23 14:06:30,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:06:44,492] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:06:44,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:06:45,208] {logging_mixin.py:104} INFO - [2021-04-23 14:06:45,131] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:06:45,635] {logging_mixin.py:104} INFO - [2021-04-23 14:06:45,635] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:06:45,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 15.532 seconds
[2021-04-23 14:07:17,453] {scheduler_job.py:182} INFO - Started process (PID=103) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:07:17,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:07:17,579] {logging_mixin.py:104} INFO - [2021-04-23 14:07:17,574] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:07:24,059] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:07:24,188] {logging_mixin.py:104} INFO - [2021-04-23 14:07:24,152] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 139, in <module>
    run_recent_played_classification_pypark
NameError: name 'run_recent_played_classification_pypark' is not defined
[2021-04-23 14:07:24,197] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:07:24,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 6.955 seconds
[2021-04-23 14:07:54,450] {scheduler_job.py:182} INFO - Started process (PID=105) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:07:54,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:07:54,486] {logging_mixin.py:104} INFO - [2021-04-23 14:07:54,486] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:07:56,031] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:07:56,058] {logging_mixin.py:104} INFO - [2021-04-23 14:07:56,053] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 139, in <module>
    run_recent_played_classification_pypark
NameError: name 'run_recent_played_classification_pypark' is not defined
[2021-04-23 14:07:56,068] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:07:56,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.644 seconds
[2021-04-23 14:08:26,938] {scheduler_job.py:182} INFO - Started process (PID=107) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:08:26,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:08:26,977] {logging_mixin.py:104} INFO - [2021-04-23 14:08:26,976] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:08:28,444] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:08:28,465] {logging_mixin.py:104} INFO - [2021-04-23 14:08:28,462] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 139, in <module>
    run_recent_played_classification_pypark
NameError: name 'run_recent_played_classification_pypark' is not defined
[2021-04-23 14:08:28,468] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:08:28,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.574 seconds
[2021-04-23 14:08:59,490] {scheduler_job.py:182} INFO - Started process (PID=109) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:08:59,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:08:59,556] {logging_mixin.py:104} INFO - [2021-04-23 14:08:59,552] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:09:10,464] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:09:10,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:09:10,543] {logging_mixin.py:104} INFO - [2021-04-23 14:09:10,541] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:09:10,576] {logging_mixin.py:104} INFO - [2021-04-23 14:09:10,576] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T12:00:00+00:00
[2021-04-23 14:09:10,614] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 11.255 seconds
[2021-04-23 14:09:40,811] {scheduler_job.py:182} INFO - Started process (PID=111) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:09:40,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:09:40,820] {logging_mixin.py:104} INFO - [2021-04-23 14:09:40,820] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:09:41,767] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:09:41,824] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:09:41,842] {logging_mixin.py:104} INFO - [2021-04-23 14:09:41,841] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:09:41,877] {logging_mixin.py:104} INFO - [2021-04-23 14:09:41,877] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T12:00:00+00:00
[2021-04-23 14:09:41,892] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.097 seconds
[2021-04-23 14:10:12,012] {scheduler_job.py:182} INFO - Started process (PID=113) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:10:12,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:10:12,017] {logging_mixin.py:104} INFO - [2021-04-23 14:10:12,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:10:13,129] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:10:13,160] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:10:13,175] {logging_mixin.py:104} INFO - [2021-04-23 14:10:13,174] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:10:13,201] {logging_mixin.py:104} INFO - [2021-04-23 14:10:13,200] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T12:00:00+00:00
[2021-04-23 14:10:13,228] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.221 seconds
[2021-04-23 14:10:43,304] {scheduler_job.py:182} INFO - Started process (PID=115) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:10:43,317] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:10:43,325] {logging_mixin.py:104} INFO - [2021-04-23 14:10:43,325] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:10:44,148] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:10:44,169] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:10:44,182] {logging_mixin.py:104} INFO - [2021-04-23 14:10:44,181] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:10:44,203] {logging_mixin.py:104} INFO - [2021-04-23 14:10:44,203] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:10:44,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.918 seconds
[2021-04-23 14:11:14,575] {scheduler_job.py:182} INFO - Started process (PID=117) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:11:14,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:11:14,585] {logging_mixin.py:104} INFO - [2021-04-23 14:11:14,585] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:11:15,636] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:11:15,657] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:11:15,678] {logging_mixin.py:104} INFO - [2021-04-23 14:11:15,676] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:11:15,696] {logging_mixin.py:104} INFO - [2021-04-23 14:11:15,696] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:11:15,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.163 seconds
[2021-04-23 14:11:45,856] {scheduler_job.py:182} INFO - Started process (PID=119) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:11:45,860] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:11:45,863] {logging_mixin.py:104} INFO - [2021-04-23 14:11:45,862] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:11:46,984] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:11:47,028] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:11:47,049] {logging_mixin.py:104} INFO - [2021-04-23 14:11:47,047] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:11:47,089] {logging_mixin.py:104} INFO - [2021-04-23 14:11:47,088] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T12:00:00+00:00
[2021-04-23 14:11:47,139] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.291 seconds
[2021-04-23 14:12:17,357] {scheduler_job.py:182} INFO - Started process (PID=121) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:12:17,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:12:17,364] {logging_mixin.py:104} INFO - [2021-04-23 14:12:17,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:12:18,861] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:12:18,938] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:12:19,028] {logging_mixin.py:104} INFO - [2021-04-23 14:12:19,025] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:12:19,142] {logging_mixin.py:104} INFO - [2021-04-23 14:12:19,141] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:12:19,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.828 seconds
[2021-04-23 14:12:49,497] {scheduler_job.py:182} INFO - Started process (PID=123) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:12:49,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:12:49,508] {logging_mixin.py:104} INFO - [2021-04-23 14:12:49,508] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:12:50,409] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:12:50,432] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:12:50,447] {logging_mixin.py:104} INFO - [2021-04-23 14:12:50,446] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:12:50,468] {logging_mixin.py:104} INFO - [2021-04-23 14:12:50,467] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:12:50,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.985 seconds
[2021-04-23 14:13:20,628] {scheduler_job.py:182} INFO - Started process (PID=125) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:13:20,632] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:13:20,635] {logging_mixin.py:104} INFO - [2021-04-23 14:13:20,635] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:13:22,148] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:13:22,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:13:22,233] {logging_mixin.py:104} INFO - [2021-04-23 14:13:22,231] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:13:22,266] {logging_mixin.py:104} INFO - [2021-04-23 14:13:22,265] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:13:22,285] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.662 seconds
[2021-04-23 14:13:52,460] {scheduler_job.py:182} INFO - Started process (PID=127) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:13:52,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:13:52,466] {logging_mixin.py:104} INFO - [2021-04-23 14:13:52,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:13:53,885] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:13:53,933] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:13:53,970] {logging_mixin.py:104} INFO - [2021-04-23 14:13:53,965] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:13:53,999] {logging_mixin.py:104} INFO - [2021-04-23 14:13:53,999] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:13:54,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.599 seconds
[2021-04-23 14:14:24,217] {scheduler_job.py:182} INFO - Started process (PID=129) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:14:24,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:14:24,223] {logging_mixin.py:104} INFO - [2021-04-23 14:14:24,223] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:14:25,573] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:14:25,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:14:25,638] {logging_mixin.py:104} INFO - [2021-04-23 14:14:25,636] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:14:25,674] {logging_mixin.py:104} INFO - [2021-04-23 14:14:25,674] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:14:25,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.478 seconds
[2021-04-23 14:14:55,873] {scheduler_job.py:182} INFO - Started process (PID=131) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:14:55,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:14:55,880] {logging_mixin.py:104} INFO - [2021-04-23 14:14:55,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:14:57,081] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:14:57,135] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:14:57,170] {logging_mixin.py:104} INFO - [2021-04-23 14:14:57,168] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:14:57,213] {logging_mixin.py:104} INFO - [2021-04-23 14:14:57,213] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:14:57,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.365 seconds
[2021-04-23 14:15:27,367] {scheduler_job.py:182} INFO - Started process (PID=133) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:15:27,372] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:15:27,375] {logging_mixin.py:104} INFO - [2021-04-23 14:15:27,374] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:15:28,616] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:15:28,657] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:15:28,678] {logging_mixin.py:104} INFO - [2021-04-23 14:15:28,676] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:15:28,717] {logging_mixin.py:104} INFO - [2021-04-23 14:15:28,717] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:15:28,728] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.376 seconds
[2021-04-23 14:15:58,830] {scheduler_job.py:182} INFO - Started process (PID=135) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:15:58,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:15:58,834] {logging_mixin.py:104} INFO - [2021-04-23 14:15:58,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:15:59,580] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:15:59,621] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:15:59,637] {logging_mixin.py:104} INFO - [2021-04-23 14:15:59,636] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:15:59,661] {logging_mixin.py:104} INFO - [2021-04-23 14:15:59,660] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T13:00:00+00:00
[2021-04-23 14:15:59,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.851 seconds
[2021-04-23 14:16:29,788] {scheduler_job.py:182} INFO - Started process (PID=137) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:16:29,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:16:29,794] {logging_mixin.py:104} INFO - [2021-04-23 14:16:29,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:16:30,531] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:16:30,562] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:16:30,594] {logging_mixin.py:104} INFO - [2021-04-23 14:16:30,588] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:16:30,627] {logging_mixin.py:104} INFO - [2021-04-23 14:16:30,627] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:16:30,641] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.857 seconds
[2021-04-23 14:17:01,259] {scheduler_job.py:182} INFO - Started process (PID=139) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:17:01,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:17:01,267] {logging_mixin.py:104} INFO - [2021-04-23 14:17:01,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:17:02,131] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:17:02,177] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:17:02,193] {logging_mixin.py:104} INFO - [2021-04-23 14:17:02,191] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:17:02,220] {logging_mixin.py:104} INFO - [2021-04-23 14:17:02,219] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:17:02,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.977 seconds
[2021-04-23 14:17:32,465] {scheduler_job.py:182} INFO - Started process (PID=141) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:17:32,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:17:32,471] {logging_mixin.py:104} INFO - [2021-04-23 14:17:32,471] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:17:33,289] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:17:33,326] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:17:33,347] {logging_mixin.py:104} INFO - [2021-04-23 14:17:33,345] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:17:33,373] {logging_mixin.py:104} INFO - [2021-04-23 14:17:33,373] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:17:33,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.932 seconds
[2021-04-23 14:18:03,516] {scheduler_job.py:182} INFO - Started process (PID=143) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:18:03,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:18:03,523] {logging_mixin.py:104} INFO - [2021-04-23 14:18:03,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:18:04,454] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:18:04,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:18:04,513] {logging_mixin.py:104} INFO - [2021-04-23 14:18:04,511] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:18:04,532] {logging_mixin.py:104} INFO - [2021-04-23 14:18:04,532] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:18:04,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.031 seconds
[2021-04-23 14:18:34,704] {scheduler_job.py:182} INFO - Started process (PID=145) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:18:34,710] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:18:34,714] {logging_mixin.py:104} INFO - [2021-04-23 14:18:34,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:18:35,728] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:18:35,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:18:35,792] {logging_mixin.py:104} INFO - [2021-04-23 14:18:35,790] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:18:35,822] {logging_mixin.py:104} INFO - [2021-04-23 14:18:35,822] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:18:35,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.137 seconds
[2021-04-23 14:19:05,988] {scheduler_job.py:182} INFO - Started process (PID=147) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:19:05,992] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:19:05,995] {logging_mixin.py:104} INFO - [2021-04-23 14:19:05,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:19:06,032] {logging_mixin.py:104} INFO - [2021-04-23 14:19:06,026] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 137
    triger_rule=)
                ^
SyntaxError: invalid syntax
[2021-04-23 14:19:06,040] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:19:06,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.104 seconds
[2021-04-23 14:19:36,327] {scheduler_job.py:182} INFO - Started process (PID=149) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:19:36,334] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:19:36,337] {logging_mixin.py:104} INFO - [2021-04-23 14:19:36,337] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:19:36,372] {logging_mixin.py:104} INFO - [2021-04-23 14:19:36,370] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 137
    trigger_rule=.)
                 ^
SyntaxError: invalid syntax
[2021-04-23 14:19:36,377] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:19:36,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.101 seconds
[2021-04-23 14:20:06,560] {scheduler_job.py:182} INFO - Started process (PID=151) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:20:06,565] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:20:06,567] {logging_mixin.py:104} INFO - [2021-04-23 14:20:06,567] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:20:06,584] {logging_mixin.py:104} INFO - [2021-04-23 14:20:06,583] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 137
    trigger_rule=.)
                 ^
SyntaxError: invalid syntax
[2021-04-23 14:20:06,587] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:20:06,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.067 seconds
[2021-04-23 14:20:36,749] {scheduler_job.py:182} INFO - Started process (PID=153) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:20:36,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:20:36,755] {logging_mixin.py:104} INFO - [2021-04-23 14:20:36,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:20:37,816] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:20:37,855] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:20:37,885] {logging_mixin.py:104} INFO - [2021-04-23 14:20:37,884] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:20:37,918] {logging_mixin.py:104} INFO - [2021-04-23 14:20:37,918] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:20:37,960] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.218 seconds
[2021-04-23 14:21:08,036] {scheduler_job.py:182} INFO - Started process (PID=155) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:21:08,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:21:08,042] {logging_mixin.py:104} INFO - [2021-04-23 14:21:08,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:21:08,830] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:21:08,862] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:21:08,877] {logging_mixin.py:104} INFO - [2021-04-23 14:21:08,876] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:21:08,904] {logging_mixin.py:104} INFO - [2021-04-23 14:21:08,904] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:21:08,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.886 seconds
[2021-04-23 14:21:39,061] {scheduler_job.py:182} INFO - Started process (PID=157) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:21:39,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:21:39,075] {logging_mixin.py:104} INFO - [2021-04-23 14:21:39,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:21:39,899] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:21:39,920] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:21:39,932] {logging_mixin.py:104} INFO - [2021-04-23 14:21:39,931] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:21:39,950] {logging_mixin.py:104} INFO - [2021-04-23 14:21:39,950] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:21:39,959] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.905 seconds
[2021-04-23 14:22:10,944] {scheduler_job.py:182} INFO - Started process (PID=159) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:22:10,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:22:10,954] {logging_mixin.py:104} INFO - [2021-04-23 14:22:10,953] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:22:11,950] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:22:11,977] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:22:11,989] {logging_mixin.py:104} INFO - [2021-04-23 14:22:11,987] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:22:12,009] {logging_mixin.py:104} INFO - [2021-04-23 14:22:12,009] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:22:12,021] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.083 seconds
[2021-04-23 14:22:42,370] {scheduler_job.py:182} INFO - Started process (PID=161) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:22:42,374] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:22:42,378] {logging_mixin.py:104} INFO - [2021-04-23 14:22:42,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:22:43,063] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:22:43,083] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:22:43,103] {logging_mixin.py:104} INFO - [2021-04-23 14:22:43,102] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:22:43,126] {logging_mixin.py:104} INFO - [2021-04-23 14:22:43,125] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:22:43,139] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.776 seconds
[2021-04-23 14:23:13,276] {scheduler_job.py:182} INFO - Started process (PID=163) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:23:13,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:23:13,286] {logging_mixin.py:104} INFO - [2021-04-23 14:23:13,285] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:23:14,325] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:23:14,390] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:23:14,415] {logging_mixin.py:104} INFO - [2021-04-23 14:23:14,414] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:23:14,463] {logging_mixin.py:104} INFO - [2021-04-23 14:23:14,463] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:23:14,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.207 seconds
[2021-04-23 14:23:44,633] {scheduler_job.py:182} INFO - Started process (PID=165) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:23:44,636] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:23:44,638] {logging_mixin.py:104} INFO - [2021-04-23 14:23:44,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:23:45,347] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:23:45,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:23:45,383] {logging_mixin.py:104} INFO - [2021-04-23 14:23:45,382] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:23:45,404] {logging_mixin.py:104} INFO - [2021-04-23 14:23:45,404] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:23:45,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.786 seconds
[2021-04-23 14:24:15,837] {scheduler_job.py:182} INFO - Started process (PID=167) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:24:15,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:24:15,842] {logging_mixin.py:104} INFO - [2021-04-23 14:24:15,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:24:16,540] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:24:16,563] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:24:16,575] {logging_mixin.py:104} INFO - [2021-04-23 14:24:16,574] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:24:16,593] {logging_mixin.py:104} INFO - [2021-04-23 14:24:16,592] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:24:16,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.770 seconds
[2021-04-23 14:24:47,440] {scheduler_job.py:182} INFO - Started process (PID=169) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:24:47,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:24:47,446] {logging_mixin.py:104} INFO - [2021-04-23 14:24:47,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:24:48,155] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:24:48,175] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:24:48,187] {logging_mixin.py:104} INFO - [2021-04-23 14:24:48,186] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:24:48,211] {logging_mixin.py:104} INFO - [2021-04-23 14:24:48,211] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:24:48,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.783 seconds
[2021-04-23 14:25:18,338] {scheduler_job.py:182} INFO - Started process (PID=171) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:25:18,342] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:25:18,344] {logging_mixin.py:104} INFO - [2021-04-23 14:25:18,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:25:19,137] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:25:19,167] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:25:19,184] {logging_mixin.py:104} INFO - [2021-04-23 14:25:19,183] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:25:19,214] {logging_mixin.py:104} INFO - [2021-04-23 14:25:19,214] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:25:19,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.901 seconds
[2021-04-23 14:25:49,389] {scheduler_job.py:182} INFO - Started process (PID=173) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:25:49,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:25:49,396] {logging_mixin.py:104} INFO - [2021-04-23 14:25:49,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:25:50,714] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:25:50,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:25:50,798] {logging_mixin.py:104} INFO - [2021-04-23 14:25:50,797] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:25:50,830] {logging_mixin.py:104} INFO - [2021-04-23 14:25:50,830] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:25:50,842] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.459 seconds
[2021-04-23 14:26:20,912] {scheduler_job.py:182} INFO - Started process (PID=175) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:26:20,915] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:26:20,917] {logging_mixin.py:104} INFO - [2021-04-23 14:26:20,917] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:26:21,827] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:26:21,862] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:26:21,878] {logging_mixin.py:104} INFO - [2021-04-23 14:26:21,876] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:26:21,902] {logging_mixin.py:104} INFO - [2021-04-23 14:26:21,902] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:26:21,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.018 seconds
[2021-04-23 14:26:52,086] {scheduler_job.py:182} INFO - Started process (PID=177) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:26:52,089] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:26:52,092] {logging_mixin.py:104} INFO - [2021-04-23 14:26:52,092] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:26:53,270] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:26:53,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:26:53,352] {logging_mixin.py:104} INFO - [2021-04-23 14:26:53,350] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:26:53,387] {logging_mixin.py:104} INFO - [2021-04-23 14:26:53,387] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:26:53,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.366 seconds
[2021-04-23 14:27:23,592] {scheduler_job.py:182} INFO - Started process (PID=179) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:27:23,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:27:23,597] {logging_mixin.py:104} INFO - [2021-04-23 14:27:23,596] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:27:24,354] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:27:24,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:27:24,395] {logging_mixin.py:104} INFO - [2021-04-23 14:27:24,394] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:27:24,413] {logging_mixin.py:104} INFO - [2021-04-23 14:27:24,413] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:27:24,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.837 seconds
[2021-04-23 14:27:54,484] {scheduler_job.py:182} INFO - Started process (PID=181) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:27:54,486] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:27:54,489] {logging_mixin.py:104} INFO - [2021-04-23 14:27:54,489] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:27:55,210] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:27:55,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:27:55,241] {logging_mixin.py:104} INFO - [2021-04-23 14:27:55,240] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:27:55,259] {logging_mixin.py:104} INFO - [2021-04-23 14:27:55,258] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:27:55,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.789 seconds
[2021-04-23 14:28:25,646] {scheduler_job.py:182} INFO - Started process (PID=183) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:28:25,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:28:25,654] {logging_mixin.py:104} INFO - [2021-04-23 14:28:25,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:28:26,499] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:28:26,569] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:28:26,594] {logging_mixin.py:104} INFO - [2021-04-23 14:28:26,590] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:28:26,621] {logging_mixin.py:104} INFO - [2021-04-23 14:28:26,621] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:28:26,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.007 seconds
[2021-04-23 14:28:56,884] {scheduler_job.py:182} INFO - Started process (PID=185) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:28:56,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:28:56,907] {logging_mixin.py:104} INFO - [2021-04-23 14:28:56,901] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:29:01,276] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:29:01,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:29:01,760] {logging_mixin.py:104} INFO - [2021-04-23 14:29:01,752] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:29:01,819] {logging_mixin.py:104} INFO - [2021-04-23 14:29:01,819] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:29:01,927] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 5.050 seconds
[2021-04-23 14:29:32,987] {scheduler_job.py:182} INFO - Started process (PID=187) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:29:32,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:29:32,994] {logging_mixin.py:104} INFO - [2021-04-23 14:29:32,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:29:33,739] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:29:33,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:29:33,787] {logging_mixin.py:104} INFO - [2021-04-23 14:29:33,786] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:29:33,809] {logging_mixin.py:104} INFO - [2021-04-23 14:29:33,809] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:29:33,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.839 seconds
[2021-04-23 14:30:03,917] {scheduler_job.py:182} INFO - Started process (PID=189) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:30:03,920] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:30:03,924] {logging_mixin.py:104} INFO - [2021-04-23 14:30:03,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:30:04,856] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:30:04,919] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:30:04,942] {logging_mixin.py:104} INFO - [2021-04-23 14:30:04,940] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:30:05,004] {logging_mixin.py:104} INFO - [2021-04-23 14:30:05,002] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:30:05,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.125 seconds
[2021-04-23 14:30:35,197] {scheduler_job.py:182} INFO - Started process (PID=191) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:30:35,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:30:35,205] {logging_mixin.py:104} INFO - [2021-04-23 14:30:35,205] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:30:36,022] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:30:36,047] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:30:36,076] {logging_mixin.py:104} INFO - [2021-04-23 14:30:36,074] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:30:36,109] {logging_mixin.py:104} INFO - [2021-04-23 14:30:36,108] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:30:36,140] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.949 seconds
[2021-04-23 14:31:06,321] {scheduler_job.py:182} INFO - Started process (PID=193) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:31:06,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:31:06,342] {logging_mixin.py:104} INFO - [2021-04-23 14:31:06,341] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:31:07,676] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:31:07,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:31:07,760] {logging_mixin.py:104} INFO - [2021-04-23 14:31:07,756] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:31:07,798] {logging_mixin.py:104} INFO - [2021-04-23 14:31:07,798] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:31:07,816] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.505 seconds
[2021-04-23 14:31:37,937] {scheduler_job.py:182} INFO - Started process (PID=195) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:31:37,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:31:37,943] {logging_mixin.py:104} INFO - [2021-04-23 14:31:37,943] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:31:39,257] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:31:39,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:31:39,319] {logging_mixin.py:104} INFO - [2021-04-23 14:31:39,317] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:31:39,345] {logging_mixin.py:104} INFO - [2021-04-23 14:31:39,344] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:31:39,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.426 seconds
[2021-04-23 14:32:09,425] {scheduler_job.py:182} INFO - Started process (PID=197) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:32:09,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:32:09,435] {logging_mixin.py:104} INFO - [2021-04-23 14:32:09,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:32:10,254] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:32:10,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:32:10,297] {logging_mixin.py:104} INFO - [2021-04-23 14:32:10,296] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:32:10,316] {logging_mixin.py:104} INFO - [2021-04-23 14:32:10,316] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:32:10,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.904 seconds
[2021-04-23 14:32:40,439] {scheduler_job.py:182} INFO - Started process (PID=199) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:32:40,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:32:40,450] {logging_mixin.py:104} INFO - [2021-04-23 14:32:40,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:32:41,379] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:32:41,406] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:32:41,421] {logging_mixin.py:104} INFO - [2021-04-23 14:32:41,420] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:32:41,443] {logging_mixin.py:104} INFO - [2021-04-23 14:32:41,443] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:32:41,456] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.023 seconds
[2021-04-23 14:33:11,641] {scheduler_job.py:182} INFO - Started process (PID=201) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:33:11,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:33:11,653] {logging_mixin.py:104} INFO - [2021-04-23 14:33:11,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:33:12,508] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:33:12,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:33:12,543] {logging_mixin.py:104} INFO - [2021-04-23 14:33:12,541] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:33:12,563] {logging_mixin.py:104} INFO - [2021-04-23 14:33:12,563] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:33:12,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.940 seconds
[2021-04-23 14:33:42,711] {scheduler_job.py:182} INFO - Started process (PID=203) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:33:42,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:33:42,717] {logging_mixin.py:104} INFO - [2021-04-23 14:33:42,717] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:33:43,723] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:33:43,756] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:33:43,775] {logging_mixin.py:104} INFO - [2021-04-23 14:33:43,773] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:33:43,814] {logging_mixin.py:104} INFO - [2021-04-23 14:33:43,814] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:33:43,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.120 seconds
[2021-04-23 14:34:13,927] {scheduler_job.py:182} INFO - Started process (PID=205) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:34:13,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:34:13,931] {logging_mixin.py:104} INFO - [2021-04-23 14:34:13,931] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:34:14,831] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:34:14,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:34:14,873] {logging_mixin.py:104} INFO - [2021-04-23 14:34:14,872] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:34:14,916] {logging_mixin.py:104} INFO - [2021-04-23 14:34:14,916] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:34:14,932] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.009 seconds
[2021-04-23 14:34:45,022] {scheduler_job.py:182} INFO - Started process (PID=207) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:34:45,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:34:45,027] {logging_mixin.py:104} INFO - [2021-04-23 14:34:45,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:34:46,158] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:34:46,208] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:34:46,230] {logging_mixin.py:104} INFO - [2021-04-23 14:34:46,228] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:34:46,251] {logging_mixin.py:104} INFO - [2021-04-23 14:34:46,251] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:34:46,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.248 seconds
[2021-04-23 14:35:16,345] {scheduler_job.py:182} INFO - Started process (PID=209) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:35:16,349] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:35:16,352] {logging_mixin.py:104} INFO - [2021-04-23 14:35:16,351] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:35:17,988] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:35:18,041] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:35:18,072] {logging_mixin.py:104} INFO - [2021-04-23 14:35:18,070] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:35:18,131] {logging_mixin.py:104} INFO - [2021-04-23 14:35:18,130] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:35:18,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.820 seconds
[2021-04-23 14:35:48,260] {scheduler_job.py:182} INFO - Started process (PID=211) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:35:48,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:35:48,267] {logging_mixin.py:104} INFO - [2021-04-23 14:35:48,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:35:49,193] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:35:49,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:35:49,254] {logging_mixin.py:104} INFO - [2021-04-23 14:35:49,252] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:35:49,277] {logging_mixin.py:104} INFO - [2021-04-23 14:35:49,277] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:35:49,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.039 seconds
[2021-04-23 14:36:19,395] {scheduler_job.py:182} INFO - Started process (PID=213) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:36:19,399] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:36:19,403] {logging_mixin.py:104} INFO - [2021-04-23 14:36:19,402] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:36:20,382] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:36:20,413] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:36:20,431] {logging_mixin.py:104} INFO - [2021-04-23 14:36:20,429] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:36:20,453] {logging_mixin.py:104} INFO - [2021-04-23 14:36:20,453] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:36:20,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.078 seconds
[2021-04-23 14:36:50,576] {scheduler_job.py:182} INFO - Started process (PID=215) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:36:50,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:36:50,592] {logging_mixin.py:104} INFO - [2021-04-23 14:36:50,592] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:36:51,440] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:36:51,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:36:51,474] {logging_mixin.py:104} INFO - [2021-04-23 14:36:51,474] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:36:51,494] {logging_mixin.py:104} INFO - [2021-04-23 14:36:51,493] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:36:51,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.932 seconds
[2021-04-23 14:37:22,065] {scheduler_job.py:182} INFO - Started process (PID=217) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:37:22,067] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:37:22,069] {logging_mixin.py:104} INFO - [2021-04-23 14:37:22,069] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:37:22,960] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:37:22,993] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:37:23,021] {logging_mixin.py:104} INFO - [2021-04-23 14:37:23,019] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:37:23,044] {logging_mixin.py:104} INFO - [2021-04-23 14:37:23,043] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:37:23,058] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.034 seconds
[2021-04-23 14:37:53,189] {scheduler_job.py:182} INFO - Started process (PID=219) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:37:53,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:37:53,199] {logging_mixin.py:104} INFO - [2021-04-23 14:37:53,198] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:37:55,656] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:37:55,712] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:37:55,742] {logging_mixin.py:104} INFO - [2021-04-23 14:37:55,741] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:37:55,778] {logging_mixin.py:104} INFO - [2021-04-23 14:37:55,778] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:37:55,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.626 seconds
[2021-04-23 14:38:26,423] {scheduler_job.py:182} INFO - Started process (PID=221) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:38:26,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:38:26,439] {logging_mixin.py:104} INFO - [2021-04-23 14:38:26,439] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:38:27,435] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:38:27,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:38:27,472] {logging_mixin.py:104} INFO - [2021-04-23 14:38:27,471] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:38:27,495] {logging_mixin.py:104} INFO - [2021-04-23 14:38:27,495] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:38:27,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.097 seconds
[2021-04-23 14:38:57,694] {scheduler_job.py:182} INFO - Started process (PID=223) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:38:57,702] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:38:57,711] {logging_mixin.py:104} INFO - [2021-04-23 14:38:57,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:38:58,934] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:38:58,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:38:58,993] {logging_mixin.py:104} INFO - [2021-04-23 14:38:58,992] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:38:59,020] {logging_mixin.py:104} INFO - [2021-04-23 14:38:59,020] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:38:59,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.357 seconds
[2021-04-23 14:39:29,917] {scheduler_job.py:182} INFO - Started process (PID=225) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:39:29,923] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:39:29,926] {logging_mixin.py:104} INFO - [2021-04-23 14:39:29,926] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:39:30,836] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:39:30,854] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:39:30,866] {logging_mixin.py:104} INFO - [2021-04-23 14:39:30,865] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:39:30,885] {logging_mixin.py:104} INFO - [2021-04-23 14:39:30,885] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:39:30,899] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.985 seconds
[2021-04-23 14:40:01,039] {scheduler_job.py:182} INFO - Started process (PID=227) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:40:01,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:40:01,047] {logging_mixin.py:104} INFO - [2021-04-23 14:40:01,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:40:02,371] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:40:02,407] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:40:02,428] {logging_mixin.py:104} INFO - [2021-04-23 14:40:02,426] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:40:02,457] {logging_mixin.py:104} INFO - [2021-04-23 14:40:02,457] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:40:02,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.438 seconds
[2021-04-23 14:40:33,101] {scheduler_job.py:182} INFO - Started process (PID=229) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:40:33,104] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:40:33,105] {logging_mixin.py:104} INFO - [2021-04-23 14:40:33,105] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:40:34,102] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:40:34,137] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:40:34,166] {logging_mixin.py:104} INFO - [2021-04-23 14:40:34,163] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:40:34,231] {logging_mixin.py:104} INFO - [2021-04-23 14:40:34,230] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:40:34,244] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.146 seconds
[2021-04-23 14:41:04,382] {scheduler_job.py:182} INFO - Started process (PID=231) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:41:04,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:41:04,393] {logging_mixin.py:104} INFO - [2021-04-23 14:41:04,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:41:05,341] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:41:05,372] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:41:05,391] {logging_mixin.py:104} INFO - [2021-04-23 14:41:05,390] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:41:05,415] {logging_mixin.py:104} INFO - [2021-04-23 14:41:05,415] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:41:05,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.050 seconds
[2021-04-23 14:41:35,572] {scheduler_job.py:182} INFO - Started process (PID=233) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:41:35,576] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:41:35,581] {logging_mixin.py:104} INFO - [2021-04-23 14:41:35,581] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:41:36,731] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:41:36,787] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:41:36,811] {logging_mixin.py:104} INFO - [2021-04-23 14:41:36,808] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:41:36,853] {logging_mixin.py:104} INFO - [2021-04-23 14:41:36,853] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:41:36,868] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.303 seconds
[2021-04-23 14:42:07,072] {scheduler_job.py:182} INFO - Started process (PID=235) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:42:07,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:42:07,079] {logging_mixin.py:104} INFO - [2021-04-23 14:42:07,079] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:42:07,920] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:42:07,953] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:42:07,967] {logging_mixin.py:104} INFO - [2021-04-23 14:42:07,966] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:42:07,992] {logging_mixin.py:104} INFO - [2021-04-23 14:42:07,992] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:42:08,002] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.935 seconds
[2021-04-23 14:42:38,102] {scheduler_job.py:182} INFO - Started process (PID=237) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:42:38,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:42:38,107] {logging_mixin.py:104} INFO - [2021-04-23 14:42:38,107] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:42:38,931] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:42:38,957] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:42:38,978] {logging_mixin.py:104} INFO - [2021-04-23 14:42:38,977] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:42:39,001] {logging_mixin.py:104} INFO - [2021-04-23 14:42:39,000] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:42:39,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.914 seconds
[2021-04-23 14:43:09,110] {scheduler_job.py:182} INFO - Started process (PID=239) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:43:09,113] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:43:09,115] {logging_mixin.py:104} INFO - [2021-04-23 14:43:09,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:43:10,012] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:43:10,049] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:43:10,065] {logging_mixin.py:104} INFO - [2021-04-23 14:43:10,063] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:43:10,088] {logging_mixin.py:104} INFO - [2021-04-23 14:43:10,088] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:43:10,104] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.998 seconds
[2021-04-23 14:43:40,203] {scheduler_job.py:182} INFO - Started process (PID=241) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:43:40,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:43:40,208] {logging_mixin.py:104} INFO - [2021-04-23 14:43:40,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:43:41,110] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:43:41,171] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:43:41,209] {logging_mixin.py:104} INFO - [2021-04-23 14:43:41,208] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:43:41,245] {logging_mixin.py:104} INFO - [2021-04-23 14:43:41,245] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:43:41,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.070 seconds
[2021-04-23 14:44:11,401] {scheduler_job.py:182} INFO - Started process (PID=243) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:44:11,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:44:11,406] {logging_mixin.py:104} INFO - [2021-04-23 14:44:11,406] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:44:12,347] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:44:12,381] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:44:12,398] {logging_mixin.py:104} INFO - [2021-04-23 14:44:12,397] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:44:12,424] {logging_mixin.py:104} INFO - [2021-04-23 14:44:12,424] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:44:12,435] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.038 seconds
[2021-04-23 14:44:42,607] {scheduler_job.py:182} INFO - Started process (PID=245) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:44:42,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:44:42,614] {logging_mixin.py:104} INFO - [2021-04-23 14:44:42,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:44:43,400] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:44:43,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:44:43,459] {logging_mixin.py:104} INFO - [2021-04-23 14:44:43,458] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:44:43,522] {logging_mixin.py:104} INFO - [2021-04-23 14:44:43,522] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:44:43,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.941 seconds
[2021-04-23 14:45:13,633] {scheduler_job.py:182} INFO - Started process (PID=247) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:45:13,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:45:13,638] {logging_mixin.py:104} INFO - [2021-04-23 14:45:13,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:45:14,406] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:45:14,435] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:45:14,450] {logging_mixin.py:104} INFO - [2021-04-23 14:45:14,449] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:45:14,469] {logging_mixin.py:104} INFO - [2021-04-23 14:45:14,469] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:45:14,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.853 seconds
[2021-04-23 14:45:44,617] {scheduler_job.py:182} INFO - Started process (PID=249) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:45:44,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:45:44,626] {logging_mixin.py:104} INFO - [2021-04-23 14:45:44,625] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:45:46,063] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:45:46,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:45:46,110] {logging_mixin.py:104} INFO - [2021-04-23 14:45:46,109] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:45:46,139] {logging_mixin.py:104} INFO - [2021-04-23 14:45:46,139] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:45:46,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.543 seconds
[2021-04-23 14:46:16,342] {scheduler_job.py:182} INFO - Started process (PID=251) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:46:16,347] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:46:16,349] {logging_mixin.py:104} INFO - [2021-04-23 14:46:16,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:46:17,194] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:46:17,213] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:46:17,224] {logging_mixin.py:104} INFO - [2021-04-23 14:46:17,223] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:46:17,248] {logging_mixin.py:104} INFO - [2021-04-23 14:46:17,248] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:46:17,262] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.930 seconds
[2021-04-23 14:46:47,399] {scheduler_job.py:182} INFO - Started process (PID=253) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:46:47,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:46:47,404] {logging_mixin.py:104} INFO - [2021-04-23 14:46:47,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:46:48,155] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:46:48,183] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:46:48,196] {logging_mixin.py:104} INFO - [2021-04-23 14:46:48,195] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:46:48,212] {logging_mixin.py:104} INFO - [2021-04-23 14:46:48,212] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:46:48,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.828 seconds
[2021-04-23 14:47:21,713] {scheduler_job.py:182} INFO - Started process (PID=255) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:47:21,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:47:21,749] {logging_mixin.py:104} INFO - [2021-04-23 14:47:21,748] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:48:33,978] {scheduler_job.py:182} INFO - Started process (PID=258) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:48:34,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:48:34,016] {logging_mixin.py:104} INFO - [2021-04-23 14:48:34,015] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:48:38,992] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:48:39,048] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:48:39,070] {logging_mixin.py:104} INFO - [2021-04-23 14:48:39,069] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:48:39,104] {logging_mixin.py:104} INFO - [2021-04-23 14:48:39,104] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:48:39,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 5.203 seconds
[2021-04-23 14:49:09,430] {scheduler_job.py:182} INFO - Started process (PID=260) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:49:09,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:49:09,446] {logging_mixin.py:104} INFO - [2021-04-23 14:49:09,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:49:09,961] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:49:10,002] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:49:10,014] {logging_mixin.py:104} INFO - [2021-04-23 14:49:10,013] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:49:10,032] {logging_mixin.py:104} INFO - [2021-04-23 14:49:10,032] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:49:10,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.627 seconds
[2021-04-23 14:49:40,186] {scheduler_job.py:182} INFO - Started process (PID=262) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:49:40,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:49:40,191] {logging_mixin.py:104} INFO - [2021-04-23 14:49:40,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:49:40,601] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:49:40,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:49:40,632] {logging_mixin.py:104} INFO - [2021-04-23 14:49:40,630] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:49:40,651] {logging_mixin.py:104} INFO - [2021-04-23 14:49:40,650] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:49:40,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.480 seconds
[2021-04-23 14:50:10,805] {scheduler_job.py:182} INFO - Started process (PID=264) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:50:10,811] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:50:10,813] {logging_mixin.py:104} INFO - [2021-04-23 14:50:10,813] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:50:11,396] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:50:11,455] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:50:11,487] {logging_mixin.py:104} INFO - [2021-04-23 14:50:11,483] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:50:11,517] {logging_mixin.py:104} INFO - [2021-04-23 14:50:11,517] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:50:11,531] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.731 seconds
[2021-04-23 14:50:41,943] {scheduler_job.py:182} INFO - Started process (PID=266) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:50:41,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:50:41,962] {logging_mixin.py:104} INFO - [2021-04-23 14:50:41,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:50:43,391] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:50:43,449] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:50:43,485] {logging_mixin.py:104} INFO - [2021-04-23 14:50:43,484] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:50:43,523] {logging_mixin.py:104} INFO - [2021-04-23 14:50:43,522] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:50:43,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.623 seconds
[2021-04-23 14:51:13,794] {scheduler_job.py:182} INFO - Started process (PID=268) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:51:13,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:51:13,802] {logging_mixin.py:104} INFO - [2021-04-23 14:51:13,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:51:14,412] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:51:14,452] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:51:14,480] {logging_mixin.py:104} INFO - [2021-04-23 14:51:14,477] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:51:14,514] {logging_mixin.py:104} INFO - [2021-04-23 14:51:14,514] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:51:14,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-23 14:51:44,787] {scheduler_job.py:182} INFO - Started process (PID=270) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:51:44,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:51:44,794] {logging_mixin.py:104} INFO - [2021-04-23 14:51:44,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:51:45,420] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:51:45,438] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:51:45,455] {logging_mixin.py:104} INFO - [2021-04-23 14:51:45,453] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:51:45,475] {logging_mixin.py:104} INFO - [2021-04-23 14:51:45,475] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:51:45,489] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.710 seconds
[2021-04-23 14:52:15,639] {scheduler_job.py:182} INFO - Started process (PID=272) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:52:15,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:52:15,652] {logging_mixin.py:104} INFO - [2021-04-23 14:52:15,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:52:16,437] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:52:16,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:52:16,494] {logging_mixin.py:104} INFO - [2021-04-23 14:52:16,491] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:52:16,553] {logging_mixin.py:104} INFO - [2021-04-23 14:52:16,553] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:52:16,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.949 seconds
[2021-04-23 14:52:46,914] {scheduler_job.py:182} INFO - Started process (PID=274) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:52:46,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:52:46,923] {logging_mixin.py:104} INFO - [2021-04-23 14:52:46,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:52:47,886] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:52:47,913] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:52:47,935] {logging_mixin.py:104} INFO - [2021-04-23 14:52:47,933] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:52:48,011] {logging_mixin.py:104} INFO - [2021-04-23 14:52:48,010] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:52:48,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.138 seconds
[2021-04-23 14:53:18,292] {scheduler_job.py:182} INFO - Started process (PID=276) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:53:18,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:53:18,299] {logging_mixin.py:104} INFO - [2021-04-23 14:53:18,299] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:53:18,848] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:53:18,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:53:18,894] {logging_mixin.py:104} INFO - [2021-04-23 14:53:18,892] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:53:18,938] {logging_mixin.py:104} INFO - [2021-04-23 14:53:18,938] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:53:18,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.668 seconds
[2021-04-23 14:53:49,816] {scheduler_job.py:182} INFO - Started process (PID=278) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:53:49,822] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:53:49,826] {logging_mixin.py:104} INFO - [2021-04-23 14:53:49,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:53:50,812] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:53:50,833] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:53:50,846] {logging_mixin.py:104} INFO - [2021-04-23 14:53:50,845] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:53:50,873] {logging_mixin.py:104} INFO - [2021-04-23 14:53:50,873] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:53:50,886] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.086 seconds
[2021-04-23 14:54:21,205] {scheduler_job.py:182} INFO - Started process (PID=280) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:54:21,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:54:21,213] {logging_mixin.py:104} INFO - [2021-04-23 14:54:21,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:54:22,086] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:54:22,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:54:22,152] {logging_mixin.py:104} INFO - [2021-04-23 14:54:22,151] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:54:22,198] {logging_mixin.py:104} INFO - [2021-04-23 14:54:22,198] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:54:22,216] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.017 seconds
[2021-04-23 14:54:52,437] {scheduler_job.py:182} INFO - Started process (PID=282) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:54:52,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:54:52,442] {logging_mixin.py:104} INFO - [2021-04-23 14:54:52,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:54:53,163] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:54:53,237] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:54:53,257] {logging_mixin.py:104} INFO - [2021-04-23 14:54:53,256] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:54:53,290] {logging_mixin.py:104} INFO - [2021-04-23 14:54:53,290] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:54:53,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.873 seconds
[2021-04-23 14:55:23,472] {scheduler_job.py:182} INFO - Started process (PID=284) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:55:23,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:55:23,483] {logging_mixin.py:104} INFO - [2021-04-23 14:55:23,483] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:55:24,165] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:55:24,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:55:24,214] {logging_mixin.py:104} INFO - [2021-04-23 14:55:24,211] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:55:24,254] {logging_mixin.py:104} INFO - [2021-04-23 14:55:24,254] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:55:24,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.804 seconds
[2021-04-23 14:55:54,491] {scheduler_job.py:182} INFO - Started process (PID=286) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:55:54,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:55:54,501] {logging_mixin.py:104} INFO - [2021-04-23 14:55:54,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:55:54,985] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:55:55,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:55:55,056] {logging_mixin.py:104} INFO - [2021-04-23 14:55:55,054] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:55:55,128] {logging_mixin.py:104} INFO - [2021-04-23 14:55:55,127] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:55:55,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.669 seconds
[2021-04-23 14:56:25,447] {scheduler_job.py:182} INFO - Started process (PID=288) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:56:25,451] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:56:25,453] {logging_mixin.py:104} INFO - [2021-04-23 14:56:25,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:56:26,052] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:56:26,073] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:56:26,090] {logging_mixin.py:104} INFO - [2021-04-23 14:56:26,089] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:56:26,109] {logging_mixin.py:104} INFO - [2021-04-23 14:56:26,108] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:56:26,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.681 seconds
[2021-04-23 14:56:56,273] {scheduler_job.py:182} INFO - Started process (PID=290) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:56:56,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:56:56,278] {logging_mixin.py:104} INFO - [2021-04-23 14:56:56,277] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:56:56,732] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:56:56,759] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:56:56,775] {logging_mixin.py:104} INFO - [2021-04-23 14:56:56,774] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:56:56,800] {logging_mixin.py:104} INFO - [2021-04-23 14:56:56,799] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:56:56,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.542 seconds
[2021-04-23 14:57:26,961] {scheduler_job.py:182} INFO - Started process (PID=292) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:57:26,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:57:26,966] {logging_mixin.py:104} INFO - [2021-04-23 14:57:26,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:57:27,364] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:57:27,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:57:27,403] {logging_mixin.py:104} INFO - [2021-04-23 14:57:27,401] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:57:27,422] {logging_mixin.py:104} INFO - [2021-04-23 14:57:27,422] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:57:27,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.473 seconds
[2021-04-23 14:57:57,641] {scheduler_job.py:182} INFO - Started process (PID=294) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:57:57,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:57:57,691] {logging_mixin.py:104} INFO - [2021-04-23 14:57:57,690] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:57:58,661] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:57:58,693] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:57:58,714] {logging_mixin.py:104} INFO - [2021-04-23 14:57:58,713] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:57:58,745] {logging_mixin.py:104} INFO - [2021-04-23 14:57:58,745] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:57:58,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.130 seconds
[2021-04-23 14:58:28,918] {scheduler_job.py:182} INFO - Started process (PID=296) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:58:28,923] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:58:28,925] {logging_mixin.py:104} INFO - [2021-04-23 14:58:28,925] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:58:30,190] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:58:30,258] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:58:30,309] {logging_mixin.py:104} INFO - [2021-04-23 14:58:30,306] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:58:30,346] {logging_mixin.py:104} INFO - [2021-04-23 14:58:30,345] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:58:30,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.444 seconds
[2021-04-23 14:59:00,480] {scheduler_job.py:182} INFO - Started process (PID=298) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:59:00,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:59:00,487] {logging_mixin.py:104} INFO - [2021-04-23 14:59:00,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:59:01,150] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:59:01,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:59:01,212] {logging_mixin.py:104} INFO - [2021-04-23 14:59:01,211] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:59:01,242] {logging_mixin.py:104} INFO - [2021-04-23 14:59:01,242] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:59:01,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.782 seconds
[2021-04-23 14:59:31,380] {scheduler_job.py:182} INFO - Started process (PID=300) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:59:31,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 14:59:31,385] {logging_mixin.py:104} INFO - [2021-04-23 14:59:31,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:59:31,895] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 14:59:31,924] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 14:59:31,984] {logging_mixin.py:104} INFO - [2021-04-23 14:59:31,980] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 14:59:32,031] {logging_mixin.py:104} INFO - [2021-04-23 14:59:32,030] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 14:59:32,047] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.672 seconds
[2021-04-23 15:00:02,147] {scheduler_job.py:182} INFO - Started process (PID=302) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:00:02,151] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:00:02,154] {logging_mixin.py:104} INFO - [2021-04-23 15:00:02,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:00:02,766] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:00:02,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:00:02,816] {logging_mixin.py:104} INFO - [2021-04-23 15:00:02,815] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:00:02,845] {logging_mixin.py:104} INFO - [2021-04-23 15:00:02,845] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:00:02,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.727 seconds
[2021-04-23 15:00:32,989] {scheduler_job.py:182} INFO - Started process (PID=304) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:00:32,992] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:00:32,994] {logging_mixin.py:104} INFO - [2021-04-23 15:00:32,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:00:33,366] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:00:33,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:00:33,390] {logging_mixin.py:104} INFO - [2021-04-23 15:00:33,389] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:00:33,409] {logging_mixin.py:104} INFO - [2021-04-23 15:00:33,408] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:00:33,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.434 seconds
[2021-04-23 15:01:03,571] {scheduler_job.py:182} INFO - Started process (PID=306) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:01:03,574] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:01:03,576] {logging_mixin.py:104} INFO - [2021-04-23 15:01:03,576] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:01:03,993] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:01:04,010] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:01:04,023] {logging_mixin.py:104} INFO - [2021-04-23 15:01:04,022] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:01:04,045] {logging_mixin.py:104} INFO - [2021-04-23 15:01:04,045] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:01:04,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.494 seconds
[2021-04-23 15:01:34,203] {scheduler_job.py:182} INFO - Started process (PID=308) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:01:34,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:01:34,208] {logging_mixin.py:104} INFO - [2021-04-23 15:01:34,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:01:34,634] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:01:34,652] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:01:34,675] {logging_mixin.py:104} INFO - [2021-04-23 15:01:34,673] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:01:34,691] {logging_mixin.py:104} INFO - [2021-04-23 15:01:34,691] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:01:34,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.506 seconds
[2021-04-23 15:02:04,773] {scheduler_job.py:182} INFO - Started process (PID=310) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:02:04,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:02:04,782] {logging_mixin.py:104} INFO - [2021-04-23 15:02:04,781] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:02:05,149] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:02:05,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:02:05,175] {logging_mixin.py:104} INFO - [2021-04-23 15:02:05,174] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:02:05,194] {logging_mixin.py:104} INFO - [2021-04-23 15:02:05,193] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:02:05,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.435 seconds
[2021-04-23 15:02:35,357] {scheduler_job.py:182} INFO - Started process (PID=312) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:02:35,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:02:35,363] {logging_mixin.py:104} INFO - [2021-04-23 15:02:35,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:02:35,836] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:02:35,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:02:35,886] {logging_mixin.py:104} INFO - [2021-04-23 15:02:35,885] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:02:35,904] {logging_mixin.py:104} INFO - [2021-04-23 15:02:35,904] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:02:35,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.565 seconds
[2021-04-23 15:03:06,507] {scheduler_job.py:182} INFO - Started process (PID=314) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:03:06,511] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:03:06,519] {logging_mixin.py:104} INFO - [2021-04-23 15:03:06,518] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:03:08,439] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:03:08,525] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:03:08,600] {logging_mixin.py:104} INFO - [2021-04-23 15:03:08,598] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:03:08,660] {logging_mixin.py:104} INFO - [2021-04-23 15:03:08,659] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:03:08,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.180 seconds
[2021-04-23 15:03:39,029] {scheduler_job.py:182} INFO - Started process (PID=316) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:03:39,032] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:03:39,041] {logging_mixin.py:104} INFO - [2021-04-23 15:03:39,040] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:03:39,745] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:03:39,779] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:03:39,795] {logging_mixin.py:104} INFO - [2021-04-23 15:03:39,794] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:03:39,815] {logging_mixin.py:104} INFO - [2021-04-23 15:03:39,815] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:03:39,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.813 seconds
[2021-04-23 15:04:09,945] {scheduler_job.py:182} INFO - Started process (PID=318) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:04:09,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:04:09,953] {logging_mixin.py:104} INFO - [2021-04-23 15:04:09,953] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:04:10,800] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:04:10,829] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:04:10,851] {logging_mixin.py:104} INFO - [2021-04-23 15:04:10,850] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:04:10,883] {logging_mixin.py:104} INFO - [2021-04-23 15:04:10,883] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:04:10,906] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.967 seconds
[2021-04-23 15:04:41,084] {scheduler_job.py:182} INFO - Started process (PID=320) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:04:41,091] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:04:41,096] {logging_mixin.py:104} INFO - [2021-04-23 15:04:41,096] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:04:42,080] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:04:42,105] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:04:42,122] {logging_mixin.py:104} INFO - [2021-04-23 15:04:42,120] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:04:42,143] {logging_mixin.py:104} INFO - [2021-04-23 15:04:42,143] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:04:42,156] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.092 seconds
[2021-04-23 15:05:13,362] {scheduler_job.py:182} INFO - Started process (PID=322) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:05:13,369] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:05:13,374] {logging_mixin.py:104} INFO - [2021-04-23 15:05:13,374] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:05:14,949] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:05:14,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:05:15,027] {logging_mixin.py:104} INFO - [2021-04-23 15:05:15,026] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:05:15,065] {logging_mixin.py:104} INFO - [2021-04-23 15:05:15,064] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:05:15,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.750 seconds
[2021-04-23 15:05:45,210] {scheduler_job.py:182} INFO - Started process (PID=324) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:05:45,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:05:45,220] {logging_mixin.py:104} INFO - [2021-04-23 15:05:45,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:05:46,302] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:05:46,344] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:05:46,394] {logging_mixin.py:104} INFO - [2021-04-23 15:05:46,392] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:05:46,439] {logging_mixin.py:104} INFO - [2021-04-23 15:05:46,438] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:05:46,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.262 seconds
[2021-04-23 15:06:16,755] {scheduler_job.py:182} INFO - Started process (PID=326) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:06:16,761] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:06:16,772] {logging_mixin.py:104} INFO - [2021-04-23 15:06:16,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:06:18,102] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:06:18,159] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:06:18,220] {logging_mixin.py:104} INFO - [2021-04-23 15:06:18,214] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:06:18,329] {logging_mixin.py:104} INFO - [2021-04-23 15:06:18,328] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:06:18,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.678 seconds
[2021-04-23 15:06:48,573] {scheduler_job.py:182} INFO - Started process (PID=328) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:06:48,579] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:06:48,583] {logging_mixin.py:104} INFO - [2021-04-23 15:06:48,583] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:06:49,200] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:06:49,266] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:06:49,374] {logging_mixin.py:104} INFO - [2021-04-23 15:06:49,367] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:06:49,497] {logging_mixin.py:104} INFO - [2021-04-23 15:06:49,494] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:06:49,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.022 seconds
[2021-04-23 15:07:19,791] {scheduler_job.py:182} INFO - Started process (PID=330) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:07:19,798] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:07:19,800] {logging_mixin.py:104} INFO - [2021-04-23 15:07:19,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:07:20,218] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:07:20,234] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:07:20,252] {logging_mixin.py:104} INFO - [2021-04-23 15:07:20,251] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:07:20,272] {logging_mixin.py:104} INFO - [2021-04-23 15:07:20,272] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:07:20,285] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.509 seconds
[2021-04-23 15:07:50,429] {scheduler_job.py:182} INFO - Started process (PID=332) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:07:50,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:07:50,445] {logging_mixin.py:104} INFO - [2021-04-23 15:07:50,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:07:51,385] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:07:51,407] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:07:51,420] {logging_mixin.py:104} INFO - [2021-04-23 15:07:51,419] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:07:51,437] {logging_mixin.py:104} INFO - [2021-04-23 15:07:51,437] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:07:51,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.025 seconds
[2021-04-23 15:08:21,528] {scheduler_job.py:182} INFO - Started process (PID=334) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:08:21,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:08:21,539] {logging_mixin.py:104} INFO - [2021-04-23 15:08:21,539] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:08:22,354] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:08:22,387] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:08:22,409] {logging_mixin.py:104} INFO - [2021-04-23 15:08:22,407] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:08:22,437] {logging_mixin.py:104} INFO - [2021-04-23 15:08:22,437] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:08:22,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.941 seconds
[2021-04-23 15:08:52,646] {scheduler_job.py:182} INFO - Started process (PID=336) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:08:52,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:08:52,657] {logging_mixin.py:104} INFO - [2021-04-23 15:08:52,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:08:53,284] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:08:53,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:08:53,390] {logging_mixin.py:104} INFO - [2021-04-23 15:08:53,379] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:08:53,471] {logging_mixin.py:104} INFO - [2021-04-23 15:08:53,470] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:08:53,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.847 seconds
[2021-04-23 15:09:23,592] {scheduler_job.py:182} INFO - Started process (PID=338) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:09:23,597] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:09:23,601] {logging_mixin.py:104} INFO - [2021-04-23 15:09:23,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:09:24,426] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:09:24,464] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:09:24,495] {logging_mixin.py:104} INFO - [2021-04-23 15:09:24,492] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:09:24,529] {logging_mixin.py:104} INFO - [2021-04-23 15:09:24,529] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:09:24,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.959 seconds
[2021-04-23 15:09:54,690] {scheduler_job.py:182} INFO - Started process (PID=340) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:09:54,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:09:54,694] {logging_mixin.py:104} INFO - [2021-04-23 15:09:54,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:09:55,116] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:09:55,158] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:09:55,187] {logging_mixin.py:104} INFO - [2021-04-23 15:09:55,186] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:09:55,205] {logging_mixin.py:104} INFO - [2021-04-23 15:09:55,205] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:09:55,222] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.536 seconds
[2021-04-23 15:10:25,352] {scheduler_job.py:182} INFO - Started process (PID=342) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:10:25,357] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:10:25,361] {logging_mixin.py:104} INFO - [2021-04-23 15:10:25,360] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:10:25,822] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:10:25,841] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:10:25,861] {logging_mixin.py:104} INFO - [2021-04-23 15:10:25,860] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:10:25,877] {logging_mixin.py:104} INFO - [2021-04-23 15:10:25,876] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:10:25,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.537 seconds
[2021-04-23 15:10:56,177] {scheduler_job.py:182} INFO - Started process (PID=344) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:10:56,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:10:56,186] {logging_mixin.py:104} INFO - [2021-04-23 15:10:56,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:10:56,823] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:10:56,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:10:56,876] {logging_mixin.py:104} INFO - [2021-04-23 15:10:56,874] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:10:56,914] {logging_mixin.py:104} INFO - [2021-04-23 15:10:56,914] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:10:56,927] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.762 seconds
[2021-04-23 15:11:27,066] {scheduler_job.py:182} INFO - Started process (PID=346) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:11:27,072] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:11:27,075] {logging_mixin.py:104} INFO - [2021-04-23 15:11:27,074] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:11:27,444] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:11:27,460] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:11:27,494] {logging_mixin.py:104} INFO - [2021-04-23 15:11:27,493] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:11:27,538] {logging_mixin.py:104} INFO - [2021-04-23 15:11:27,538] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:11:27,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.506 seconds
[2021-04-23 15:11:57,697] {scheduler_job.py:182} INFO - Started process (PID=348) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:11:57,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:11:57,706] {logging_mixin.py:104} INFO - [2021-04-23 15:11:57,706] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:11:58,140] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:11:58,155] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:11:58,168] {logging_mixin.py:104} INFO - [2021-04-23 15:11:58,167] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:11:58,184] {logging_mixin.py:104} INFO - [2021-04-23 15:11:58,184] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:11:58,197] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.509 seconds
[2021-04-23 15:12:28,328] {scheduler_job.py:182} INFO - Started process (PID=350) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:12:28,331] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:12:28,333] {logging_mixin.py:104} INFO - [2021-04-23 15:12:28,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:12:28,732] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:12:28,754] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:12:28,769] {logging_mixin.py:104} INFO - [2021-04-23 15:12:28,768] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:12:28,803] {logging_mixin.py:104} INFO - [2021-04-23 15:12:28,803] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:12:28,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.493 seconds
[2021-04-23 15:12:59,268] {scheduler_job.py:182} INFO - Started process (PID=352) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:12:59,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:12:59,291] {logging_mixin.py:104} INFO - [2021-04-23 15:12:59,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:12:59,985] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:13:00,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:13:00,026] {logging_mixin.py:104} INFO - [2021-04-23 15:13:00,023] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:13:00,054] {logging_mixin.py:104} INFO - [2021-04-23 15:13:00,053] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:13:00,063] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.840 seconds
[2021-04-23 15:13:30,186] {scheduler_job.py:182} INFO - Started process (PID=354) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:13:30,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:13:30,194] {logging_mixin.py:104} INFO - [2021-04-23 15:13:30,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:13:30,712] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:13:30,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:13:30,747] {logging_mixin.py:104} INFO - [2021-04-23 15:13:30,746] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:13:30,813] {logging_mixin.py:104} INFO - [2021-04-23 15:13:30,813] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:13:30,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.643 seconds
[2021-04-23 15:14:01,030] {scheduler_job.py:182} INFO - Started process (PID=356) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:14:01,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:14:01,037] {logging_mixin.py:104} INFO - [2021-04-23 15:14:01,036] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:14:01,544] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:14:01,565] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:14:01,585] {logging_mixin.py:104} INFO - [2021-04-23 15:14:01,583] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:14:01,611] {logging_mixin.py:104} INFO - [2021-04-23 15:14:01,610] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:14:01,648] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.623 seconds
[2021-04-23 15:14:31,797] {scheduler_job.py:182} INFO - Started process (PID=358) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:14:31,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:14:31,807] {logging_mixin.py:104} INFO - [2021-04-23 15:14:31,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:14:32,343] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:14:32,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:14:32,400] {logging_mixin.py:104} INFO - [2021-04-23 15:14:32,398] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:14:32,436] {logging_mixin.py:104} INFO - [2021-04-23 15:14:32,435] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:14:32,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.657 seconds
[2021-04-23 15:15:02,577] {scheduler_job.py:182} INFO - Started process (PID=360) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:15:02,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:15:02,584] {logging_mixin.py:104} INFO - [2021-04-23 15:15:02,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:15:03,122] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:15:03,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:15:03,165] {logging_mixin.py:104} INFO - [2021-04-23 15:15:03,164] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:15:03,245] {logging_mixin.py:104} INFO - [2021-04-23 15:15:03,244] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:15:03,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-23 15:15:33,884] {scheduler_job.py:182} INFO - Started process (PID=362) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:15:33,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:15:33,891] {logging_mixin.py:104} INFO - [2021-04-23 15:15:33,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:15:34,338] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:15:34,366] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:15:34,380] {logging_mixin.py:104} INFO - [2021-04-23 15:15:34,379] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:15:34,397] {logging_mixin.py:104} INFO - [2021-04-23 15:15:34,397] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:15:34,406] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.527 seconds
[2021-04-23 15:16:04,555] {scheduler_job.py:182} INFO - Started process (PID=364) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:16:04,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:16:04,562] {logging_mixin.py:104} INFO - [2021-04-23 15:16:04,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:16:05,060] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:16:05,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:16:05,089] {logging_mixin.py:104} INFO - [2021-04-23 15:16:05,088] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:16:05,110] {logging_mixin.py:104} INFO - [2021-04-23 15:16:05,110] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:16:05,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.568 seconds
[2021-04-23 15:16:35,231] {scheduler_job.py:182} INFO - Started process (PID=366) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:16:35,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:16:35,239] {logging_mixin.py:104} INFO - [2021-04-23 15:16:35,239] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:16:35,826] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:16:35,843] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:16:35,858] {logging_mixin.py:104} INFO - [2021-04-23 15:16:35,857] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:16:35,884] {logging_mixin.py:104} INFO - [2021-04-23 15:16:35,884] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:16:35,893] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.668 seconds
[2021-04-23 15:17:05,970] {scheduler_job.py:182} INFO - Started process (PID=368) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:17:05,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:17:05,976] {logging_mixin.py:104} INFO - [2021-04-23 15:17:05,976] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:17:06,593] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:17:06,622] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:17:06,644] {logging_mixin.py:104} INFO - [2021-04-23 15:17:06,642] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:17:06,678] {logging_mixin.py:104} INFO - [2021-04-23 15:17:06,678] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:17:06,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.747 seconds
[2021-04-23 15:17:36,852] {scheduler_job.py:182} INFO - Started process (PID=370) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:17:36,856] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:17:36,858] {logging_mixin.py:104} INFO - [2021-04-23 15:17:36,858] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:17:37,365] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:17:37,409] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:17:37,428] {logging_mixin.py:104} INFO - [2021-04-23 15:17:37,427] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:17:37,453] {logging_mixin.py:104} INFO - [2021-04-23 15:17:37,453] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:17:37,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.623 seconds
[2021-04-23 15:18:07,608] {scheduler_job.py:182} INFO - Started process (PID=372) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:18:07,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:18:07,620] {logging_mixin.py:104} INFO - [2021-04-23 15:18:07,619] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:18:08,956] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:18:08,988] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:18:09,021] {logging_mixin.py:104} INFO - [2021-04-23 15:18:09,014] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:18:09,074] {logging_mixin.py:104} INFO - [2021-04-23 15:18:09,073] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:18:09,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.495 seconds
[2021-04-23 15:18:39,286] {scheduler_job.py:182} INFO - Started process (PID=374) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:18:39,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:18:39,291] {logging_mixin.py:104} INFO - [2021-04-23 15:18:39,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:18:39,689] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:18:39,705] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:18:39,729] {logging_mixin.py:104} INFO - [2021-04-23 15:18:39,728] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:18:39,750] {logging_mixin.py:104} INFO - [2021-04-23 15:18:39,750] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:18:39,762] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.481 seconds
[2021-04-23 15:19:09,875] {scheduler_job.py:182} INFO - Started process (PID=376) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:19:09,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:19:09,885] {logging_mixin.py:104} INFO - [2021-04-23 15:19:09,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:19:10,384] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:19:10,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:19:10,430] {logging_mixin.py:104} INFO - [2021-04-23 15:19:10,429] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:19:10,463] {logging_mixin.py:104} INFO - [2021-04-23 15:19:10,463] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:19:10,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.612 seconds
[2021-04-23 15:19:40,587] {scheduler_job.py:182} INFO - Started process (PID=378) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:19:40,607] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:19:40,610] {logging_mixin.py:104} INFO - [2021-04-23 15:19:40,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:19:41,016] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:19:41,033] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:19:41,047] {logging_mixin.py:104} INFO - [2021-04-23 15:19:41,046] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:19:41,089] {logging_mixin.py:104} INFO - [2021-04-23 15:19:41,089] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:19:41,106] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.524 seconds
[2021-04-23 15:20:11,204] {scheduler_job.py:182} INFO - Started process (PID=380) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:20:11,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:20:11,210] {logging_mixin.py:104} INFO - [2021-04-23 15:20:11,210] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:20:11,614] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:20:11,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:20:11,653] {logging_mixin.py:104} INFO - [2021-04-23 15:20:11,651] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:20:11,685] {logging_mixin.py:104} INFO - [2021-04-23 15:20:11,685] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:20:11,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.506 seconds
[2021-04-23 15:20:41,822] {scheduler_job.py:182} INFO - Started process (PID=382) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:20:41,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:20:41,825] {logging_mixin.py:104} INFO - [2021-04-23 15:20:41,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:20:42,219] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:20:42,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:20:42,259] {logging_mixin.py:104} INFO - [2021-04-23 15:20:42,258] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:20:42,284] {logging_mixin.py:104} INFO - [2021-04-23 15:20:42,283] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:20:42,297] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.479 seconds
[2021-04-23 15:21:12,420] {scheduler_job.py:182} INFO - Started process (PID=384) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:21:12,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:21:12,426] {logging_mixin.py:104} INFO - [2021-04-23 15:21:12,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:21:12,844] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:21:12,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:21:12,871] {logging_mixin.py:104} INFO - [2021-04-23 15:21:12,870] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:21:12,889] {logging_mixin.py:104} INFO - [2021-04-23 15:21:12,889] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:21:12,896] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.479 seconds
[2021-04-23 15:21:43,016] {scheduler_job.py:182} INFO - Started process (PID=386) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:21:43,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:21:43,022] {logging_mixin.py:104} INFO - [2021-04-23 15:21:43,022] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:21:43,470] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:21:43,487] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:21:43,500] {logging_mixin.py:104} INFO - [2021-04-23 15:21:43,499] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:21:43,521] {logging_mixin.py:104} INFO - [2021-04-23 15:21:43,521] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:21:43,531] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.520 seconds
[2021-04-23 15:22:13,665] {scheduler_job.py:182} INFO - Started process (PID=388) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:22:13,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:22:13,671] {logging_mixin.py:104} INFO - [2021-04-23 15:22:13,671] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:22:14,084] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:22:14,103] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:22:14,118] {logging_mixin.py:104} INFO - [2021-04-23 15:22:14,115] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:22:14,139] {logging_mixin.py:104} INFO - [2021-04-23 15:22:14,139] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:22:14,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.490 seconds
[2021-04-23 15:22:44,268] {scheduler_job.py:182} INFO - Started process (PID=390) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:22:44,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:22:44,273] {logging_mixin.py:104} INFO - [2021-04-23 15:22:44,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:22:44,781] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:22:44,803] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:22:44,819] {logging_mixin.py:104} INFO - [2021-04-23 15:22:44,818] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:22:44,844] {logging_mixin.py:104} INFO - [2021-04-23 15:22:44,844] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:22:44,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.600 seconds
[2021-04-23 15:23:14,986] {scheduler_job.py:182} INFO - Started process (PID=392) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:23:14,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:23:14,992] {logging_mixin.py:104} INFO - [2021-04-23 15:23:14,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:23:15,619] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:23:15,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:23:15,677] {logging_mixin.py:104} INFO - [2021-04-23 15:23:15,675] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:23:15,703] {logging_mixin.py:104} INFO - [2021-04-23 15:23:15,703] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:23:15,717] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.736 seconds
[2021-04-23 15:23:45,901] {scheduler_job.py:182} INFO - Started process (PID=394) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:23:45,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:23:45,911] {logging_mixin.py:104} INFO - [2021-04-23 15:23:45,910] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:23:46,842] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:23:46,908] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:23:46,933] {logging_mixin.py:104} INFO - [2021-04-23 15:23:46,928] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:23:46,972] {logging_mixin.py:104} INFO - [2021-04-23 15:23:46,972] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:23:46,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.098 seconds
[2021-04-23 15:24:17,148] {scheduler_job.py:182} INFO - Started process (PID=396) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:24:17,153] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:24:17,159] {logging_mixin.py:104} INFO - [2021-04-23 15:24:17,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:24:18,114] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:24:18,162] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:24:18,194] {logging_mixin.py:104} INFO - [2021-04-23 15:24:18,192] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:24:18,238] {logging_mixin.py:104} INFO - [2021-04-23 15:24:18,237] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:24:18,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.120 seconds
[2021-04-23 15:24:48,367] {scheduler_job.py:182} INFO - Started process (PID=398) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:24:48,370] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:24:48,372] {logging_mixin.py:104} INFO - [2021-04-23 15:24:48,372] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:24:48,823] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:24:48,849] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:24:48,867] {logging_mixin.py:104} INFO - [2021-04-23 15:24:48,866] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:24:48,892] {logging_mixin.py:104} INFO - [2021-04-23 15:24:48,892] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:24:48,905] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.542 seconds
[2021-04-23 15:25:19,097] {scheduler_job.py:182} INFO - Started process (PID=400) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:25:19,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:25:19,113] {logging_mixin.py:104} INFO - [2021-04-23 15:25:19,112] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:25:20,283] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:25:20,315] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:25:20,337] {logging_mixin.py:104} INFO - [2021-04-23 15:25:20,334] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:25:20,369] {logging_mixin.py:104} INFO - [2021-04-23 15:25:20,369] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:25:20,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.301 seconds
[2021-04-23 15:25:50,550] {scheduler_job.py:182} INFO - Started process (PID=402) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:25:50,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:25:50,561] {logging_mixin.py:104} INFO - [2021-04-23 15:25:50,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:25:51,155] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:25:51,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:25:51,198] {logging_mixin.py:104} INFO - [2021-04-23 15:25:51,195] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:25:51,224] {logging_mixin.py:104} INFO - [2021-04-23 15:25:51,224] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:25:51,244] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.703 seconds
[2021-04-23 15:26:21,361] {scheduler_job.py:182} INFO - Started process (PID=404) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:26:21,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:26:21,367] {logging_mixin.py:104} INFO - [2021-04-23 15:26:21,367] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:26:21,972] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:26:22,000] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:26:22,020] {logging_mixin.py:104} INFO - [2021-04-23 15:26:22,019] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:26:22,065] {logging_mixin.py:104} INFO - [2021-04-23 15:26:22,064] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:26:22,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.732 seconds
[2021-04-23 15:26:52,236] {scheduler_job.py:182} INFO - Started process (PID=406) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:26:52,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:26:52,240] {logging_mixin.py:104} INFO - [2021-04-23 15:26:52,240] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:26:52,760] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:26:52,778] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:26:52,798] {logging_mixin.py:104} INFO - [2021-04-23 15:26:52,796] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:26:52,818] {logging_mixin.py:104} INFO - [2021-04-23 15:26:52,818] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:26:52,828] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.597 seconds
[2021-04-23 15:27:22,924] {scheduler_job.py:182} INFO - Started process (PID=408) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:27:22,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:27:22,931] {logging_mixin.py:104} INFO - [2021-04-23 15:27:22,931] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:27:23,355] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:27:23,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:27:23,382] {logging_mixin.py:104} INFO - [2021-04-23 15:27:23,381] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:27:23,400] {logging_mixin.py:104} INFO - [2021-04-23 15:27:23,399] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:27:23,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.489 seconds
[2021-04-23 15:27:53,511] {scheduler_job.py:182} INFO - Started process (PID=410) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:27:53,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:27:53,519] {logging_mixin.py:104} INFO - [2021-04-23 15:27:53,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:27:53,992] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:27:54,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:27:54,024] {logging_mixin.py:104} INFO - [2021-04-23 15:27:54,023] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:27:54,045] {logging_mixin.py:104} INFO - [2021-04-23 15:27:54,045] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:27:54,057] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.552 seconds
[2021-04-23 15:28:24,191] {scheduler_job.py:182} INFO - Started process (PID=412) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:28:24,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:28:24,199] {logging_mixin.py:104} INFO - [2021-04-23 15:28:24,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:28:24,636] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:28:24,654] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:28:24,665] {logging_mixin.py:104} INFO - [2021-04-23 15:28:24,664] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:28:24,683] {logging_mixin.py:104} INFO - [2021-04-23 15:28:24,683] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:28:24,694] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.508 seconds
[2021-04-23 15:28:54,775] {scheduler_job.py:182} INFO - Started process (PID=414) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:28:54,781] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:28:54,785] {logging_mixin.py:104} INFO - [2021-04-23 15:28:54,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:28:55,339] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:28:55,355] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:28:55,366] {logging_mixin.py:104} INFO - [2021-04-23 15:28:55,365] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:28:55,386] {logging_mixin.py:104} INFO - [2021-04-23 15:28:55,386] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:28:55,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.625 seconds
[2021-04-23 15:29:25,540] {scheduler_job.py:182} INFO - Started process (PID=416) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:29:25,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:29:25,545] {logging_mixin.py:104} INFO - [2021-04-23 15:29:25,545] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:29:25,944] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:29:25,967] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:29:25,981] {logging_mixin.py:104} INFO - [2021-04-23 15:29:25,979] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:29:26,003] {logging_mixin.py:104} INFO - [2021-04-23 15:29:26,003] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:29:26,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.482 seconds
[2021-04-23 15:29:56,110] {scheduler_job.py:182} INFO - Started process (PID=418) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:29:56,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:29:56,117] {logging_mixin.py:104} INFO - [2021-04-23 15:29:56,117] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:29:56,768] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:29:56,829] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:29:56,870] {logging_mixin.py:104} INFO - [2021-04-23 15:29:56,866] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:29:56,921] {logging_mixin.py:104} INFO - [2021-04-23 15:29:56,921] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:29:56,937] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.835 seconds
[2021-04-23 15:30:27,095] {scheduler_job.py:182} INFO - Started process (PID=420) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:30:27,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:30:27,099] {logging_mixin.py:104} INFO - [2021-04-23 15:30:27,099] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:30:27,514] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:30:27,541] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:30:27,553] {logging_mixin.py:104} INFO - [2021-04-23 15:30:27,552] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:30:27,570] {logging_mixin.py:104} INFO - [2021-04-23 15:30:27,570] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:30:27,579] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.488 seconds
[2021-04-23 15:30:57,702] {scheduler_job.py:182} INFO - Started process (PID=422) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:30:57,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:30:57,707] {logging_mixin.py:104} INFO - [2021-04-23 15:30:57,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:30:58,151] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:30:58,169] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:30:58,180] {logging_mixin.py:104} INFO - [2021-04-23 15:30:58,178] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:30:58,200] {logging_mixin.py:104} INFO - [2021-04-23 15:30:58,200] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:30:58,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.513 seconds
[2021-04-23 15:31:31,243] {scheduler_job.py:182} INFO - Started process (PID=424) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:31:31,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:31:31,356] {logging_mixin.py:104} INFO - [2021-04-23 15:31:31,355] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:31:44,831] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:31:45,900] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:31:46,295] {logging_mixin.py:104} INFO - [2021-04-23 15:31:46,225] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:31:47,902] {logging_mixin.py:104} INFO - [2021-04-23 15:31:47,900] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:31:48,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 17.096 seconds
[2021-04-23 15:32:20,227] {scheduler_job.py:182} INFO - Started process (PID=426) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:32:20,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:32:20,239] {logging_mixin.py:104} INFO - [2021-04-23 15:32:20,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:32:21,309] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:32:21,360] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:32:21,405] {logging_mixin.py:104} INFO - [2021-04-23 15:32:21,400] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:32:21,442] {logging_mixin.py:104} INFO - [2021-04-23 15:32:21,442] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:32:21,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.258 seconds
[2021-04-23 15:32:52,005] {scheduler_job.py:182} INFO - Started process (PID=428) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:32:52,010] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:32:52,012] {logging_mixin.py:104} INFO - [2021-04-23 15:32:52,012] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:32:52,802] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:32:52,829] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:32:52,845] {logging_mixin.py:104} INFO - [2021-04-23 15:32:52,844] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:32:52,871] {logging_mixin.py:104} INFO - [2021-04-23 15:32:52,871] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:32:52,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.884 seconds
[2021-04-23 15:33:23,036] {scheduler_job.py:182} INFO - Started process (PID=430) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:33:23,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:33:23,047] {logging_mixin.py:104} INFO - [2021-04-23 15:33:23,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:33:23,684] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:33:23,709] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:33:23,733] {logging_mixin.py:104} INFO - [2021-04-23 15:33:23,731] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:33:23,765] {logging_mixin.py:104} INFO - [2021-04-23 15:33:23,765] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:33:23,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.755 seconds
[2021-04-23 15:33:54,008] {scheduler_job.py:182} INFO - Started process (PID=432) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:33:54,011] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:33:54,015] {logging_mixin.py:104} INFO - [2021-04-23 15:33:54,014] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:33:54,518] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:33:54,541] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:33:54,553] {logging_mixin.py:104} INFO - [2021-04-23 15:33:54,552] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:33:54,583] {logging_mixin.py:104} INFO - [2021-04-23 15:33:54,582] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:33:54,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.596 seconds
[2021-04-23 15:34:24,740] {scheduler_job.py:182} INFO - Started process (PID=434) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:34:24,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:34:24,748] {logging_mixin.py:104} INFO - [2021-04-23 15:34:24,748] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:34:25,292] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:34:25,311] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:34:25,324] {logging_mixin.py:104} INFO - [2021-04-23 15:34:25,321] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:34:25,349] {logging_mixin.py:104} INFO - [2021-04-23 15:34:25,348] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:34:25,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.630 seconds
[2021-04-23 15:34:55,507] {scheduler_job.py:182} INFO - Started process (PID=436) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:34:55,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:34:55,513] {logging_mixin.py:104} INFO - [2021-04-23 15:34:55,513] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:34:55,908] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:34:55,922] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:34:55,937] {logging_mixin.py:104} INFO - [2021-04-23 15:34:55,936] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:34:55,960] {logging_mixin.py:104} INFO - [2021-04-23 15:34:55,959] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:34:55,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.469 seconds
[2021-04-23 15:35:26,138] {scheduler_job.py:182} INFO - Started process (PID=438) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:35:26,143] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:35:26,146] {logging_mixin.py:104} INFO - [2021-04-23 15:35:26,146] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:35:26,939] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:35:26,965] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:35:26,982] {logging_mixin.py:104} INFO - [2021-04-23 15:35:26,981] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:35:27,014] {logging_mixin.py:104} INFO - [2021-04-23 15:35:27,014] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:35:27,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.915 seconds
[2021-04-23 15:35:57,139] {scheduler_job.py:182} INFO - Started process (PID=440) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:35:57,145] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:35:57,147] {logging_mixin.py:104} INFO - [2021-04-23 15:35:57,147] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:35:57,968] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:35:57,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:35:58,021] {logging_mixin.py:104} INFO - [2021-04-23 15:35:58,019] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:35:58,059] {logging_mixin.py:104} INFO - [2021-04-23 15:35:58,059] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:35:58,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.948 seconds
[2021-04-23 15:36:28,273] {scheduler_job.py:182} INFO - Started process (PID=442) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:36:28,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:36:28,278] {logging_mixin.py:104} INFO - [2021-04-23 15:36:28,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:36:28,885] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:36:28,907] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:36:28,919] {logging_mixin.py:104} INFO - [2021-04-23 15:36:28,918] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:36:28,943] {logging_mixin.py:104} INFO - [2021-04-23 15:36:28,943] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:36:28,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.692 seconds
[2021-04-23 15:36:59,174] {scheduler_job.py:182} INFO - Started process (PID=444) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:36:59,178] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:36:59,181] {logging_mixin.py:104} INFO - [2021-04-23 15:36:59,181] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:36:59,911] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:36:59,940] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:36:59,963] {logging_mixin.py:104} INFO - [2021-04-23 15:36:59,961] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:36:59,996] {logging_mixin.py:104} INFO - [2021-04-23 15:36:59,996] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:37:00,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.881 seconds
[2021-04-23 15:37:30,164] {scheduler_job.py:182} INFO - Started process (PID=446) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:37:30,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:37:30,173] {logging_mixin.py:104} INFO - [2021-04-23 15:37:30,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:37:30,642] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:37:30,674] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:37:30,690] {logging_mixin.py:104} INFO - [2021-04-23 15:37:30,688] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:37:30,711] {logging_mixin.py:104} INFO - [2021-04-23 15:37:30,711] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:37:30,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.578 seconds
[2021-04-23 15:38:00,903] {scheduler_job.py:182} INFO - Started process (PID=448) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:38:00,910] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:38:00,917] {logging_mixin.py:104} INFO - [2021-04-23 15:38:00,916] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:38:01,604] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:38:01,629] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:38:01,646] {logging_mixin.py:104} INFO - [2021-04-23 15:38:01,645] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:38:01,675] {logging_mixin.py:104} INFO - [2021-04-23 15:38:01,675] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:38:01,688] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-23 15:38:32,408] {scheduler_job.py:182} INFO - Started process (PID=450) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:38:32,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:38:32,417] {logging_mixin.py:104} INFO - [2021-04-23 15:38:32,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:38:33,005] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:38:33,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:38:33,068] {logging_mixin.py:104} INFO - [2021-04-23 15:38:33,066] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:38:33,101] {logging_mixin.py:104} INFO - [2021-04-23 15:38:33,101] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:38:33,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.729 seconds
[2021-04-23 15:39:03,301] {scheduler_job.py:182} INFO - Started process (PID=452) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:39:03,303] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:39:03,305] {logging_mixin.py:104} INFO - [2021-04-23 15:39:03,305] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:39:03,863] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:39:03,890] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:39:03,909] {logging_mixin.py:104} INFO - [2021-04-23 15:39:03,908] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:39:03,951] {logging_mixin.py:104} INFO - [2021-04-23 15:39:03,951] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:39:03,967] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.671 seconds
[2021-04-23 15:39:34,081] {scheduler_job.py:182} INFO - Started process (PID=454) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:39:34,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:39:34,086] {logging_mixin.py:104} INFO - [2021-04-23 15:39:34,086] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:39:34,724] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:39:34,745] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:39:34,763] {logging_mixin.py:104} INFO - [2021-04-23 15:39:34,761] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:39:34,791] {logging_mixin.py:104} INFO - [2021-04-23 15:39:34,791] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:39:34,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.725 seconds
[2021-04-23 15:40:04,945] {scheduler_job.py:182} INFO - Started process (PID=456) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:40:04,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:40:04,955] {logging_mixin.py:104} INFO - [2021-04-23 15:40:04,955] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:40:05,672] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 15:40:05,694] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:40:05,708] {logging_mixin.py:104} INFO - [2021-04-23 15:40:05,707] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 15:40:05,743] {logging_mixin.py:104} INFO - [2021-04-23 15:40:05,743] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 15:40:05,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.819 seconds
[2021-04-23 15:40:40,128] {scheduler_job.py:182} INFO - Started process (PID=458) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:40:40,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 15:40:40,216] {logging_mixin.py:104} INFO - [2021-04-23 15:40:40,215] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 15:40:47,512] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:02:03,276] {scheduler_job.py:182} INFO - Started process (PID=23) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:02:03,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:02:03,301] {logging_mixin.py:104} INFO - [2021-04-23 16:02:03,301] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:02:08,608] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:02:08,714] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:02:08,752] {logging_mixin.py:104} INFO - [2021-04-23 16:02:08,751] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:02:08,886] {logging_mixin.py:104} INFO - [2021-04-23 16:02:08,886] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:02:08,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 5.726 seconds
[2021-04-23 16:02:39,533] {scheduler_job.py:182} INFO - Started process (PID=25) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:02:39,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:02:39,546] {logging_mixin.py:104} INFO - [2021-04-23 16:02:39,545] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:02:58,041] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:02:58,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:02:58,213] {logging_mixin.py:104} INFO - [2021-04-23 16:02:58,211] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:02:58,277] {logging_mixin.py:104} INFO - [2021-04-23 16:02:58,277] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:02:58,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 18.792 seconds
[2021-04-23 16:03:29,201] {scheduler_job.py:182} INFO - Started process (PID=27) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:03:29,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:03:29,213] {logging_mixin.py:104} INFO - [2021-04-23 16:03:29,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:03:30,574] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:03:30,604] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:03:30,628] {logging_mixin.py:104} INFO - [2021-04-23 16:03:30,625] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:03:30,665] {logging_mixin.py:104} INFO - [2021-04-23 16:03:30,665] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:03:30,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.499 seconds
[2021-04-23 16:04:00,970] {scheduler_job.py:182} INFO - Started process (PID=29) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:04:00,977] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:04:00,983] {logging_mixin.py:104} INFO - [2021-04-23 16:04:00,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:04:02,464] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:04:02,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:04:02,536] {logging_mixin.py:104} INFO - [2021-04-23 16:04:02,535] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:04:02,568] {logging_mixin.py:104} INFO - [2021-04-23 16:04:02,568] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:04:02,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.615 seconds
[2021-04-23 16:04:32,701] {scheduler_job.py:182} INFO - Started process (PID=31) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:04:32,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:04:32,707] {logging_mixin.py:104} INFO - [2021-04-23 16:04:32,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:04:33,684] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:04:33,775] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:04:33,812] {logging_mixin.py:104} INFO - [2021-04-23 16:04:33,809] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:04:33,868] {logging_mixin.py:104} INFO - [2021-04-23 16:04:33,868] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:04:33,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.227 seconds
[2021-04-23 16:05:04,085] {scheduler_job.py:182} INFO - Started process (PID=33) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:05:04,089] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:05:04,091] {logging_mixin.py:104} INFO - [2021-04-23 16:05:04,091] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:05:04,783] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:05:04,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:05:04,825] {logging_mixin.py:104} INFO - [2021-04-23 16:05:04,824] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:05:04,841] {logging_mixin.py:104} INFO - [2021-04-23 16:05:04,841] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:05:04,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.784 seconds
[2021-04-23 16:05:35,047] {scheduler_job.py:182} INFO - Started process (PID=35) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:05:35,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:05:35,052] {logging_mixin.py:104} INFO - [2021-04-23 16:05:35,052] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:05:36,050] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:05:36,163] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:05:36,234] {logging_mixin.py:104} INFO - [2021-04-23 16:05:36,233] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:05:36,276] {logging_mixin.py:104} INFO - [2021-04-23 16:05:36,276] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:05:36,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.264 seconds
[2021-04-23 16:06:06,385] {scheduler_job.py:182} INFO - Started process (PID=36) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:06:06,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:06:06,390] {logging_mixin.py:104} INFO - [2021-04-23 16:06:06,390] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:06:07,192] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:06:07,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:06:07,237] {logging_mixin.py:104} INFO - [2021-04-23 16:06:07,236] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:06:07,254] {logging_mixin.py:104} INFO - [2021-04-23 16:06:07,254] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:06:07,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.884 seconds
[2021-04-23 16:06:37,488] {scheduler_job.py:182} INFO - Started process (PID=38) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:06:37,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:06:37,493] {logging_mixin.py:104} INFO - [2021-04-23 16:06:37,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:06:38,238] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:06:38,269] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:06:38,281] {logging_mixin.py:104} INFO - [2021-04-23 16:06:38,280] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:06:38,300] {logging_mixin.py:104} INFO - [2021-04-23 16:06:38,300] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:06:38,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.831 seconds
[2021-04-23 16:07:08,374] {scheduler_job.py:182} INFO - Started process (PID=40) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:07:08,378] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:07:08,381] {logging_mixin.py:104} INFO - [2021-04-23 16:07:08,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:07:09,002] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:07:09,024] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:07:09,034] {logging_mixin.py:104} INFO - [2021-04-23 16:07:09,033] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:07:09,051] {logging_mixin.py:104} INFO - [2021-04-23 16:07:09,051] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:07:09,059] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.727 seconds
[2021-04-23 16:07:39,776] {scheduler_job.py:182} INFO - Started process (PID=42) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:07:39,780] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:07:39,781] {logging_mixin.py:104} INFO - [2021-04-23 16:07:39,781] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:07:40,579] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:07:40,645] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:07:40,674] {logging_mixin.py:104} INFO - [2021-04-23 16:07:40,673] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:07:40,700] {logging_mixin.py:104} INFO - [2021-04-23 16:07:40,700] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:07:40,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.939 seconds
[2021-04-23 16:08:10,886] {scheduler_job.py:182} INFO - Started process (PID=44) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:08:10,890] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:08:10,893] {logging_mixin.py:104} INFO - [2021-04-23 16:08:10,893] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:08:11,679] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:08:11,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:08:11,713] {logging_mixin.py:104} INFO - [2021-04-23 16:08:11,712] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:08:11,730] {logging_mixin.py:104} INFO - [2021-04-23 16:08:11,730] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:08:11,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.855 seconds
[2021-04-23 16:08:42,026] {scheduler_job.py:182} INFO - Started process (PID=46) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:08:42,028] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:08:42,031] {logging_mixin.py:104} INFO - [2021-04-23 16:08:42,030] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:08:42,792] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:08:42,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:08:42,832] {logging_mixin.py:104} INFO - [2021-04-23 16:08:42,830] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:08:42,852] {logging_mixin.py:104} INFO - [2021-04-23 16:08:42,852] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:08:42,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.841 seconds
[2021-04-23 16:09:12,932] {scheduler_job.py:182} INFO - Started process (PID=48) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:09:12,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:09:12,937] {logging_mixin.py:104} INFO - [2021-04-23 16:09:12,937] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:09:13,745] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:09:13,791] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:09:13,811] {logging_mixin.py:104} INFO - [2021-04-23 16:09:13,810] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:09:13,852] {logging_mixin.py:104} INFO - [2021-04-23 16:09:13,851] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:09:13,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.945 seconds
[2021-04-23 16:09:43,957] {scheduler_job.py:182} INFO - Started process (PID=50) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:09:43,966] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:09:43,970] {logging_mixin.py:104} INFO - [2021-04-23 16:09:43,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:09:44,692] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:09:44,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:09:44,774] {logging_mixin.py:104} INFO - [2021-04-23 16:09:44,769] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:09:44,848] {logging_mixin.py:104} INFO - [2021-04-23 16:09:44,848] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:09:44,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.921 seconds
[2021-04-23 16:10:15,230] {scheduler_job.py:182} INFO - Started process (PID=52) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:10:15,232] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:10:15,234] {logging_mixin.py:104} INFO - [2021-04-23 16:10:15,234] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:10:15,842] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:10:15,868] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:10:15,879] {logging_mixin.py:104} INFO - [2021-04-23 16:10:15,878] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:10:15,900] {logging_mixin.py:104} INFO - [2021-04-23 16:10:15,900] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:10:15,908] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.681 seconds
[2021-04-23 16:10:46,482] {scheduler_job.py:182} INFO - Started process (PID=54) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:10:46,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:10:46,555] {logging_mixin.py:104} INFO - [2021-04-23 16:10:46,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:10:47,812] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:10:47,848] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:10:47,864] {logging_mixin.py:104} INFO - [2021-04-23 16:10:47,863] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:10:47,894] {logging_mixin.py:104} INFO - [2021-04-23 16:10:47,894] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:10:47,910] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.442 seconds
[2021-04-23 16:11:18,640] {scheduler_job.py:182} INFO - Started process (PID=56) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:11:18,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:11:18,644] {logging_mixin.py:104} INFO - [2021-04-23 16:11:18,644] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:11:20,185] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:11:20,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:11:20,241] {logging_mixin.py:104} INFO - [2021-04-23 16:11:20,239] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:11:20,271] {logging_mixin.py:104} INFO - [2021-04-23 16:11:20,271] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:11:20,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.651 seconds
[2021-04-23 16:11:50,820] {scheduler_job.py:182} INFO - Started process (PID=58) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:11:50,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:11:50,825] {logging_mixin.py:104} INFO - [2021-04-23 16:11:50,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:11:51,717] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:11:51,743] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:11:51,765] {logging_mixin.py:104} INFO - [2021-04-23 16:11:51,761] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:11:51,790] {logging_mixin.py:104} INFO - [2021-04-23 16:11:51,790] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:11:51,799] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.984 seconds
[2021-04-23 16:12:21,971] {scheduler_job.py:182} INFO - Started process (PID=60) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:12:21,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:12:21,980] {logging_mixin.py:104} INFO - [2021-04-23 16:12:21,979] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:12:22,929] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:12:22,957] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:12:22,978] {logging_mixin.py:104} INFO - [2021-04-23 16:12:22,976] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:12:23,007] {logging_mixin.py:104} INFO - [2021-04-23 16:12:23,007] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:12:23,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.062 seconds
[2021-04-23 16:12:53,111] {scheduler_job.py:182} INFO - Started process (PID=62) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:12:53,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:12:53,115] {logging_mixin.py:104} INFO - [2021-04-23 16:12:53,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:12:53,781] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:12:53,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:12:53,830] {logging_mixin.py:104} INFO - [2021-04-23 16:12:53,829] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:12:53,850] {logging_mixin.py:104} INFO - [2021-04-23 16:12:53,849] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:12:53,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.751 seconds
[2021-04-23 16:13:23,977] {scheduler_job.py:182} INFO - Started process (PID=64) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:13:23,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:13:23,982] {logging_mixin.py:104} INFO - [2021-04-23 16:13:23,981] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:13:24,824] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:13:24,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:13:24,856] {logging_mixin.py:104} INFO - [2021-04-23 16:13:24,855] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:13:24,872] {logging_mixin.py:104} INFO - [2021-04-23 16:13:24,872] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:13:24,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.909 seconds
[2021-04-23 16:13:55,370] {scheduler_job.py:182} INFO - Started process (PID=66) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:13:55,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:13:55,395] {logging_mixin.py:104} INFO - [2021-04-23 16:13:55,395] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:13:56,565] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:13:56,605] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:13:56,621] {logging_mixin.py:104} INFO - [2021-04-23 16:13:56,620] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:13:56,641] {logging_mixin.py:104} INFO - [2021-04-23 16:13:56,640] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:13:56,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.296 seconds
[2021-04-23 16:14:27,480] {scheduler_job.py:182} INFO - Started process (PID=68) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:14:27,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:14:27,486] {logging_mixin.py:104} INFO - [2021-04-23 16:14:27,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:14:28,694] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:14:28,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:14:28,750] {logging_mixin.py:104} INFO - [2021-04-23 16:14:28,748] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:14:28,776] {logging_mixin.py:104} INFO - [2021-04-23 16:14:28,776] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:14:28,787] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.313 seconds
[2021-04-23 16:14:58,950] {scheduler_job.py:182} INFO - Started process (PID=70) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:14:58,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:14:58,960] {logging_mixin.py:104} INFO - [2021-04-23 16:14:58,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:14:59,707] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:14:59,729] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:14:59,748] {logging_mixin.py:104} INFO - [2021-04-23 16:14:59,746] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:14:59,773] {logging_mixin.py:104} INFO - [2021-04-23 16:14:59,773] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:14:59,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.841 seconds
[2021-04-23 16:15:30,008] {scheduler_job.py:182} INFO - Started process (PID=72) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:15:30,012] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:15:30,014] {logging_mixin.py:104} INFO - [2021-04-23 16:15:30,014] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:15:31,201] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:15:31,257] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:15:31,276] {logging_mixin.py:104} INFO - [2021-04-23 16:15:31,274] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:15:31,301] {logging_mixin.py:104} INFO - [2021-04-23 16:15:31,301] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T14:00:00+00:00
[2021-04-23 16:15:31,314] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.314 seconds
[2021-04-23 16:16:01,046] {scheduler_job.py:182} INFO - Started process (PID=74) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:16:01,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:16:01,057] {logging_mixin.py:104} INFO - [2021-04-23 16:16:01,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:16:02,188] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:16:02,213] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:16:02,230] {logging_mixin.py:104} INFO - [2021-04-23 16:16:02,229] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:16:02,246] {logging_mixin.py:104} INFO - [2021-04-23 16:16:02,246] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:16:02,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.219 seconds
[2021-04-23 16:16:32,341] {scheduler_job.py:182} INFO - Started process (PID=76) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:16:32,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:16:32,348] {logging_mixin.py:104} INFO - [2021-04-23 16:16:32,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:16:33,036] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:16:33,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:16:33,095] {logging_mixin.py:104} INFO - [2021-04-23 16:16:33,092] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:16:33,126] {logging_mixin.py:104} INFO - [2021-04-23 16:16:33,126] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:16:33,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.801 seconds
[2021-04-23 16:17:03,328] {scheduler_job.py:182} INFO - Started process (PID=78) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:17:03,331] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:17:03,333] {logging_mixin.py:104} INFO - [2021-04-23 16:17:03,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:17:04,198] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:17:04,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:17:04,237] {logging_mixin.py:104} INFO - [2021-04-23 16:17:04,236] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:17:04,255] {logging_mixin.py:104} INFO - [2021-04-23 16:17:04,255] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:17:04,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.941 seconds
[2021-04-23 16:17:34,406] {scheduler_job.py:182} INFO - Started process (PID=80) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:17:34,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:17:34,411] {logging_mixin.py:104} INFO - [2021-04-23 16:17:34,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:17:35,644] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:17:35,726] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:17:35,766] {logging_mixin.py:104} INFO - [2021-04-23 16:17:35,764] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:17:35,826] {logging_mixin.py:104} INFO - [2021-04-23 16:17:35,826] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:17:35,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.453 seconds
[2021-04-23 16:18:08,390] {scheduler_job.py:182} INFO - Started process (PID=83) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:18:08,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:18:08,422] {logging_mixin.py:104} INFO - [2021-04-23 16:18:08,421] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:18:11,492] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:18:11,532] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:18:11,564] {logging_mixin.py:104} INFO - [2021-04-23 16:18:11,563] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:18:11,602] {logging_mixin.py:104} INFO - [2021-04-23 16:18:11,602] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:18:11,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.432 seconds
[2021-04-23 16:18:41,796] {scheduler_job.py:182} INFO - Started process (PID=85) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:18:41,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:18:41,805] {logging_mixin.py:104} INFO - [2021-04-23 16:18:41,805] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:18:42,835] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:18:42,864] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:18:42,888] {logging_mixin.py:104} INFO - [2021-04-23 16:18:42,886] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:18:42,924] {logging_mixin.py:104} INFO - [2021-04-23 16:18:42,924] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:18:42,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.174 seconds
[2021-04-23 16:19:13,087] {scheduler_job.py:182} INFO - Started process (PID=87) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:19:13,092] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:19:13,097] {logging_mixin.py:104} INFO - [2021-04-23 16:19:13,097] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:19:13,980] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:19:14,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:19:14,023] {logging_mixin.py:104} INFO - [2021-04-23 16:19:14,022] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:19:14,039] {logging_mixin.py:104} INFO - [2021-04-23 16:19:14,039] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:19:14,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.964 seconds
[2021-04-23 16:19:44,181] {scheduler_job.py:182} INFO - Started process (PID=89) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:19:44,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:19:44,191] {logging_mixin.py:104} INFO - [2021-04-23 16:19:44,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:19:45,091] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:19:45,112] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:19:45,125] {logging_mixin.py:104} INFO - [2021-04-23 16:19:45,124] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:19:45,141] {logging_mixin.py:104} INFO - [2021-04-23 16:19:45,141] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:19:45,149] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.972 seconds
[2021-04-23 16:20:15,248] {scheduler_job.py:182} INFO - Started process (PID=91) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:20:15,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:20:15,253] {logging_mixin.py:104} INFO - [2021-04-23 16:20:15,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:20:16,131] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:20:16,154] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:20:16,165] {logging_mixin.py:104} INFO - [2021-04-23 16:20:16,164] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:20:16,182] {logging_mixin.py:104} INFO - [2021-04-23 16:20:16,182] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:20:16,192] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.948 seconds
[2021-04-23 16:20:46,261] {scheduler_job.py:182} INFO - Started process (PID=93) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:20:46,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:20:46,265] {logging_mixin.py:104} INFO - [2021-04-23 16:20:46,264] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:20:47,035] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:20:47,054] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:20:47,065] {logging_mixin.py:104} INFO - [2021-04-23 16:20:47,064] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:20:47,082] {logging_mixin.py:104} INFO - [2021-04-23 16:20:47,082] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:20:47,091] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.834 seconds
[2021-04-23 16:21:17,161] {scheduler_job.py:182} INFO - Started process (PID=95) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:21:17,165] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:21:17,167] {logging_mixin.py:104} INFO - [2021-04-23 16:21:17,166] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:21:18,120] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:21:18,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:21:18,161] {logging_mixin.py:104} INFO - [2021-04-23 16:21:18,160] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:21:18,181] {logging_mixin.py:104} INFO - [2021-04-23 16:21:18,181] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:21:18,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.034 seconds
[2021-04-23 16:21:48,991] {scheduler_job.py:182} INFO - Started process (PID=97) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:21:49,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:21:49,026] {logging_mixin.py:104} INFO - [2021-04-23 16:21:49,026] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:21:50,852] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:21:50,893] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:21:50,921] {logging_mixin.py:104} INFO - [2021-04-23 16:21:50,918] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:21:50,970] {logging_mixin.py:104} INFO - [2021-04-23 16:21:50,969] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:21:50,995] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.063 seconds
[2021-04-23 16:22:21,297] {scheduler_job.py:182} INFO - Started process (PID=99) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:22:21,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:22:21,304] {logging_mixin.py:104} INFO - [2021-04-23 16:22:21,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:22:21,980] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:22:21,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:22:22,012] {logging_mixin.py:104} INFO - [2021-04-23 16:22:22,011] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:22:22,029] {logging_mixin.py:104} INFO - [2021-04-23 16:22:22,029] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:22:22,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.746 seconds
[2021-04-23 16:22:52,159] {scheduler_job.py:182} INFO - Started process (PID=101) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:22:52,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:22:52,164] {logging_mixin.py:104} INFO - [2021-04-23 16:22:52,164] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:22:52,960] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:22:52,981] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:22:52,993] {logging_mixin.py:104} INFO - [2021-04-23 16:22:52,992] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:22:53,015] {logging_mixin.py:104} INFO - [2021-04-23 16:22:53,015] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:22:53,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.870 seconds
[2021-04-23 16:23:23,093] {scheduler_job.py:182} INFO - Started process (PID=103) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:23:23,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:23:23,101] {logging_mixin.py:104} INFO - [2021-04-23 16:23:23,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:23:23,743] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:23:23,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:23:23,789] {logging_mixin.py:104} INFO - [2021-04-23 16:23:23,788] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:23:23,811] {logging_mixin.py:104} INFO - [2021-04-23 16:23:23,810] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:23:23,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.732 seconds
[2021-04-23 16:23:53,945] {scheduler_job.py:182} INFO - Started process (PID=105) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:23:53,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:23:53,950] {logging_mixin.py:104} INFO - [2021-04-23 16:23:53,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:23:54,603] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:23:54,667] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:23:54,693] {logging_mixin.py:104} INFO - [2021-04-23 16:23:54,691] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:23:54,735] {logging_mixin.py:104} INFO - [2021-04-23 16:23:54,735] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:23:54,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.816 seconds
[2021-04-23 16:24:24,887] {scheduler_job.py:182} INFO - Started process (PID=106) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:24:24,890] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:24:24,892] {logging_mixin.py:104} INFO - [2021-04-23 16:24:24,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:24:25,684] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:24:25,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:24:25,729] {logging_mixin.py:104} INFO - [2021-04-23 16:24:25,727] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:24:25,748] {logging_mixin.py:104} INFO - [2021-04-23 16:24:25,748] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:24:25,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.875 seconds
[2021-04-23 16:24:55,897] {scheduler_job.py:182} INFO - Started process (PID=109) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:24:55,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:24:55,902] {logging_mixin.py:104} INFO - [2021-04-23 16:24:55,902] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:24:56,640] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:24:56,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:24:56,676] {logging_mixin.py:104} INFO - [2021-04-23 16:24:56,674] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:24:56,696] {logging_mixin.py:104} INFO - [2021-04-23 16:24:56,696] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:24:56,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.816 seconds
[2021-04-23 16:25:26,845] {scheduler_job.py:182} INFO - Started process (PID=111) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:25:26,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:25:26,853] {logging_mixin.py:104} INFO - [2021-04-23 16:25:26,852] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:25:28,044] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:25:28,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:25:28,096] {logging_mixin.py:104} INFO - [2021-04-23 16:25:28,095] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:25:28,119] {logging_mixin.py:104} INFO - [2021-04-23 16:25:28,119] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:25:28,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.289 seconds
[2021-04-23 16:25:58,385] {scheduler_job.py:182} INFO - Started process (PID=113) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:25:58,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:25:58,395] {logging_mixin.py:104} INFO - [2021-04-23 16:25:58,395] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:26:01,195] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:26:01,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:26:01,257] {logging_mixin.py:104} INFO - [2021-04-23 16:26:01,255] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:26:01,305] {logging_mixin.py:104} INFO - [2021-04-23 16:26:01,304] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:26:01,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.947 seconds
[2021-04-23 16:26:31,600] {scheduler_job.py:182} INFO - Started process (PID=115) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:26:31,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:26:31,605] {logging_mixin.py:104} INFO - [2021-04-23 16:26:31,605] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:26:32,449] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:26:32,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:26:32,486] {logging_mixin.py:104} INFO - [2021-04-23 16:26:32,485] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:26:32,503] {logging_mixin.py:104} INFO - [2021-04-23 16:26:32,503] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:26:32,524] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.928 seconds
[2021-04-23 16:27:02,621] {scheduler_job.py:182} INFO - Started process (PID=117) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:27:02,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:27:02,627] {logging_mixin.py:104} INFO - [2021-04-23 16:27:02,627] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:27:03,304] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:27:03,328] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:27:03,344] {logging_mixin.py:104} INFO - [2021-04-23 16:27:03,342] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:27:03,369] {logging_mixin.py:104} INFO - [2021-04-23 16:27:03,369] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:27:03,377] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.760 seconds
[2021-04-23 16:27:33,558] {scheduler_job.py:182} INFO - Started process (PID=119) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:27:33,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:27:33,568] {logging_mixin.py:104} INFO - [2021-04-23 16:27:33,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:27:34,238] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:27:34,258] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:27:34,270] {logging_mixin.py:104} INFO - [2021-04-23 16:27:34,269] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:27:34,286] {logging_mixin.py:104} INFO - [2021-04-23 16:27:34,286] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:27:34,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.748 seconds
[2021-04-23 16:28:04,464] {scheduler_job.py:182} INFO - Started process (PID=121) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:28:04,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:28:04,472] {logging_mixin.py:104} INFO - [2021-04-23 16:28:04,472] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:28:05,423] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:28:05,466] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:28:05,495] {logging_mixin.py:104} INFO - [2021-04-23 16:28:05,493] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:28:05,526] {logging_mixin.py:104} INFO - [2021-04-23 16:28:05,526] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:28:05,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.080 seconds
[2021-04-23 16:28:35,643] {scheduler_job.py:182} INFO - Started process (PID=123) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:28:35,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:28:35,656] {logging_mixin.py:104} INFO - [2021-04-23 16:28:35,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:28:36,742] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:28:36,770] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:28:36,783] {logging_mixin.py:104} INFO - [2021-04-23 16:28:36,782] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:28:36,803] {logging_mixin.py:104} INFO - [2021-04-23 16:28:36,803] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:28:36,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.175 seconds
[2021-04-23 16:29:06,864] {scheduler_job.py:182} INFO - Started process (PID=125) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:29:06,866] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:29:06,867] {logging_mixin.py:104} INFO - [2021-04-23 16:29:06,867] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:29:07,633] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:29:07,682] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:29:07,702] {logging_mixin.py:104} INFO - [2021-04-23 16:29:07,701] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:29:07,727] {logging_mixin.py:104} INFO - [2021-04-23 16:29:07,727] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:29:07,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.913 seconds
[2021-04-23 16:29:37,847] {scheduler_job.py:182} INFO - Started process (PID=127) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:29:37,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:29:37,854] {logging_mixin.py:104} INFO - [2021-04-23 16:29:37,854] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:29:38,955] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:29:38,986] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:29:39,009] {logging_mixin.py:104} INFO - [2021-04-23 16:29:39,008] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:29:39,039] {logging_mixin.py:104} INFO - [2021-04-23 16:29:39,038] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:29:39,051] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.212 seconds
[2021-04-23 16:30:09,146] {scheduler_job.py:182} INFO - Started process (PID=129) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:30:09,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:30:09,152] {logging_mixin.py:104} INFO - [2021-04-23 16:30:09,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:30:10,420] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:30:10,492] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:30:10,522] {logging_mixin.py:104} INFO - [2021-04-23 16:30:10,520] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:30:10,566] {logging_mixin.py:104} INFO - [2021-04-23 16:30:10,566] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:30:10,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.453 seconds
[2021-04-23 16:30:40,788] {scheduler_job.py:182} INFO - Started process (PID=131) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:30:40,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:30:40,806] {logging_mixin.py:104} INFO - [2021-04-23 16:30:40,805] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:30:42,341] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:30:42,367] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:30:42,393] {logging_mixin.py:104} INFO - [2021-04-23 16:30:42,390] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:30:42,428] {logging_mixin.py:104} INFO - [2021-04-23 16:30:42,428] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:30:42,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.680 seconds
[2021-04-23 16:31:12,603] {scheduler_job.py:182} INFO - Started process (PID=133) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:31:12,605] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:31:12,608] {logging_mixin.py:104} INFO - [2021-04-23 16:31:12,608] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:31:13,664] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:31:13,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:31:13,740] {logging_mixin.py:104} INFO - [2021-04-23 16:31:13,739] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:31:13,775] {logging_mixin.py:104} INFO - [2021-04-23 16:31:13,774] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:31:13,789] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.190 seconds
[2021-04-23 16:31:43,880] {scheduler_job.py:182} INFO - Started process (PID=135) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:31:43,885] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:31:43,889] {logging_mixin.py:104} INFO - [2021-04-23 16:31:43,888] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:31:44,823] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:31:44,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:31:44,883] {logging_mixin.py:104} INFO - [2021-04-23 16:31:44,882] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:31:44,911] {logging_mixin.py:104} INFO - [2021-04-23 16:31:44,911] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:31:44,932] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.057 seconds
[2021-04-23 16:32:15,178] {scheduler_job.py:182} INFO - Started process (PID=137) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:32:15,181] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:32:15,182] {logging_mixin.py:104} INFO - [2021-04-23 16:32:15,182] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:32:15,907] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:32:15,959] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:32:15,976] {logging_mixin.py:104} INFO - [2021-04-23 16:32:15,974] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:32:16,012] {logging_mixin.py:104} INFO - [2021-04-23 16:32:16,011] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:32:16,021] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.846 seconds
[2021-04-23 16:32:46,150] {scheduler_job.py:182} INFO - Started process (PID=139) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:32:46,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:32:46,156] {logging_mixin.py:104} INFO - [2021-04-23 16:32:46,156] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:32:46,882] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:32:46,904] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:32:46,916] {logging_mixin.py:104} INFO - [2021-04-23 16:32:46,916] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:32:46,934] {logging_mixin.py:104} INFO - [2021-04-23 16:32:46,934] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:32:46,943] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.797 seconds
[2021-04-23 16:33:17,190] {scheduler_job.py:182} INFO - Started process (PID=141) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:33:17,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:33:17,255] {logging_mixin.py:104} INFO - [2021-04-23 16:33:17,255] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:33:18,416] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:33:18,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:33:18,496] {logging_mixin.py:104} INFO - [2021-04-23 16:33:18,492] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:33:18,524] {logging_mixin.py:104} INFO - [2021-04-23 16:33:18,524] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:33:18,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.361 seconds
[2021-04-23 16:33:36,460] {scheduler_job.py:182} INFO - Started process (PID=142) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:33:36,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:33:36,468] {logging_mixin.py:104} INFO - [2021-04-23 16:33:36,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:33:37,205] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:33:37,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:33:37,240] {logging_mixin.py:104} INFO - [2021-04-23 16:33:37,239] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:33:37,264] {logging_mixin.py:104} INFO - [2021-04-23 16:33:37,264] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:33:37,272] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.853 seconds
[2021-04-23 16:34:02,782] {scheduler_job.py:182} INFO - Started process (PID=144) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:34:02,785] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:34:02,786] {logging_mixin.py:104} INFO - [2021-04-23 16:34:02,786] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:34:03,458] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:34:03,480] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:34:03,502] {logging_mixin.py:104} INFO - [2021-04-23 16:34:03,501] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:34:03,518] {logging_mixin.py:104} INFO - [2021-04-23 16:34:03,518] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:34:03,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.749 seconds
[2021-04-23 16:34:33,845] {scheduler_job.py:182} INFO - Started process (PID=146) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:34:33,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:34:33,853] {logging_mixin.py:104} INFO - [2021-04-23 16:34:33,852] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:34:34,520] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:34:34,550] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:34:34,573] {logging_mixin.py:104} INFO - [2021-04-23 16:34:34,572] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:34:34,594] {logging_mixin.py:104} INFO - [2021-04-23 16:34:34,594] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:34:34,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.783 seconds
[2021-04-23 16:35:04,710] {scheduler_job.py:182} INFO - Started process (PID=148) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:35:04,712] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:35:04,714] {logging_mixin.py:104} INFO - [2021-04-23 16:35:04,714] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:35:05,380] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:35:05,399] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:35:05,412] {logging_mixin.py:104} INFO - [2021-04-23 16:35:05,411] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:35:05,422] {logging_mixin.py:104} INFO - [2021-04-23 16:35:05,421] {dag.py:1837} INFO - Creating ORM DAG for recent_played_ingestion
[2021-04-23 16:35:05,432] {logging_mixin.py:104} INFO - [2021-04-23 16:35:05,432] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:35:05,449] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.744 seconds
[2021-04-23 16:35:35,531] {scheduler_job.py:182} INFO - Started process (PID=150) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:35:35,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:35:35,535] {logging_mixin.py:104} INFO - [2021-04-23 16:35:35,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:35:36,287] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:35:36,337] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:35:36,414] {logging_mixin.py:104} INFO - [2021-04-23 16:35:36,410] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:35:36,466] {logging_mixin.py:104} INFO - [2021-04-23 16:35:36,466] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:35:36,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.959 seconds
[2021-04-23 16:36:06,565] {scheduler_job.py:182} INFO - Started process (PID=152) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:36:06,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:36:06,570] {logging_mixin.py:104} INFO - [2021-04-23 16:36:06,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:36:08,469] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:36:08,514] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:36:08,546] {logging_mixin.py:104} INFO - [2021-04-23 16:36:08,544] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:36:08,563] {logging_mixin.py:104} INFO - [2021-04-23 16:36:08,562] {dag.py:1837} INFO - Creating ORM DAG for recent_played_ingestion
[2021-04-23 16:36:08,580] {logging_mixin.py:104} INFO - [2021-04-23 16:36:08,580] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T15:00:00+00:00
[2021-04-23 16:36:08,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.092 seconds
[2021-04-23 16:36:38,716] {scheduler_job.py:182} INFO - Started process (PID=154) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:36:38,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:36:38,724] {logging_mixin.py:104} INFO - [2021-04-23 16:36:38,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:36:39,462] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:36:39,483] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:36:39,495] {logging_mixin.py:104} INFO - [2021-04-23 16:36:39,494] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:36:39,512] {logging_mixin.py:104} INFO - [2021-04-23 16:36:39,512] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T15:00:00+00:00
[2021-04-23 16:36:39,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.812 seconds
[2021-04-23 16:37:09,594] {scheduler_job.py:182} INFO - Started process (PID=156) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:37:09,596] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:37:09,599] {logging_mixin.py:104} INFO - [2021-04-23 16:37:09,598] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:37:10,222] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:37:10,245] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:37:10,261] {logging_mixin.py:104} INFO - [2021-04-23 16:37:10,260] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:37:10,281] {logging_mixin.py:104} INFO - [2021-04-23 16:37:10,281] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T15:00:00+00:00
[2021-04-23 16:37:10,289] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.699 seconds
[2021-04-23 16:37:40,413] {scheduler_job.py:182} INFO - Started process (PID=158) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:37:40,416] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:37:40,418] {logging_mixin.py:104} INFO - [2021-04-23 16:37:40,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:37:41,026] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:37:41,046] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:37:41,056] {logging_mixin.py:104} INFO - [2021-04-23 16:37:41,055] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:37:41,072] {logging_mixin.py:104} INFO - [2021-04-23 16:37:41,071] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:37:41,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.672 seconds
[2021-04-23 16:38:11,286] {scheduler_job.py:182} INFO - Started process (PID=160) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:38:11,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:38:11,299] {logging_mixin.py:104} INFO - [2021-04-23 16:38:11,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:38:12,939] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:38:13,020] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:38:13,064] {logging_mixin.py:104} INFO - [2021-04-23 16:38:13,063] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:38:13,126] {logging_mixin.py:104} INFO - [2021-04-23 16:38:13,126] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:38:13,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.887 seconds
[2021-04-23 16:38:43,317] {scheduler_job.py:182} INFO - Started process (PID=162) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:38:43,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:38:43,325] {logging_mixin.py:104} INFO - [2021-04-23 16:38:43,324] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:38:44,959] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:38:44,992] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:38:45,017] {logging_mixin.py:104} INFO - [2021-04-23 16:38:45,016] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:38:45,046] {logging_mixin.py:104} INFO - [2021-04-23 16:38:45,046] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:38:45,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.749 seconds
[2021-04-23 16:39:15,558] {scheduler_job.py:182} INFO - Started process (PID=164) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:39:15,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:39:15,565] {logging_mixin.py:104} INFO - [2021-04-23 16:39:15,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:39:16,287] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:39:16,308] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:39:16,320] {logging_mixin.py:104} INFO - [2021-04-23 16:39:16,319] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:39:16,338] {logging_mixin.py:104} INFO - [2021-04-23 16:39:16,338] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:39:16,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-23 16:39:46,800] {scheduler_job.py:182} INFO - Started process (PID=166) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:39:46,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:39:46,812] {logging_mixin.py:104} INFO - [2021-04-23 16:39:46,812] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:39:47,678] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:39:47,698] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:39:47,710] {logging_mixin.py:104} INFO - [2021-04-23 16:39:47,709] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:39:47,727] {logging_mixin.py:104} INFO - [2021-04-23 16:39:47,727] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:39:47,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.943 seconds
[2021-04-23 16:40:18,959] {scheduler_job.py:182} INFO - Started process (PID=168) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:40:18,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:40:18,984] {logging_mixin.py:104} INFO - [2021-04-23 16:40:18,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:40:20,360] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:40:20,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:40:20,406] {logging_mixin.py:104} INFO - [2021-04-23 16:40:20,405] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:40:20,435] {logging_mixin.py:104} INFO - [2021-04-23 16:40:20,435] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:40:20,444] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.502 seconds
[2021-04-23 16:40:50,996] {scheduler_job.py:182} INFO - Started process (PID=170) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:40:50,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:40:51,002] {logging_mixin.py:104} INFO - [2021-04-23 16:40:51,002] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:40:51,681] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:40:51,704] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:40:51,721] {logging_mixin.py:104} INFO - [2021-04-23 16:40:51,720] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:40:51,743] {logging_mixin.py:104} INFO - [2021-04-23 16:40:51,743] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:40:51,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.763 seconds
[2021-04-23 16:41:21,859] {scheduler_job.py:182} INFO - Started process (PID=172) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:41:21,861] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:41:21,863] {logging_mixin.py:104} INFO - [2021-04-23 16:41:21,863] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:41:22,595] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:41:22,618] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:41:22,632] {logging_mixin.py:104} INFO - [2021-04-23 16:41:22,631] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:41:22,653] {logging_mixin.py:104} INFO - [2021-04-23 16:41:22,653] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:41:22,663] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.808 seconds
[2021-04-23 16:41:52,955] {scheduler_job.py:182} INFO - Started process (PID=174) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:41:52,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:41:52,965] {logging_mixin.py:104} INFO - [2021-04-23 16:41:52,964] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:41:54,657] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:41:54,760] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:41:54,813] {logging_mixin.py:104} INFO - [2021-04-23 16:41:54,808] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:41:54,859] {logging_mixin.py:104} INFO - [2021-04-23 16:41:54,859] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:41:54,876] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.930 seconds
[2021-04-23 16:42:25,004] {scheduler_job.py:182} INFO - Started process (PID=176) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:42:25,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:42:25,021] {logging_mixin.py:104} INFO - [2021-04-23 16:42:25,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:42:26,071] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:42:26,101] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:42:26,126] {logging_mixin.py:104} INFO - [2021-04-23 16:42:26,125] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:42:26,151] {logging_mixin.py:104} INFO - [2021-04-23 16:42:26,151] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:42:26,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.163 seconds
[2021-04-23 16:42:56,757] {scheduler_job.py:182} INFO - Started process (PID=178) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:42:56,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:42:56,851] {logging_mixin.py:104} INFO - [2021-04-23 16:42:56,846] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:42:59,339] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:42:59,398] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:42:59,432] {logging_mixin.py:104} INFO - [2021-04-23 16:42:59,429] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:42:59,477] {logging_mixin.py:104} INFO - [2021-04-23 16:42:59,476] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:42:59,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.767 seconds
[2021-04-23 16:43:29,854] {scheduler_job.py:182} INFO - Started process (PID=180) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:43:29,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:43:29,868] {logging_mixin.py:104} INFO - [2021-04-23 16:43:29,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:43:30,835] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:43:30,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:43:30,870] {logging_mixin.py:104} INFO - [2021-04-23 16:43:30,868] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:43:30,887] {logging_mixin.py:104} INFO - [2021-04-23 16:43:30,887] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:43:30,896] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.058 seconds
[2021-04-23 16:44:01,023] {scheduler_job.py:182} INFO - Started process (PID=182) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:44:01,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:44:01,030] {logging_mixin.py:104} INFO - [2021-04-23 16:44:01,030] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:44:01,852] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:44:01,890] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:44:01,910] {logging_mixin.py:104} INFO - [2021-04-23 16:44:01,909] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:44:01,945] {logging_mixin.py:104} INFO - [2021-04-23 16:44:01,945] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:44:01,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.952 seconds
[2021-04-23 16:44:32,513] {scheduler_job.py:182} INFO - Started process (PID=184) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:44:32,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:44:32,528] {logging_mixin.py:104} INFO - [2021-04-23 16:44:32,528] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:44:34,578] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:44:34,626] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:44:34,646] {logging_mixin.py:104} INFO - [2021-04-23 16:44:34,645] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:44:34,672] {logging_mixin.py:104} INFO - [2021-04-23 16:44:34,672] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:44:34,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.207 seconds
[2021-04-23 16:45:04,815] {scheduler_job.py:182} INFO - Started process (PID=186) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:45:04,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:45:04,823] {logging_mixin.py:104} INFO - [2021-04-23 16:45:04,823] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:45:05,593] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:45:05,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:45:05,659] {logging_mixin.py:104} INFO - [2021-04-23 16:45:05,658] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:45:05,684] {logging_mixin.py:104} INFO - [2021-04-23 16:45:05,684] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:45:05,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.901 seconds
[2021-04-23 16:45:35,769] {scheduler_job.py:182} INFO - Started process (PID=188) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:45:35,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:45:35,776] {logging_mixin.py:104} INFO - [2021-04-23 16:45:35,776] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:45:36,515] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:45:36,543] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:45:36,556] {logging_mixin.py:104} INFO - [2021-04-23 16:45:36,555] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:45:36,600] {logging_mixin.py:104} INFO - [2021-04-23 16:45:36,600] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:45:36,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.879 seconds
[2021-04-23 16:46:06,719] {scheduler_job.py:182} INFO - Started process (PID=190) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:46:06,723] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:46:06,725] {logging_mixin.py:104} INFO - [2021-04-23 16:46:06,725] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:46:07,365] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:46:07,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:46:07,409] {logging_mixin.py:104} INFO - [2021-04-23 16:46:07,408] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:46:07,425] {logging_mixin.py:104} INFO - [2021-04-23 16:46:07,424] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:46:07,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.717 seconds
[2021-04-23 16:46:37,551] {scheduler_job.py:182} INFO - Started process (PID=192) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:46:37,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:46:37,569] {logging_mixin.py:104} INFO - [2021-04-23 16:46:37,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:46:39,876] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:46:39,907] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:46:39,925] {logging_mixin.py:104} INFO - [2021-04-23 16:46:39,924] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:46:39,947] {logging_mixin.py:104} INFO - [2021-04-23 16:46:39,947] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:46:39,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.414 seconds
[2021-04-23 16:47:10,051] {scheduler_job.py:182} INFO - Started process (PID=194) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:47:10,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:47:10,056] {logging_mixin.py:104} INFO - [2021-04-23 16:47:10,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:47:10,663] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:47:10,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:47:10,695] {logging_mixin.py:104} INFO - [2021-04-23 16:47:10,694] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:47:10,712] {logging_mixin.py:104} INFO - [2021-04-23 16:47:10,712] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:47:10,723] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.676 seconds
[2021-04-23 16:47:40,816] {scheduler_job.py:182} INFO - Started process (PID=196) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:47:40,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:47:40,819] {logging_mixin.py:104} INFO - [2021-04-23 16:47:40,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:47:41,461] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:47:41,481] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:47:41,495] {logging_mixin.py:104} INFO - [2021-04-23 16:47:41,494] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:47:41,510] {logging_mixin.py:104} INFO - [2021-04-23 16:47:41,510] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:47:41,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.707 seconds
[2021-04-23 16:48:11,591] {scheduler_job.py:182} INFO - Started process (PID=198) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:48:11,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:48:11,599] {logging_mixin.py:104} INFO - [2021-04-23 16:48:11,598] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:48:12,237] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:48:12,267] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:48:12,278] {logging_mixin.py:104} INFO - [2021-04-23 16:48:12,277] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:48:12,294] {logging_mixin.py:104} INFO - [2021-04-23 16:48:12,294] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:48:12,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-23 16:48:42,706] {scheduler_job.py:182} INFO - Started process (PID=200) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:48:42,714] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:48:42,718] {logging_mixin.py:104} INFO - [2021-04-23 16:48:42,717] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:48:43,924] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:48:43,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:48:43,991] {logging_mixin.py:104} INFO - [2021-04-23 16:48:43,990] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:48:44,017] {logging_mixin.py:104} INFO - [2021-04-23 16:48:44,017] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:48:44,032] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.334 seconds
[2021-04-23 16:49:14,134] {scheduler_job.py:182} INFO - Started process (PID=202) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:49:14,136] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:49:14,138] {logging_mixin.py:104} INFO - [2021-04-23 16:49:14,138] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:49:14,778] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:49:14,801] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:49:14,814] {logging_mixin.py:104} INFO - [2021-04-23 16:49:14,813] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:49:14,833] {logging_mixin.py:104} INFO - [2021-04-23 16:49:14,833] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:49:14,845] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-23 16:49:44,925] {scheduler_job.py:182} INFO - Started process (PID=204) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:49:44,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:49:44,934] {logging_mixin.py:104} INFO - [2021-04-23 16:49:44,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:49:45,644] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:49:45,671] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:49:45,687] {logging_mixin.py:104} INFO - [2021-04-23 16:49:45,686] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:49:45,704] {logging_mixin.py:104} INFO - [2021-04-23 16:49:45,704] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:49:45,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.800 seconds
[2021-04-23 16:50:16,600] {scheduler_job.py:182} INFO - Started process (PID=206) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:50:16,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:50:16,607] {logging_mixin.py:104} INFO - [2021-04-23 16:50:16,607] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:50:17,365] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:50:17,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:50:17,399] {logging_mixin.py:104} INFO - [2021-04-23 16:50:17,398] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:50:17,419] {logging_mixin.py:104} INFO - [2021-04-23 16:50:17,419] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:50:17,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.834 seconds
[2021-04-23 16:50:47,520] {scheduler_job.py:182} INFO - Started process (PID=208) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:50:47,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:50:47,523] {logging_mixin.py:104} INFO - [2021-04-23 16:50:47,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:50:48,216] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:50:48,237] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:50:48,249] {logging_mixin.py:104} INFO - [2021-04-23 16:50:48,248] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:50:48,266] {logging_mixin.py:104} INFO - [2021-04-23 16:50:48,266] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:50:48,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.759 seconds
[2021-04-23 16:51:18,388] {scheduler_job.py:182} INFO - Started process (PID=210) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:51:18,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:51:18,396] {logging_mixin.py:104} INFO - [2021-04-23 16:51:18,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:51:19,280] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:51:19,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:51:19,359] {logging_mixin.py:104} INFO - [2021-04-23 16:51:19,357] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:51:19,387] {logging_mixin.py:104} INFO - [2021-04-23 16:51:19,387] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:51:19,400] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.018 seconds
[2021-04-23 16:51:49,534] {scheduler_job.py:182} INFO - Started process (PID=212) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:51:49,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:51:49,544] {logging_mixin.py:104} INFO - [2021-04-23 16:51:49,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:51:51,322] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:51:51,363] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:51:51,399] {logging_mixin.py:104} INFO - [2021-04-23 16:51:51,395] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:51:51,437] {logging_mixin.py:104} INFO - [2021-04-23 16:51:51,436] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:51:51,471] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.945 seconds
[2021-04-23 16:52:21,563] {scheduler_job.py:182} INFO - Started process (PID=214) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:52:21,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:52:21,569] {logging_mixin.py:104} INFO - [2021-04-23 16:52:21,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:52:22,503] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:52:22,526] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:52:22,543] {logging_mixin.py:104} INFO - [2021-04-23 16:52:22,542] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:52:22,568] {logging_mixin.py:104} INFO - [2021-04-23 16:52:22,568] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:52:22,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.024 seconds
[2021-04-23 16:52:53,307] {scheduler_job.py:182} INFO - Started process (PID=216) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:52:53,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:52:53,323] {logging_mixin.py:104} INFO - [2021-04-23 16:52:53,323] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:52:55,010] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:52:55,038] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:52:55,050] {logging_mixin.py:104} INFO - [2021-04-23 16:52:55,049] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:52:55,071] {logging_mixin.py:104} INFO - [2021-04-23 16:52:55,070] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:52:55,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.786 seconds
[2021-04-23 16:53:25,227] {scheduler_job.py:182} INFO - Started process (PID=218) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:53:25,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:53:25,231] {logging_mixin.py:104} INFO - [2021-04-23 16:53:25,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:53:25,864] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:53:25,885] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:53:25,897] {logging_mixin.py:104} INFO - [2021-04-23 16:53:25,896] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:53:25,913] {logging_mixin.py:104} INFO - [2021-04-23 16:53:25,913] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:53:25,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.703 seconds
[2021-04-23 16:53:56,021] {scheduler_job.py:182} INFO - Started process (PID=220) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:53:56,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:53:56,026] {logging_mixin.py:104} INFO - [2021-04-23 16:53:56,026] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:53:56,769] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:53:56,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:53:56,809] {logging_mixin.py:104} INFO - [2021-04-23 16:53:56,807] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:53:56,833] {logging_mixin.py:104} INFO - [2021-04-23 16:53:56,833] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:53:56,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.830 seconds
[2021-04-23 16:54:26,973] {scheduler_job.py:182} INFO - Started process (PID=222) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:54:26,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:54:26,979] {logging_mixin.py:104} INFO - [2021-04-23 16:54:26,979] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:54:27,608] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:54:27,631] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:54:27,643] {logging_mixin.py:104} INFO - [2021-04-23 16:54:27,642] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:54:27,659] {logging_mixin.py:104} INFO - [2021-04-23 16:54:27,659] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:54:27,669] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.700 seconds
[2021-04-23 16:54:58,145] {scheduler_job.py:182} INFO - Started process (PID=224) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:54:58,147] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:54:58,150] {logging_mixin.py:104} INFO - [2021-04-23 16:54:58,150] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:54:59,044] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:54:59,074] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:54:59,090] {logging_mixin.py:104} INFO - [2021-04-23 16:54:59,089] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:54:59,111] {logging_mixin.py:104} INFO - [2021-04-23 16:54:59,111] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:54:59,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.982 seconds
[2021-04-23 16:55:29,267] {scheduler_job.py:182} INFO - Started process (PID=226) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:55:29,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:55:29,273] {logging_mixin.py:104} INFO - [2021-04-23 16:55:29,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:55:30,045] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:55:30,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:55:30,083] {logging_mixin.py:104} INFO - [2021-04-23 16:55:30,082] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:55:30,108] {logging_mixin.py:104} INFO - [2021-04-23 16:55:30,108] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:55:30,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.865 seconds
[2021-04-23 16:56:00,219] {scheduler_job.py:182} INFO - Started process (PID=228) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:56:00,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:56:00,222] {logging_mixin.py:104} INFO - [2021-04-23 16:56:00,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:56:00,853] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:56:00,901] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:56:00,917] {logging_mixin.py:104} INFO - [2021-04-23 16:56:00,915] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:56:00,941] {logging_mixin.py:104} INFO - [2021-04-23 16:56:00,940] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:56:00,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.751 seconds
[2021-04-23 16:56:31,066] {scheduler_job.py:182} INFO - Started process (PID=230) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:56:31,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:56:31,071] {logging_mixin.py:104} INFO - [2021-04-23 16:56:31,070] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:56:31,711] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:56:31,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:56:31,749] {logging_mixin.py:104} INFO - [2021-04-23 16:56:31,748] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:56:31,768] {logging_mixin.py:104} INFO - [2021-04-23 16:56:31,768] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:56:31,775] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.714 seconds
[2021-04-23 16:57:01,859] {scheduler_job.py:182} INFO - Started process (PID=232) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:57:01,861] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:57:01,864] {logging_mixin.py:104} INFO - [2021-04-23 16:57:01,864] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:57:02,501] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:57:02,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:57:02,538] {logging_mixin.py:104} INFO - [2021-04-23 16:57:02,536] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:57:02,557] {logging_mixin.py:104} INFO - [2021-04-23 16:57:02,557] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:57:02,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.712 seconds
[2021-04-23 16:57:32,659] {scheduler_job.py:182} INFO - Started process (PID=234) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:57:32,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:57:32,665] {logging_mixin.py:104} INFO - [2021-04-23 16:57:32,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:57:33,416] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:57:33,437] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:57:33,449] {logging_mixin.py:104} INFO - [2021-04-23 16:57:33,448] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:57:33,468] {logging_mixin.py:104} INFO - [2021-04-23 16:57:33,468] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:57:33,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.824 seconds
[2021-04-23 16:58:03,585] {scheduler_job.py:182} INFO - Started process (PID=236) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:58:03,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:58:03,593] {logging_mixin.py:104} INFO - [2021-04-23 16:58:03,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:58:04,403] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:58:04,426] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:58:04,440] {logging_mixin.py:104} INFO - [2021-04-23 16:58:04,439] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:58:04,459] {logging_mixin.py:104} INFO - [2021-04-23 16:58:04,459] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:58:04,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.888 seconds
[2021-04-23 16:58:34,790] {scheduler_job.py:182} INFO - Started process (PID=238) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:58:34,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:58:34,798] {logging_mixin.py:104} INFO - [2021-04-23 16:58:34,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:58:35,548] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:58:35,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:58:35,592] {logging_mixin.py:104} INFO - [2021-04-23 16:58:35,591] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:58:35,610] {logging_mixin.py:104} INFO - [2021-04-23 16:58:35,610] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:58:35,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.839 seconds
[2021-04-23 16:59:05,717] {scheduler_job.py:182} INFO - Started process (PID=240) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:59:05,719] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:59:05,723] {logging_mixin.py:104} INFO - [2021-04-23 16:59:05,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:59:06,431] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:59:06,454] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:59:06,468] {logging_mixin.py:104} INFO - [2021-04-23 16:59:06,467] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:59:06,484] {logging_mixin.py:104} INFO - [2021-04-23 16:59:06,484] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:59:06,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.816 seconds
[2021-04-23 16:59:37,117] {scheduler_job.py:182} INFO - Started process (PID=242) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:59:37,123] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 16:59:37,125] {logging_mixin.py:104} INFO - [2021-04-23 16:59:37,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:59:38,428] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 16:59:38,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 16:59:38,491] {logging_mixin.py:104} INFO - [2021-04-23 16:59:38,489] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 16:59:38,520] {logging_mixin.py:104} INFO - [2021-04-23 16:59:38,520] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T16:00:00+00:00
[2021-04-23 16:59:38,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.434 seconds
[2021-04-23 17:00:08,751] {scheduler_job.py:182} INFO - Started process (PID=244) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:00:08,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:00:08,756] {logging_mixin.py:104} INFO - [2021-04-23 17:00:08,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:00:09,413] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:00:09,434] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:00:09,447] {logging_mixin.py:104} INFO - [2021-04-23 17:00:09,446] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:00:09,465] {logging_mixin.py:104} INFO - [2021-04-23 17:00:09,465] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:00:09,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.729 seconds
[2021-04-23 17:00:39,856] {scheduler_job.py:182} INFO - Started process (PID=246) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:00:39,861] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:00:39,866] {logging_mixin.py:104} INFO - [2021-04-23 17:00:39,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:00:41,111] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:00:41,147] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:00:41,168] {logging_mixin.py:104} INFO - [2021-04-23 17:00:41,166] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:00:41,198] {logging_mixin.py:104} INFO - [2021-04-23 17:00:41,197] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:00:41,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.366 seconds
[2021-04-23 17:01:11,373] {scheduler_job.py:182} INFO - Started process (PID=248) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:01:11,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:01:11,380] {logging_mixin.py:104} INFO - [2021-04-23 17:01:11,380] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:01:12,270] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:01:12,291] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:01:12,302] {logging_mixin.py:104} INFO - [2021-04-23 17:01:12,301] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:01:12,319] {logging_mixin.py:104} INFO - [2021-04-23 17:01:12,319] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:01:12,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.960 seconds
[2021-04-23 17:01:42,465] {scheduler_job.py:182} INFO - Started process (PID=250) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:01:42,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:01:42,476] {logging_mixin.py:104} INFO - [2021-04-23 17:01:42,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:01:43,934] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:01:43,967] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:01:43,986] {logging_mixin.py:104} INFO - [2021-04-23 17:01:43,985] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:01:44,016] {logging_mixin.py:104} INFO - [2021-04-23 17:01:44,016] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:01:44,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.572 seconds
[2021-04-23 17:02:14,753] {scheduler_job.py:182} INFO - Started process (PID=252) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:02:14,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:02:14,765] {logging_mixin.py:104} INFO - [2021-04-23 17:02:14,764] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:02:15,479] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:02:15,503] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:02:15,516] {logging_mixin.py:104} INFO - [2021-04-23 17:02:15,515] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:02:15,534] {logging_mixin.py:104} INFO - [2021-04-23 17:02:15,534] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:02:15,545] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.800 seconds
[2021-04-23 17:02:46,055] {scheduler_job.py:182} INFO - Started process (PID=254) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:02:46,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:02:46,087] {logging_mixin.py:104} INFO - [2021-04-23 17:02:46,086] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:03:22,549] {logging_mixin.py:104} INFO - [2021-04-23 17:03:22,535] {timeout.py:36} ERROR - Process timed out, PID: 254
[2021-04-23 17:03:22,559] {logging_mixin.py:104} WARNING - Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f3ebda148c8>
[2021-04-23 17:03:22,563] {logging_mixin.py:104} WARNING - Traceback (most recent call last):
[2021-04-23 17:03:22,586] {logging_mixin.py:104} WARNING -   File "/usr/local/lib/python3.6/weakref.py", line 109, in remove
[2021-04-23 17:03:22,651] {logging_mixin.py:104} WARNING -     def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
[2021-04-23 17:03:22,658] {logging_mixin.py:104} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2021-04-23 17:03:22,699] {logging_mixin.py:104} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2021-04-23 17:03:22,704] {logging_mixin.py:104} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/recent_played_ingestion.py after 30.0s, PID: 254
[2021-04-23 17:03:25,277] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:03:25,726] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:03:26,231] {logging_mixin.py:104} INFO - [2021-04-23 17:03:26,170] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:03:26,348] {logging_mixin.py:104} INFO - [2021-04-23 17:03:26,347] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:03:26,444] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 40.433 seconds
[2021-04-23 17:03:57,056] {scheduler_job.py:182} INFO - Started process (PID=256) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:03:57,059] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:03:57,062] {logging_mixin.py:104} INFO - [2021-04-23 17:03:57,062] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:03:57,832] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:03:57,872] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:03:57,896] {logging_mixin.py:104} INFO - [2021-04-23 17:03:57,894] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:03:57,937] {logging_mixin.py:104} INFO - [2021-04-23 17:03:57,937] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:03:57,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.907 seconds
[2021-04-23 17:04:28,150] {scheduler_job.py:182} INFO - Started process (PID=258) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:04:28,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:04:28,161] {logging_mixin.py:104} INFO - [2021-04-23 17:04:28,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:04:29,358] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:04:29,425] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:04:29,488] {logging_mixin.py:104} INFO - [2021-04-23 17:04:29,487] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:04:29,543] {logging_mixin.py:104} INFO - [2021-04-23 17:04:29,543] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:04:29,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.408 seconds
[2021-04-23 17:04:59,677] {scheduler_job.py:182} INFO - Started process (PID=260) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:04:59,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:04:59,683] {logging_mixin.py:104} INFO - [2021-04-23 17:04:59,683] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:05:00,308] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:05:00,329] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:05:00,341] {logging_mixin.py:104} INFO - [2021-04-23 17:05:00,340] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:05:00,358] {logging_mixin.py:104} INFO - [2021-04-23 17:05:00,358] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:05:00,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.693 seconds
[2021-04-23 17:05:30,515] {scheduler_job.py:182} INFO - Started process (PID=262) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:05:30,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:05:30,525] {logging_mixin.py:104} INFO - [2021-04-23 17:05:30,525] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:05:32,300] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:05:32,356] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:05:32,390] {logging_mixin.py:104} INFO - [2021-04-23 17:05:32,389] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:05:32,420] {logging_mixin.py:104} INFO - [2021-04-23 17:05:32,420] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:05:32,439] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.930 seconds
[2021-04-23 17:06:03,294] {scheduler_job.py:182} INFO - Started process (PID=264) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:06:03,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:06:03,302] {logging_mixin.py:104} INFO - [2021-04-23 17:06:03,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:06:04,654] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:06:04,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:06:04,757] {logging_mixin.py:104} INFO - [2021-04-23 17:06:04,754] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:06:04,797] {logging_mixin.py:104} INFO - [2021-04-23 17:06:04,796] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:06:04,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.518 seconds
[2021-04-23 17:06:35,031] {scheduler_job.py:182} INFO - Started process (PID=266) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:06:35,037] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:06:35,041] {logging_mixin.py:104} INFO - [2021-04-23 17:06:35,040] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:06:36,423] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:06:36,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:06:36,480] {logging_mixin.py:104} INFO - [2021-04-23 17:06:36,478] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:06:36,528] {logging_mixin.py:104} INFO - [2021-04-23 17:06:36,528] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:06:36,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.551 seconds
[2021-04-23 17:07:07,622] {scheduler_job.py:182} INFO - Started process (PID=269) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:07:07,625] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:07:07,631] {logging_mixin.py:104} INFO - [2021-04-23 17:07:07,630] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:07:09,069] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:07:09,101] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:07:09,126] {logging_mixin.py:104} INFO - [2021-04-23 17:07:09,124] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:07:09,161] {logging_mixin.py:104} INFO - [2021-04-23 17:07:09,161] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:07:09,177] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.565 seconds
[2021-04-23 17:07:39,373] {scheduler_job.py:182} INFO - Started process (PID=271) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:07:39,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:07:39,379] {logging_mixin.py:104} INFO - [2021-04-23 17:07:39,379] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:07:40,217] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:07:40,243] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:07:40,265] {logging_mixin.py:104} INFO - [2021-04-23 17:07:40,263] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:07:40,294] {logging_mixin.py:104} INFO - [2021-04-23 17:07:40,294] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:07:40,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.947 seconds
[2021-04-23 17:08:11,454] {scheduler_job.py:182} INFO - Started process (PID=273) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:08:11,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:08:11,463] {logging_mixin.py:104} INFO - [2021-04-23 17:08:11,463] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:08:13,399] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:08:13,430] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:08:13,447] {logging_mixin.py:104} INFO - [2021-04-23 17:08:13,446] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:08:13,469] {logging_mixin.py:104} INFO - [2021-04-23 17:08:13,469] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:08:13,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.044 seconds
[2021-04-23 17:08:43,884] {scheduler_job.py:182} INFO - Started process (PID=275) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:08:43,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:08:43,901] {logging_mixin.py:104} INFO - [2021-04-23 17:08:43,900] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:08:45,078] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:08:45,124] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:08:45,144] {logging_mixin.py:104} INFO - [2021-04-23 17:08:45,142] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:08:45,178] {logging_mixin.py:104} INFO - [2021-04-23 17:08:45,177] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:08:45,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.312 seconds
[2021-04-23 17:09:15,362] {scheduler_job.py:182} INFO - Started process (PID=277) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:09:15,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:09:15,369] {logging_mixin.py:104} INFO - [2021-04-23 17:09:15,368] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:09:16,488] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:09:16,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:09:16,544] {logging_mixin.py:104} INFO - [2021-04-23 17:09:16,543] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:09:16,576] {logging_mixin.py:104} INFO - [2021-04-23 17:09:16,576] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:09:16,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.235 seconds
[2021-04-23 17:09:46,681] {scheduler_job.py:182} INFO - Started process (PID=279) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:09:46,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:09:46,686] {logging_mixin.py:104} INFO - [2021-04-23 17:09:46,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:09:48,765] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:09:48,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:09:49,012] {logging_mixin.py:104} INFO - [2021-04-23 17:09:49,009] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:09:49,085] {logging_mixin.py:104} INFO - [2021-04-23 17:09:49,084] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:09:49,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.447 seconds
[2021-04-23 17:10:19,802] {scheduler_job.py:182} INFO - Started process (PID=281) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:10:19,819] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:10:19,825] {logging_mixin.py:104} INFO - [2021-04-23 17:10:19,824] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:10:32,401] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:10:32,778] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:10:32,834] {logging_mixin.py:104} INFO - [2021-04-23 17:10:32,830] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:10:32,894] {logging_mixin.py:104} INFO - [2021-04-23 17:10:32,894] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:10:32,916] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 13.118 seconds
[2021-04-23 17:11:03,493] {scheduler_job.py:182} INFO - Started process (PID=283) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:11:03,499] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:11:03,504] {logging_mixin.py:104} INFO - [2021-04-23 17:11:03,504] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:11:05,573] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:11:05,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:11:05,679] {logging_mixin.py:104} INFO - [2021-04-23 17:11:05,678] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:11:05,733] {logging_mixin.py:104} INFO - [2021-04-23 17:11:05,733] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:11:05,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.304 seconds
[2021-04-23 17:11:35,896] {scheduler_job.py:182} INFO - Started process (PID=285) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:11:35,899] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:11:35,901] {logging_mixin.py:104} INFO - [2021-04-23 17:11:35,901] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:11:36,672] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:11:36,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:11:36,719] {logging_mixin.py:104} INFO - [2021-04-23 17:11:36,718] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:11:36,747] {logging_mixin.py:104} INFO - [2021-04-23 17:11:36,747] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:11:36,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.867 seconds
[2021-04-23 17:12:06,868] {scheduler_job.py:182} INFO - Started process (PID=287) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:12:06,873] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:12:06,877] {logging_mixin.py:104} INFO - [2021-04-23 17:12:06,877] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:12:07,846] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:12:07,876] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:12:07,912] {logging_mixin.py:104} INFO - [2021-04-23 17:12:07,911] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:12:07,952] {logging_mixin.py:104} INFO - [2021-04-23 17:12:07,952] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:12:07,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.109 seconds
[2021-04-23 17:12:38,187] {scheduler_job.py:182} INFO - Started process (PID=289) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:12:38,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:12:38,200] {logging_mixin.py:104} INFO - [2021-04-23 17:12:38,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:12:39,598] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:12:39,633] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:12:39,661] {logging_mixin.py:104} INFO - [2021-04-23 17:12:39,660] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:12:39,691] {logging_mixin.py:104} INFO - [2021-04-23 17:12:39,691] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:12:39,712] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.537 seconds
[2021-04-23 17:13:09,802] {scheduler_job.py:182} INFO - Started process (PID=291) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:13:09,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:13:09,813] {logging_mixin.py:104} INFO - [2021-04-23 17:13:09,813] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:13:11,086] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:13:11,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:13:11,137] {logging_mixin.py:104} INFO - [2021-04-23 17:13:11,136] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:13:11,159] {logging_mixin.py:104} INFO - [2021-04-23 17:13:11,159] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:13:11,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.384 seconds
[2021-04-23 17:13:41,388] {scheduler_job.py:182} INFO - Started process (PID=293) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:13:41,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:13:41,394] {logging_mixin.py:104} INFO - [2021-04-23 17:13:41,394] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:13:42,493] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:13:42,536] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:13:42,571] {logging_mixin.py:104} INFO - [2021-04-23 17:13:42,570] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:13:42,629] {logging_mixin.py:104} INFO - [2021-04-23 17:13:42,629] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:13:42,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.287 seconds
[2021-04-23 17:14:12,832] {scheduler_job.py:182} INFO - Started process (PID=295) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:14:12,836] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:14:12,841] {logging_mixin.py:104} INFO - [2021-04-23 17:14:12,841] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:14:14,253] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:14:14,317] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:14:14,366] {logging_mixin.py:104} INFO - [2021-04-23 17:14:14,364] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:14:14,406] {logging_mixin.py:104} INFO - [2021-04-23 17:14:14,405] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:14:14,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.591 seconds
[2021-04-23 17:14:44,682] {scheduler_job.py:182} INFO - Started process (PID=297) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:14:44,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:14:44,895] {logging_mixin.py:104} INFO - [2021-04-23 17:14:44,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:14:48,275] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:14:48,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:14:48,497] {logging_mixin.py:104} INFO - [2021-04-23 17:14:48,496] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:14:48,547] {logging_mixin.py:104} INFO - [2021-04-23 17:14:48,546] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:14:48,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.933 seconds
[2021-04-23 17:15:18,732] {scheduler_job.py:182} INFO - Started process (PID=299) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:15:18,741] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:15:18,751] {logging_mixin.py:104} INFO - [2021-04-23 17:15:18,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:15:20,289] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:15:20,339] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:15:20,359] {logging_mixin.py:104} INFO - [2021-04-23 17:15:20,357] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:15:20,410] {logging_mixin.py:104} INFO - [2021-04-23 17:15:20,409] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:15:20,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.703 seconds
[2021-04-23 17:15:50,600] {scheduler_job.py:182} INFO - Started process (PID=300) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:15:50,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:15:50,608] {logging_mixin.py:104} INFO - [2021-04-23 17:15:50,607] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:15:52,189] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:15:52,275] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:15:52,311] {logging_mixin.py:104} INFO - [2021-04-23 17:15:52,308] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:15:52,357] {logging_mixin.py:104} INFO - [2021-04-23 17:15:52,356] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:15:52,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.783 seconds
[2021-04-23 17:16:22,689] {scheduler_job.py:182} INFO - Started process (PID=303) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:16:22,694] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:16:22,697] {logging_mixin.py:104} INFO - [2021-04-23 17:16:22,696] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:16:23,660] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:16:23,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:16:23,718] {logging_mixin.py:104} INFO - [2021-04-23 17:16:23,717] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:16:23,759] {logging_mixin.py:104} INFO - [2021-04-23 17:16:23,759] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:16:23,786] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.110 seconds
[2021-04-23 17:16:53,898] {scheduler_job.py:182} INFO - Started process (PID=304) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:16:53,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:16:53,903] {logging_mixin.py:104} INFO - [2021-04-23 17:16:53,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:16:54,744] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:16:54,774] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:16:54,800] {logging_mixin.py:104} INFO - [2021-04-23 17:16:54,799] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:16:54,831] {logging_mixin.py:104} INFO - [2021-04-23 17:16:54,831] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:16:54,843] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.951 seconds
[2021-04-23 17:17:25,180] {scheduler_job.py:182} INFO - Started process (PID=307) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:17:25,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:17:25,197] {logging_mixin.py:104} INFO - [2021-04-23 17:17:25,196] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:17:26,391] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:17:26,483] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:17:26,515] {logging_mixin.py:104} INFO - [2021-04-23 17:17:26,514] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:17:26,563] {logging_mixin.py:104} INFO - [2021-04-23 17:17:26,563] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:17:26,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.412 seconds
[2021-04-23 17:17:56,853] {scheduler_job.py:182} INFO - Started process (PID=309) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:17:56,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:17:56,861] {logging_mixin.py:104} INFO - [2021-04-23 17:17:56,861] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:17:57,638] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:17:57,677] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:17:57,697] {logging_mixin.py:104} INFO - [2021-04-23 17:17:57,695] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:17:57,742] {logging_mixin.py:104} INFO - [2021-04-23 17:17:57,742] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:17:57,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.926 seconds
[2021-04-23 17:18:27,974] {scheduler_job.py:182} INFO - Started process (PID=311) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:18:27,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:18:27,981] {logging_mixin.py:104} INFO - [2021-04-23 17:18:27,981] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:18:28,818] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:18:28,849] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:18:28,863] {logging_mixin.py:104} INFO - [2021-04-23 17:18:28,862] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:18:28,886] {logging_mixin.py:104} INFO - [2021-04-23 17:18:28,885] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:18:28,896] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.935 seconds
[2021-04-23 17:18:59,048] {scheduler_job.py:182} INFO - Started process (PID=313) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:18:59,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:18:59,054] {logging_mixin.py:104} INFO - [2021-04-23 17:18:59,053] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:18:59,752] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:18:59,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:18:59,798] {logging_mixin.py:104} INFO - [2021-04-23 17:18:59,796] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:18:59,822] {logging_mixin.py:104} INFO - [2021-04-23 17:18:59,822] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:18:59,833] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.790 seconds
[2021-04-23 17:19:29,988] {scheduler_job.py:182} INFO - Started process (PID=315) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:19:30,029] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:19:30,032] {logging_mixin.py:104} INFO - [2021-04-23 17:19:30,032] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:19:31,056] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:19:31,079] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:19:31,091] {logging_mixin.py:104} INFO - [2021-04-23 17:19:31,090] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:19:31,116] {logging_mixin.py:104} INFO - [2021-04-23 17:19:31,116] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:19:31,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.151 seconds
[2021-04-23 17:20:01,246] {scheduler_job.py:182} INFO - Started process (PID=316) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:20:01,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:20:01,251] {logging_mixin.py:104} INFO - [2021-04-23 17:20:01,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:20:02,147] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:20:02,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:20:02,187] {logging_mixin.py:104} INFO - [2021-04-23 17:20:02,186] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:20:02,212] {logging_mixin.py:104} INFO - [2021-04-23 17:20:02,212] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:20:02,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.985 seconds
[2021-04-23 17:20:32,438] {scheduler_job.py:182} INFO - Started process (PID=319) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:20:32,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:20:32,445] {logging_mixin.py:104} INFO - [2021-04-23 17:20:32,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:20:33,335] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:20:33,360] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:20:33,387] {logging_mixin.py:104} INFO - [2021-04-23 17:20:33,386] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:20:33,442] {logging_mixin.py:104} INFO - [2021-04-23 17:20:33,442] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:20:33,452] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.019 seconds
[2021-04-23 17:21:03,591] {scheduler_job.py:182} INFO - Started process (PID=321) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:21:03,596] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:21:03,599] {logging_mixin.py:104} INFO - [2021-04-23 17:21:03,599] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:21:04,318] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:21:04,336] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:21:04,348] {logging_mixin.py:104} INFO - [2021-04-23 17:21:04,347] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:21:04,367] {logging_mixin.py:104} INFO - [2021-04-23 17:21:04,367] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:21:04,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-23 17:21:34,663] {scheduler_job.py:182} INFO - Started process (PID=323) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:21:34,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:21:34,670] {logging_mixin.py:104} INFO - [2021-04-23 17:21:34,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:21:35,643] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:21:35,688] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:21:35,711] {logging_mixin.py:104} INFO - [2021-04-23 17:21:35,710] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:21:35,751] {logging_mixin.py:104} INFO - [2021-04-23 17:21:35,751] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:21:35,776] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.154 seconds
[2021-04-23 17:22:06,452] {scheduler_job.py:182} INFO - Started process (PID=325) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:22:06,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:22:06,462] {logging_mixin.py:104} INFO - [2021-04-23 17:22:06,461] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:22:07,379] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:22:07,427] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:22:07,459] {logging_mixin.py:104} INFO - [2021-04-23 17:22:07,457] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:22:07,494] {logging_mixin.py:104} INFO - [2021-04-23 17:22:07,493] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:22:07,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.069 seconds
[2021-04-23 17:22:37,727] {scheduler_job.py:182} INFO - Started process (PID=327) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:22:37,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:22:37,732] {logging_mixin.py:104} INFO - [2021-04-23 17:22:37,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:22:38,605] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:22:38,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:22:38,656] {logging_mixin.py:104} INFO - [2021-04-23 17:22:38,654] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:22:38,698] {logging_mixin.py:104} INFO - [2021-04-23 17:22:38,698] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:22:38,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.003 seconds
[2021-04-23 17:23:09,812] {scheduler_job.py:182} INFO - Started process (PID=328) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:23:09,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:23:09,823] {logging_mixin.py:104} INFO - [2021-04-23 17:23:09,822] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:23:11,602] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:23:11,660] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:23:11,699] {logging_mixin.py:104} INFO - [2021-04-23 17:23:11,697] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:23:11,792] {logging_mixin.py:104} INFO - [2021-04-23 17:23:11,792] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:23:11,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.033 seconds
[2021-04-23 17:23:42,003] {scheduler_job.py:182} INFO - Started process (PID=330) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:23:42,006] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:23:42,008] {logging_mixin.py:104} INFO - [2021-04-23 17:23:42,007] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:23:42,671] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:23:42,692] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:23:42,703] {logging_mixin.py:104} INFO - [2021-04-23 17:23:42,702] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:23:42,720] {logging_mixin.py:104} INFO - [2021-04-23 17:23:42,720] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:23:42,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.732 seconds
[2021-04-23 17:24:12,810] {scheduler_job.py:182} INFO - Started process (PID=332) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:24:12,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:24:12,816] {logging_mixin.py:104} INFO - [2021-04-23 17:24:12,816] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:24:13,496] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:24:13,521] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:24:13,533] {logging_mixin.py:104} INFO - [2021-04-23 17:24:13,532] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:24:13,550] {logging_mixin.py:104} INFO - [2021-04-23 17:24:13,550] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:24:13,563] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.760 seconds
[2021-04-23 17:24:43,712] {scheduler_job.py:182} INFO - Started process (PID=334) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:24:43,716] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:24:43,718] {logging_mixin.py:104} INFO - [2021-04-23 17:24:43,718] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:24:44,540] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:24:44,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:24:44,594] {logging_mixin.py:104} INFO - [2021-04-23 17:24:44,593] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:24:44,620] {logging_mixin.py:104} INFO - [2021-04-23 17:24:44,620] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:24:44,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.927 seconds
[2021-04-23 17:25:15,292] {scheduler_job.py:182} INFO - Started process (PID=337) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:25:15,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:25:15,297] {logging_mixin.py:104} INFO - [2021-04-23 17:25:15,297] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:25:16,349] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:25:16,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:25:16,421] {logging_mixin.py:104} INFO - [2021-04-23 17:25:16,418] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:25:16,468] {logging_mixin.py:104} INFO - [2021-04-23 17:25:16,468] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:25:16,485] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.198 seconds
[2021-04-23 17:25:46,590] {scheduler_job.py:182} INFO - Started process (PID=339) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:25:46,594] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:25:46,597] {logging_mixin.py:104} INFO - [2021-04-23 17:25:46,597] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:25:47,311] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:25:47,331] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:25:47,346] {logging_mixin.py:104} INFO - [2021-04-23 17:25:47,345] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:25:47,364] {logging_mixin.py:104} INFO - [2021-04-23 17:25:47,364] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:25:47,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.787 seconds
[2021-04-23 17:26:18,418] {scheduler_job.py:182} INFO - Started process (PID=341) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:26:18,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:26:18,429] {logging_mixin.py:104} INFO - [2021-04-23 17:26:18,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:26:20,141] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:26:20,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:26:20,188] {logging_mixin.py:104} INFO - [2021-04-23 17:26:20,187] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:26:20,213] {logging_mixin.py:104} INFO - [2021-04-23 17:26:20,213] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:26:20,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.820 seconds
[2021-04-23 17:26:50,353] {scheduler_job.py:182} INFO - Started process (PID=343) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:26:50,356] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:26:50,360] {logging_mixin.py:104} INFO - [2021-04-23 17:26:50,360] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:26:51,136] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:26:51,162] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:26:51,182] {logging_mixin.py:104} INFO - [2021-04-23 17:26:51,181] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:26:51,210] {logging_mixin.py:104} INFO - [2021-04-23 17:26:51,209] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:26:51,223] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.873 seconds
[2021-04-23 17:27:22,249] {scheduler_job.py:182} INFO - Started process (PID=345) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:27:22,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:27:22,262] {logging_mixin.py:104} INFO - [2021-04-23 17:27:22,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:27:24,696] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:27:24,847] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:27:24,867] {logging_mixin.py:104} INFO - [2021-04-23 17:27:24,866] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:27:24,901] {logging_mixin.py:104} INFO - [2021-04-23 17:27:24,901] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:27:24,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.702 seconds
[2021-04-23 17:27:55,250] {scheduler_job.py:182} INFO - Started process (PID=347) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:27:55,255] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:27:55,279] {logging_mixin.py:104} INFO - [2021-04-23 17:27:55,279] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:27:58,557] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:27:58,597] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:27:58,625] {logging_mixin.py:104} INFO - [2021-04-23 17:27:58,623] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:27:58,660] {logging_mixin.py:104} INFO - [2021-04-23 17:27:58,660] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:27:58,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.441 seconds
[2021-04-23 17:28:28,793] {scheduler_job.py:182} INFO - Started process (PID=348) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:28:28,796] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:28:28,798] {logging_mixin.py:104} INFO - [2021-04-23 17:28:28,798] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:28:29,675] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:28:29,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:28:29,727] {logging_mixin.py:104} INFO - [2021-04-23 17:28:29,726] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:28:29,771] {logging_mixin.py:104} INFO - [2021-04-23 17:28:29,771] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:28:29,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.044 seconds
[2021-04-23 17:29:01,136] {scheduler_job.py:182} INFO - Started process (PID=351) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:29:01,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:29:01,169] {logging_mixin.py:104} INFO - [2021-04-23 17:29:01,169] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:29:03,636] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:29:03,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:29:03,716] {logging_mixin.py:104} INFO - [2021-04-23 17:29:03,713] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:29:03,767] {logging_mixin.py:104} INFO - [2021-04-23 17:29:03,767] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:29:03,805] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.722 seconds
[2021-04-23 17:29:34,111] {scheduler_job.py:182} INFO - Started process (PID=353) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:29:34,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:29:34,125] {logging_mixin.py:104} INFO - [2021-04-23 17:29:34,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:29:36,314] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:29:36,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:29:36,443] {logging_mixin.py:104} INFO - [2021-04-23 17:29:36,442] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:29:36,478] {logging_mixin.py:104} INFO - [2021-04-23 17:29:36,478] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:29:36,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.487 seconds
[2021-04-23 17:30:06,785] {scheduler_job.py:182} INFO - Started process (PID=355) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:30:06,789] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:30:06,796] {logging_mixin.py:104} INFO - [2021-04-23 17:30:06,796] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:30:07,733] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:30:07,757] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:30:07,768] {logging_mixin.py:104} INFO - [2021-04-23 17:30:07,767] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:30:07,785] {logging_mixin.py:104} INFO - [2021-04-23 17:30:07,785] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:30:07,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.015 seconds
[2021-04-23 17:30:38,096] {scheduler_job.py:182} INFO - Started process (PID=357) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:30:38,101] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:30:38,104] {logging_mixin.py:104} INFO - [2021-04-23 17:30:38,103] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:30:38,908] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:30:38,941] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:30:38,966] {logging_mixin.py:104} INFO - [2021-04-23 17:30:38,964] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:30:38,997] {logging_mixin.py:104} INFO - [2021-04-23 17:30:38,996] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:30:39,009] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.927 seconds
[2021-04-23 17:31:09,187] {scheduler_job.py:182} INFO - Started process (PID=359) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:31:09,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:31:09,200] {logging_mixin.py:104} INFO - [2021-04-23 17:31:09,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:31:10,338] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:31:10,383] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:31:10,418] {logging_mixin.py:104} INFO - [2021-04-23 17:31:10,415] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:31:10,459] {logging_mixin.py:104} INFO - [2021-04-23 17:31:10,459] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:31:10,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.297 seconds
[2021-04-23 17:31:40,706] {scheduler_job.py:182} INFO - Started process (PID=361) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:31:40,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:31:40,713] {logging_mixin.py:104} INFO - [2021-04-23 17:31:40,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:31:41,659] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:31:41,704] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:31:41,732] {logging_mixin.py:104} INFO - [2021-04-23 17:31:41,728] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:31:41,772] {logging_mixin.py:104} INFO - [2021-04-23 17:31:41,772] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:31:41,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.093 seconds
[2021-04-23 17:32:12,307] {scheduler_job.py:182} INFO - Started process (PID=363) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:32:12,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:32:12,314] {logging_mixin.py:104} INFO - [2021-04-23 17:32:12,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:32:13,120] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:32:13,160] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:32:13,194] {logging_mixin.py:104} INFO - [2021-04-23 17:32:13,187] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:32:13,217] {logging_mixin.py:104} INFO - [2021-04-23 17:32:13,216] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:32:13,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.925 seconds
[2021-04-23 17:32:43,542] {scheduler_job.py:182} INFO - Started process (PID=365) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:32:43,547] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:32:43,550] {logging_mixin.py:104} INFO - [2021-04-23 17:32:43,550] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:32:44,295] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:32:44,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:32:44,348] {logging_mixin.py:104} INFO - [2021-04-23 17:32:44,347] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:32:44,364] {logging_mixin.py:104} INFO - [2021-04-23 17:32:44,364] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:32:44,374] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.836 seconds
[2021-04-23 17:33:14,555] {scheduler_job.py:182} INFO - Started process (PID=367) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:33:14,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:33:14,563] {logging_mixin.py:104} INFO - [2021-04-23 17:33:14,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:33:15,478] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:33:15,510] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:33:15,541] {logging_mixin.py:104} INFO - [2021-04-23 17:33:15,538] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:33:15,566] {logging_mixin.py:104} INFO - [2021-04-23 17:33:15,566] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:33:15,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.043 seconds
[2021-04-23 17:33:45,738] {scheduler_job.py:182} INFO - Started process (PID=369) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:33:45,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:33:45,744] {logging_mixin.py:104} INFO - [2021-04-23 17:33:45,744] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:33:46,694] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:33:46,726] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:33:46,754] {logging_mixin.py:104} INFO - [2021-04-23 17:33:46,753] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:33:46,778] {logging_mixin.py:104} INFO - [2021-04-23 17:33:46,777] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:33:46,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.062 seconds
[2021-04-23 17:34:17,126] {scheduler_job.py:182} INFO - Started process (PID=371) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:34:17,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:34:17,133] {logging_mixin.py:104} INFO - [2021-04-23 17:34:17,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:34:18,173] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:34:18,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:34:18,214] {logging_mixin.py:104} INFO - [2021-04-23 17:34:18,212] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:34:18,243] {logging_mixin.py:104} INFO - [2021-04-23 17:34:18,243] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:34:18,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.139 seconds
[2021-04-23 17:34:50,412] {scheduler_job.py:182} INFO - Started process (PID=373) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:34:50,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:34:50,489] {logging_mixin.py:104} INFO - [2021-04-23 17:34:50,488] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:34:52,831] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:34:52,876] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:34:52,903] {logging_mixin.py:104} INFO - [2021-04-23 17:34:52,900] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:34:52,955] {logging_mixin.py:104} INFO - [2021-04-23 17:34:52,954] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:34:52,973] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.650 seconds
[2021-04-23 17:35:23,860] {scheduler_job.py:182} INFO - Started process (PID=375) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:35:23,865] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:35:23,868] {logging_mixin.py:104} INFO - [2021-04-23 17:35:23,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:35:25,023] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:35:25,064] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:35:25,096] {logging_mixin.py:104} INFO - [2021-04-23 17:35:25,094] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:35:25,142] {logging_mixin.py:104} INFO - [2021-04-23 17:35:25,142] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:35:25,201] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.350 seconds
[2021-04-23 17:35:55,446] {scheduler_job.py:182} INFO - Started process (PID=377) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:35:55,453] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:35:55,456] {logging_mixin.py:104} INFO - [2021-04-23 17:35:55,456] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:35:56,675] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:35:56,703] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:35:56,727] {logging_mixin.py:104} INFO - [2021-04-23 17:35:56,725] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:35:56,750] {logging_mixin.py:104} INFO - [2021-04-23 17:35:56,750] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:35:56,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.321 seconds
[2021-04-23 17:36:27,254] {scheduler_job.py:182} INFO - Started process (PID=379) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:36:27,260] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:36:27,263] {logging_mixin.py:104} INFO - [2021-04-23 17:36:27,263] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:36:28,737] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:36:28,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:36:28,798] {logging_mixin.py:104} INFO - [2021-04-23 17:36:28,797] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:36:28,823] {logging_mixin.py:104} INFO - [2021-04-23 17:36:28,823] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:36:28,836] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.592 seconds
[2021-04-23 17:36:59,025] {scheduler_job.py:182} INFO - Started process (PID=381) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:36:59,028] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:36:59,029] {logging_mixin.py:104} INFO - [2021-04-23 17:36:59,029] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:36:59,835] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:36:59,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:36:59,883] {logging_mixin.py:104} INFO - [2021-04-23 17:36:59,882] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:36:59,909] {logging_mixin.py:104} INFO - [2021-04-23 17:36:59,908] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:36:59,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.901 seconds
[2021-04-23 17:37:31,045] {scheduler_job.py:182} INFO - Started process (PID=383) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:37:31,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:37:31,056] {logging_mixin.py:104} INFO - [2021-04-23 17:37:31,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:37:33,218] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:37:33,280] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:37:33,309] {logging_mixin.py:104} INFO - [2021-04-23 17:37:33,307] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:37:33,339] {logging_mixin.py:104} INFO - [2021-04-23 17:37:33,339] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:37:33,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.338 seconds
[2021-04-23 17:38:03,639] {scheduler_job.py:182} INFO - Started process (PID=385) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:38:03,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:38:03,644] {logging_mixin.py:104} INFO - [2021-04-23 17:38:03,644] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:38:04,578] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:38:04,672] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:38:04,716] {logging_mixin.py:104} INFO - [2021-04-23 17:38:04,709] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:38:04,734] {logging_mixin.py:104} INFO - [2021-04-23 17:38:04,734] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:38:04,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.137 seconds
[2021-04-23 17:38:34,972] {scheduler_job.py:182} INFO - Started process (PID=387) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:38:34,983] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:38:34,987] {logging_mixin.py:104} INFO - [2021-04-23 17:38:34,986] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:38:35,770] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:38:35,803] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:38:35,822] {logging_mixin.py:104} INFO - [2021-04-23 17:38:35,820] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:38:35,875] {logging_mixin.py:104} INFO - [2021-04-23 17:38:35,875] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:38:35,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.933 seconds
[2021-04-23 17:39:06,562] {scheduler_job.py:182} INFO - Started process (PID=389) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:39:06,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:39:06,575] {logging_mixin.py:104} INFO - [2021-04-23 17:39:06,574] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:39:08,899] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:39:09,050] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:39:09,098] {logging_mixin.py:104} INFO - [2021-04-23 17:39:09,095] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:39:09,138] {logging_mixin.py:104} INFO - [2021-04-23 17:39:09,137] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:39:09,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.602 seconds
[2021-04-23 17:39:39,470] {scheduler_job.py:182} INFO - Started process (PID=391) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:39:39,477] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:39:39,482] {logging_mixin.py:104} INFO - [2021-04-23 17:39:39,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:39:40,705] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:39:40,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:39:40,750] {logging_mixin.py:104} INFO - [2021-04-23 17:39:40,750] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:39:40,775] {logging_mixin.py:104} INFO - [2021-04-23 17:39:40,775] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:39:40,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.340 seconds
[2021-04-23 17:40:11,538] {scheduler_job.py:182} INFO - Started process (PID=393) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:40:11,547] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:40:11,554] {logging_mixin.py:104} INFO - [2021-04-23 17:40:11,554] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:40:13,658] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:40:13,727] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:40:13,760] {logging_mixin.py:104} INFO - [2021-04-23 17:40:13,758] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:40:13,828] {logging_mixin.py:104} INFO - [2021-04-23 17:40:13,828] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:40:13,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.345 seconds
[2021-04-23 17:40:44,157] {scheduler_job.py:182} INFO - Started process (PID=395) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:40:44,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:40:44,172] {logging_mixin.py:104} INFO - [2021-04-23 17:40:44,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:40:46,575] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:40:46,624] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:40:46,651] {logging_mixin.py:104} INFO - [2021-04-23 17:40:46,649] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:40:46,679] {logging_mixin.py:104} INFO - [2021-04-23 17:40:46,679] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:40:46,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.557 seconds
[2021-04-23 17:41:16,787] {scheduler_job.py:182} INFO - Started process (PID=397) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:41:16,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:41:16,792] {logging_mixin.py:104} INFO - [2021-04-23 17:41:16,792] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:41:17,979] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:41:18,025] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:41:18,049] {logging_mixin.py:104} INFO - [2021-04-23 17:41:18,047] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:41:18,071] {logging_mixin.py:104} INFO - [2021-04-23 17:41:18,071] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:41:18,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.341 seconds
[2021-04-23 17:41:48,343] {scheduler_job.py:182} INFO - Started process (PID=399) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:41:48,356] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:41:48,363] {logging_mixin.py:104} INFO - [2021-04-23 17:41:48,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:41:49,744] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:41:49,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:41:49,856] {logging_mixin.py:104} INFO - [2021-04-23 17:41:49,853] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:41:49,895] {logging_mixin.py:104} INFO - [2021-04-23 17:41:49,895] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:41:49,915] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.586 seconds
[2021-04-23 17:42:20,217] {scheduler_job.py:182} INFO - Started process (PID=401) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:42:20,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:42:20,225] {logging_mixin.py:104} INFO - [2021-04-23 17:42:20,223] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:42:22,167] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:42:22,207] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:42:22,229] {logging_mixin.py:104} INFO - [2021-04-23 17:42:22,228] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:42:22,278] {logging_mixin.py:104} INFO - [2021-04-23 17:42:22,277] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:42:22,295] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.086 seconds
[2021-04-23 17:42:52,384] {scheduler_job.py:182} INFO - Started process (PID=403) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:42:52,390] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:42:52,393] {logging_mixin.py:104} INFO - [2021-04-23 17:42:52,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:42:53,100] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:42:53,122] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:42:53,133] {logging_mixin.py:104} INFO - [2021-04-23 17:42:53,132] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:42:53,149] {logging_mixin.py:104} INFO - [2021-04-23 17:42:53,149] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:42:53,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.780 seconds
[2021-04-23 17:43:23,277] {scheduler_job.py:182} INFO - Started process (PID=405) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:43:23,288] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:43:23,298] {logging_mixin.py:104} INFO - [2021-04-23 17:43:23,297] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:43:24,396] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:43:24,445] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:43:24,466] {logging_mixin.py:104} INFO - [2021-04-23 17:43:24,463] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:43:24,491] {logging_mixin.py:104} INFO - [2021-04-23 17:43:24,491] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:43:24,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.240 seconds
[2021-04-23 17:43:54,787] {scheduler_job.py:182} INFO - Started process (PID=407) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:43:54,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:43:54,797] {logging_mixin.py:104} INFO - [2021-04-23 17:43:54,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:43:56,100] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:43:56,130] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:43:56,149] {logging_mixin.py:104} INFO - [2021-04-23 17:43:56,147] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:43:56,175] {logging_mixin.py:104} INFO - [2021-04-23 17:43:56,175] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:43:56,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.411 seconds
[2021-04-23 17:44:26,253] {scheduler_job.py:182} INFO - Started process (PID=409) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:44:26,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:44:26,308] {logging_mixin.py:104} INFO - [2021-04-23 17:44:26,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:44:27,198] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:44:27,228] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:44:27,253] {logging_mixin.py:104} INFO - [2021-04-23 17:44:27,252] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:44:27,274] {logging_mixin.py:104} INFO - [2021-04-23 17:44:27,274] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:44:27,287] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.041 seconds
[2021-04-23 17:44:57,496] {scheduler_job.py:182} INFO - Started process (PID=411) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:44:57,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:44:57,529] {logging_mixin.py:104} INFO - [2021-04-23 17:44:57,528] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:44:59,162] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:44:59,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:44:59,217] {logging_mixin.py:104} INFO - [2021-04-23 17:44:59,216] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:44:59,244] {logging_mixin.py:104} INFO - [2021-04-23 17:44:59,244] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:44:59,254] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.798 seconds
[2021-04-23 17:45:29,604] {scheduler_job.py:182} INFO - Started process (PID=413) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:45:29,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:45:29,621] {logging_mixin.py:104} INFO - [2021-04-23 17:45:29,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:45:32,671] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:45:32,714] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:45:32,739] {logging_mixin.py:104} INFO - [2021-04-23 17:45:32,737] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:45:32,770] {logging_mixin.py:104} INFO - [2021-04-23 17:45:32,770] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:45:32,786] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.197 seconds
[2021-04-23 17:46:02,946] {scheduler_job.py:182} INFO - Started process (PID=415) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:46:02,952] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:46:02,961] {logging_mixin.py:104} INFO - [2021-04-23 17:46:02,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:46:03,991] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:46:04,018] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:46:04,035] {logging_mixin.py:104} INFO - [2021-04-23 17:46:04,034] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:46:04,063] {logging_mixin.py:104} INFO - [2021-04-23 17:46:04,063] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:46:04,074] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.133 seconds
[2021-04-23 17:46:34,355] {scheduler_job.py:182} INFO - Started process (PID=417) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:46:34,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:46:34,372] {logging_mixin.py:104} INFO - [2021-04-23 17:46:34,372] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:46:35,759] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:46:35,800] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:46:35,822] {logging_mixin.py:104} INFO - [2021-04-23 17:46:35,820] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:46:35,848] {logging_mixin.py:104} INFO - [2021-04-23 17:46:35,848] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:46:35,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.570 seconds
[2021-04-23 17:47:05,982] {scheduler_job.py:182} INFO - Started process (PID=419) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:47:05,984] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:47:05,987] {logging_mixin.py:104} INFO - [2021-04-23 17:47:05,986] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:47:06,720] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:47:06,744] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:47:06,762] {logging_mixin.py:104} INFO - [2021-04-23 17:47:06,760] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:47:06,796] {logging_mixin.py:104} INFO - [2021-04-23 17:47:06,796] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:47:06,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.835 seconds
[2021-04-23 17:47:37,436] {scheduler_job.py:182} INFO - Started process (PID=421) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:47:37,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:47:37,448] {logging_mixin.py:104} INFO - [2021-04-23 17:47:37,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:47:38,360] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:47:38,388] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:47:38,402] {logging_mixin.py:104} INFO - [2021-04-23 17:47:38,400] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:47:38,431] {logging_mixin.py:104} INFO - [2021-04-23 17:47:38,431] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:47:38,444] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.013 seconds
[2021-04-23 17:48:09,482] {scheduler_job.py:182} INFO - Started process (PID=423) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:48:09,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:48:09,487] {logging_mixin.py:104} INFO - [2021-04-23 17:48:09,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:48:10,282] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:48:10,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:48:10,321] {logging_mixin.py:104} INFO - [2021-04-23 17:48:10,319] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:48:10,337] {logging_mixin.py:104} INFO - [2021-04-23 17:48:10,337] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:48:10,352] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.875 seconds
[2021-04-23 17:48:40,500] {scheduler_job.py:182} INFO - Started process (PID=425) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:48:40,503] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:48:40,506] {logging_mixin.py:104} INFO - [2021-04-23 17:48:40,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:48:41,282] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:48:41,316] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:48:41,334] {logging_mixin.py:104} INFO - [2021-04-23 17:48:41,333] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:48:41,373] {logging_mixin.py:104} INFO - [2021-04-23 17:48:41,373] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:48:41,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.889 seconds
[2021-04-23 17:49:11,519] {scheduler_job.py:182} INFO - Started process (PID=427) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:49:11,531] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:49:11,533] {logging_mixin.py:104} INFO - [2021-04-23 17:49:11,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:49:12,213] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:49:12,234] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:49:12,246] {logging_mixin.py:104} INFO - [2021-04-23 17:49:12,245] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:49:12,263] {logging_mixin.py:104} INFO - [2021-04-23 17:49:12,263] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:49:12,273] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.758 seconds
[2021-04-23 17:49:42,425] {scheduler_job.py:182} INFO - Started process (PID=429) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:49:42,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:49:42,436] {logging_mixin.py:104} INFO - [2021-04-23 17:49:42,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:49:43,164] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:49:43,188] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:49:43,205] {logging_mixin.py:104} INFO - [2021-04-23 17:49:43,204] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:49:43,225] {logging_mixin.py:104} INFO - [2021-04-23 17:49:43,225] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:49:43,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.816 seconds
[2021-04-23 17:50:13,389] {scheduler_job.py:182} INFO - Started process (PID=431) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:50:13,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:50:13,398] {logging_mixin.py:104} INFO - [2021-04-23 17:50:13,397] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:50:14,300] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:50:14,327] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:50:14,342] {logging_mixin.py:104} INFO - [2021-04-23 17:50:14,341] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:50:14,364] {logging_mixin.py:104} INFO - [2021-04-23 17:50:14,364] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:50:14,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.991 seconds
[2021-04-23 17:50:44,496] {scheduler_job.py:182} INFO - Started process (PID=433) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:50:44,499] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:50:44,501] {logging_mixin.py:104} INFO - [2021-04-23 17:50:44,501] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:50:45,141] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:50:45,164] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:50:45,179] {logging_mixin.py:104} INFO - [2021-04-23 17:50:45,177] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:50:45,198] {logging_mixin.py:104} INFO - [2021-04-23 17:50:45,198] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:50:45,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.717 seconds
[2021-04-23 17:51:15,522] {scheduler_job.py:182} INFO - Started process (PID=435) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:51:15,525] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:51:15,529] {logging_mixin.py:104} INFO - [2021-04-23 17:51:15,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:51:16,480] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:51:16,505] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:51:16,521] {logging_mixin.py:104} INFO - [2021-04-23 17:51:16,520] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:51:16,540] {logging_mixin.py:104} INFO - [2021-04-23 17:51:16,540] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:51:16,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.035 seconds
[2021-04-23 17:51:46,699] {scheduler_job.py:182} INFO - Started process (PID=437) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:51:46,704] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:51:46,706] {logging_mixin.py:104} INFO - [2021-04-23 17:51:46,706] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:51:47,946] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:51:47,984] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:51:48,000] {logging_mixin.py:104} INFO - [2021-04-23 17:51:47,998] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:51:48,051] {logging_mixin.py:104} INFO - [2021-04-23 17:51:48,051] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:51:48,071] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.380 seconds
[2021-04-23 17:52:18,239] {scheduler_job.py:182} INFO - Started process (PID=439) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:52:18,242] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:52:18,246] {logging_mixin.py:104} INFO - [2021-04-23 17:52:18,245] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:52:18,988] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:52:19,014] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:52:19,026] {logging_mixin.py:104} INFO - [2021-04-23 17:52:19,024] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:52:19,046] {logging_mixin.py:104} INFO - [2021-04-23 17:52:19,046] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:52:19,056] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.822 seconds
[2021-04-23 17:52:49,181] {scheduler_job.py:182} INFO - Started process (PID=441) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:52:49,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:52:49,187] {logging_mixin.py:104} INFO - [2021-04-23 17:52:49,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:52:49,927] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:52:49,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:52:49,963] {logging_mixin.py:104} INFO - [2021-04-23 17:52:49,962] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:52:49,982] {logging_mixin.py:104} INFO - [2021-04-23 17:52:49,982] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:52:49,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.823 seconds
[2021-04-23 17:53:20,102] {scheduler_job.py:182} INFO - Started process (PID=443) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:53:20,105] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:53:20,108] {logging_mixin.py:104} INFO - [2021-04-23 17:53:20,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:53:20,819] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:53:20,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:53:20,863] {logging_mixin.py:104} INFO - [2021-04-23 17:53:20,862] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:53:20,898] {logging_mixin.py:104} INFO - [2021-04-23 17:53:20,897] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:53:20,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.825 seconds
[2021-04-23 17:53:51,410] {scheduler_job.py:182} INFO - Started process (PID=445) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:53:51,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:53:51,417] {logging_mixin.py:104} INFO - [2021-04-23 17:53:51,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:53:52,340] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:53:52,370] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:53:52,387] {logging_mixin.py:104} INFO - [2021-04-23 17:53:52,385] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:53:52,411] {logging_mixin.py:104} INFO - [2021-04-23 17:53:52,411] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:53:52,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.019 seconds
[2021-04-23 17:54:22,517] {scheduler_job.py:182} INFO - Started process (PID=446) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:54:22,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:54:22,523] {logging_mixin.py:104} INFO - [2021-04-23 17:54:22,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:54:23,322] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:54:23,347] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:54:23,359] {logging_mixin.py:104} INFO - [2021-04-23 17:54:23,358] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:54:23,379] {logging_mixin.py:104} INFO - [2021-04-23 17:54:23,378] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:54:23,387] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.875 seconds
[2021-04-23 17:54:53,512] {scheduler_job.py:182} INFO - Started process (PID=448) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:54:53,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:54:53,519] {logging_mixin.py:104} INFO - [2021-04-23 17:54:53,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:54:55,017] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:54:55,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:54:55,060] {logging_mixin.py:104} INFO - [2021-04-23 17:54:55,058] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:54:55,089] {logging_mixin.py:104} INFO - [2021-04-23 17:54:55,088] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:54:55,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.598 seconds
[2021-04-23 17:55:25,217] {scheduler_job.py:182} INFO - Started process (PID=450) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:55:25,222] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:55:25,225] {logging_mixin.py:104} INFO - [2021-04-23 17:55:25,225] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:55:26,113] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:55:26,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:55:26,213] {logging_mixin.py:104} INFO - [2021-04-23 17:55:26,212] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:55:26,242] {logging_mixin.py:104} INFO - [2021-04-23 17:55:26,242] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:55:26,253] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.043 seconds
[2021-04-23 17:55:56,378] {scheduler_job.py:182} INFO - Started process (PID=453) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:55:56,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:55:56,386] {logging_mixin.py:104} INFO - [2021-04-23 17:55:56,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:55:57,112] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:55:57,144] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:55:57,160] {logging_mixin.py:104} INFO - [2021-04-23 17:55:57,159] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:55:57,184] {logging_mixin.py:104} INFO - [2021-04-23 17:55:57,184] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:55:57,194] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.827 seconds
[2021-04-23 17:56:27,364] {scheduler_job.py:182} INFO - Started process (PID=455) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:56:27,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:56:27,371] {logging_mixin.py:104} INFO - [2021-04-23 17:56:27,371] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:56:28,077] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:56:28,097] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:56:28,111] {logging_mixin.py:104} INFO - [2021-04-23 17:56:28,110] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:56:28,139] {logging_mixin.py:104} INFO - [2021-04-23 17:56:28,139] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:56:28,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.795 seconds
[2021-04-23 17:56:58,272] {scheduler_job.py:182} INFO - Started process (PID=457) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:56:58,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:56:58,278] {logging_mixin.py:104} INFO - [2021-04-23 17:56:58,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:56:59,063] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:56:59,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:56:59,133] {logging_mixin.py:104} INFO - [2021-04-23 17:56:59,132] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:56:59,164] {logging_mixin.py:104} INFO - [2021-04-23 17:56:59,164] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:56:59,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.913 seconds
[2021-04-23 17:57:29,376] {scheduler_job.py:182} INFO - Started process (PID=459) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:57:29,380] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:57:29,381] {logging_mixin.py:104} INFO - [2021-04-23 17:57:29,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:57:30,266] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:57:30,303] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:57:30,320] {logging_mixin.py:104} INFO - [2021-04-23 17:57:30,318] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:57:30,347] {logging_mixin.py:104} INFO - [2021-04-23 17:57:30,347] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:57:30,363] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.992 seconds
[2021-04-23 17:58:01,338] {scheduler_job.py:182} INFO - Started process (PID=461) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:58:01,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:58:01,380] {logging_mixin.py:104} INFO - [2021-04-23 17:58:01,380] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:58:04,857] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:58:04,894] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:58:04,925] {logging_mixin.py:104} INFO - [2021-04-23 17:58:04,923] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:58:04,978] {logging_mixin.py:104} INFO - [2021-04-23 17:58:04,977] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:58:05,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.815 seconds
[2021-04-23 17:58:37,301] {scheduler_job.py:182} INFO - Started process (PID=463) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:58:37,322] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:58:37,347] {logging_mixin.py:104} INFO - [2021-04-23 17:58:37,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:58:43,024] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:58:43,188] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:58:43,273] {logging_mixin.py:104} INFO - [2021-04-23 17:58:43,270] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:58:43,384] {logging_mixin.py:104} INFO - [2021-04-23 17:58:43,384] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:58:43,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 6.233 seconds
[2021-04-23 17:59:13,639] {scheduler_job.py:182} INFO - Started process (PID=465) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:59:13,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:59:13,648] {logging_mixin.py:104} INFO - [2021-04-23 17:59:13,647] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:59:14,516] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:59:14,546] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:59:14,566] {logging_mixin.py:104} INFO - [2021-04-23 17:59:14,563] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:59:14,618] {logging_mixin.py:104} INFO - [2021-04-23 17:59:14,618] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:59:14,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.996 seconds
[2021-04-23 17:59:45,030] {scheduler_job.py:182} INFO - Started process (PID=467) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:59:45,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 17:59:45,050] {logging_mixin.py:104} INFO - [2021-04-23 17:59:45,049] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:59:46,689] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 17:59:46,806] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 17:59:46,890] {logging_mixin.py:104} INFO - [2021-04-23 17:59:46,885] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 17:59:46,963] {logging_mixin.py:104} INFO - [2021-04-23 17:59:46,963] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 17:59:47,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.986 seconds
[2021-04-23 18:00:17,319] {scheduler_job.py:182} INFO - Started process (PID=469) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:00:17,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:00:17,328] {logging_mixin.py:104} INFO - [2021-04-23 18:00:17,327] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:00:24,540] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:00:24,659] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:00:24,708] {logging_mixin.py:104} INFO - [2021-04-23 18:00:24,698] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:00:24,776] {logging_mixin.py:104} INFO - [2021-04-23 18:00:24,776] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:00:24,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 7.490 seconds
[2021-04-23 18:00:55,045] {scheduler_job.py:182} INFO - Started process (PID=470) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:00:55,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:00:55,121] {logging_mixin.py:104} INFO - [2021-04-23 18:00:55,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:00:56,549] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:00:56,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:00:56,587] {logging_mixin.py:104} INFO - [2021-04-23 18:00:56,586] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:00:56,606] {logging_mixin.py:104} INFO - [2021-04-23 18:00:56,605] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:00:56,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.579 seconds
[2021-04-23 18:01:26,713] {scheduler_job.py:182} INFO - Started process (PID=473) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:01:26,717] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:01:26,720] {logging_mixin.py:104} INFO - [2021-04-23 18:01:26,720] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:01:27,507] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:01:27,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:01:27,556] {logging_mixin.py:104} INFO - [2021-04-23 18:01:27,555] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:01:27,580] {logging_mixin.py:104} INFO - [2021-04-23 18:01:27,580] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:01:27,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.884 seconds
[2021-04-23 18:01:57,904] {scheduler_job.py:182} INFO - Started process (PID=475) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:01:57,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:01:57,918] {logging_mixin.py:104} INFO - [2021-04-23 18:01:57,918] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:01:59,208] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:01:59,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:01:59,247] {logging_mixin.py:104} INFO - [2021-04-23 18:01:59,246] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:01:59,266] {logging_mixin.py:104} INFO - [2021-04-23 18:01:59,265] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:01:59,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.412 seconds
[2021-04-23 18:02:29,550] {scheduler_job.py:182} INFO - Started process (PID=477) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:02:29,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:02:29,567] {logging_mixin.py:104} INFO - [2021-04-23 18:02:29,567] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:02:30,995] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:02:31,029] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:02:31,042] {logging_mixin.py:104} INFO - [2021-04-23 18:02:31,041] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:02:31,078] {logging_mixin.py:104} INFO - [2021-04-23 18:02:31,077] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:02:31,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.570 seconds
[2021-04-23 18:03:01,326] {scheduler_job.py:182} INFO - Started process (PID=479) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:03:01,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:03:01,340] {logging_mixin.py:104} INFO - [2021-04-23 18:03:01,340] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:03:02,540] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:03:02,581] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:03:02,613] {logging_mixin.py:104} INFO - [2021-04-23 18:03:02,611] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:03:02,650] {logging_mixin.py:104} INFO - [2021-04-23 18:03:02,650] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:03:02,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.351 seconds
[2021-04-23 18:03:33,702] {scheduler_job.py:182} INFO - Started process (PID=481) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:03:33,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:03:33,715] {logging_mixin.py:104} INFO - [2021-04-23 18:03:33,715] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:03:35,594] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:03:35,635] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:03:35,657] {logging_mixin.py:104} INFO - [2021-04-23 18:03:35,656] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:03:35,688] {logging_mixin.py:104} INFO - [2021-04-23 18:03:35,688] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:03:35,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.017 seconds
[2021-04-23 18:04:06,036] {scheduler_job.py:182} INFO - Started process (PID=483) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:04:06,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:04:06,048] {logging_mixin.py:104} INFO - [2021-04-23 18:04:06,048] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:04:07,101] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:04:07,125] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:04:07,143] {logging_mixin.py:104} INFO - [2021-04-23 18:04:07,142] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:04:07,166] {logging_mixin.py:104} INFO - [2021-04-23 18:04:07,166] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:04:07,177] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.145 seconds
[2021-04-23 18:04:37,306] {scheduler_job.py:182} INFO - Started process (PID=485) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:04:37,310] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:04:37,313] {logging_mixin.py:104} INFO - [2021-04-23 18:04:37,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:04:38,128] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:04:38,162] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:04:38,173] {logging_mixin.py:104} INFO - [2021-04-23 18:04:38,173] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:04:38,193] {logging_mixin.py:104} INFO - [2021-04-23 18:04:38,193] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:04:38,201] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.900 seconds
[2021-04-23 18:05:08,298] {scheduler_job.py:182} INFO - Started process (PID=487) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:05:08,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:05:08,307] {logging_mixin.py:104} INFO - [2021-04-23 18:05:08,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:05:09,213] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:05:09,238] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:05:09,260] {logging_mixin.py:104} INFO - [2021-04-23 18:05:09,257] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:05:09,289] {logging_mixin.py:104} INFO - [2021-04-23 18:05:09,289] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:05:09,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.010 seconds
[2021-04-23 18:05:39,442] {scheduler_job.py:182} INFO - Started process (PID=489) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:05:39,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:05:39,453] {logging_mixin.py:104} INFO - [2021-04-23 18:05:39,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:05:40,714] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:05:40,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:05:40,793] {logging_mixin.py:104} INFO - [2021-04-23 18:05:40,791] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:05:40,840] {logging_mixin.py:104} INFO - [2021-04-23 18:05:40,840] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:05:40,855] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.417 seconds
[2021-04-23 18:06:11,012] {scheduler_job.py:182} INFO - Started process (PID=491) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:06:11,016] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:06:11,019] {logging_mixin.py:104} INFO - [2021-04-23 18:06:11,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:06:12,196] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:06:12,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:06:12,235] {logging_mixin.py:104} INFO - [2021-04-23 18:06:12,234] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:06:12,283] {logging_mixin.py:104} INFO - [2021-04-23 18:06:12,283] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:06:12,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.299 seconds
[2021-04-23 18:06:42,406] {scheduler_job.py:182} INFO - Started process (PID=493) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:06:42,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:06:42,411] {logging_mixin.py:104} INFO - [2021-04-23 18:06:42,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:06:43,136] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:06:43,156] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:06:43,172] {logging_mixin.py:104} INFO - [2021-04-23 18:06:43,171] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:06:43,188] {logging_mixin.py:104} INFO - [2021-04-23 18:06:43,188] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:06:43,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.795 seconds
[2021-04-23 18:07:13,624] {scheduler_job.py:182} INFO - Started process (PID=495) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:07:13,626] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:07:13,628] {logging_mixin.py:104} INFO - [2021-04-23 18:07:13,628] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:07:14,562] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:07:14,583] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:07:14,597] {logging_mixin.py:104} INFO - [2021-04-23 18:07:14,596] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:07:14,621] {logging_mixin.py:104} INFO - [2021-04-23 18:07:14,620] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:07:14,630] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.012 seconds
[2021-04-23 18:07:44,786] {scheduler_job.py:182} INFO - Started process (PID=497) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:07:44,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:07:44,795] {logging_mixin.py:104} INFO - [2021-04-23 18:07:44,795] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:07:45,672] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:07:45,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:07:45,716] {logging_mixin.py:104} INFO - [2021-04-23 18:07:45,715] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:07:45,737] {logging_mixin.py:104} INFO - [2021-04-23 18:07:45,737] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:07:45,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.976 seconds
[2021-04-23 18:08:16,032] {scheduler_job.py:182} INFO - Started process (PID=499) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:08:16,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:08:16,044] {logging_mixin.py:104} INFO - [2021-04-23 18:08:16,044] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:08:17,311] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:08:17,366] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:08:17,440] {logging_mixin.py:104} INFO - [2021-04-23 18:08:17,436] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:08:17,486] {logging_mixin.py:104} INFO - [2021-04-23 18:08:17,486] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:08:17,506] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.489 seconds
[2021-04-23 18:08:47,627] {scheduler_job.py:182} INFO - Started process (PID=501) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:08:47,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:08:47,631] {logging_mixin.py:104} INFO - [2021-04-23 18:08:47,631] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:08:48,226] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:08:48,245] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:08:48,258] {logging_mixin.py:104} INFO - [2021-04-23 18:08:48,256] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:08:48,273] {logging_mixin.py:104} INFO - [2021-04-23 18:08:48,273] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:08:48,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.659 seconds
[2021-04-23 18:09:18,366] {scheduler_job.py:182} INFO - Started process (PID=502) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:09:18,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:09:18,370] {logging_mixin.py:104} INFO - [2021-04-23 18:09:18,370] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:09:19,059] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:09:19,079] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:09:19,092] {logging_mixin.py:104} INFO - [2021-04-23 18:09:19,091] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:09:19,110] {logging_mixin.py:104} INFO - [2021-04-23 18:09:19,110] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:09:19,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.760 seconds
[2021-04-23 18:09:49,250] {scheduler_job.py:182} INFO - Started process (PID=505) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:09:49,255] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:09:49,259] {logging_mixin.py:104} INFO - [2021-04-23 18:09:49,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:09:51,269] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:09:51,372] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:09:51,404] {logging_mixin.py:104} INFO - [2021-04-23 18:09:51,401] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:09:51,440] {logging_mixin.py:104} INFO - [2021-04-23 18:09:51,440] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:09:51,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.238 seconds
[2021-04-23 18:10:21,953] {scheduler_job.py:182} INFO - Started process (PID=507) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:10:21,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:10:21,965] {logging_mixin.py:104} INFO - [2021-04-23 18:10:21,965] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:10:23,276] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:10:23,339] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:10:23,359] {logging_mixin.py:104} INFO - [2021-04-23 18:10:23,357] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:10:23,384] {logging_mixin.py:104} INFO - [2021-04-23 18:10:23,384] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:10:23,398] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.449 seconds
[2021-04-23 18:10:53,678] {scheduler_job.py:182} INFO - Started process (PID=509) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:10:53,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:10:53,687] {logging_mixin.py:104} INFO - [2021-04-23 18:10:53,687] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:10:54,517] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:10:54,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:10:54,555] {logging_mixin.py:104} INFO - [2021-04-23 18:10:54,552] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:10:54,588] {logging_mixin.py:104} INFO - [2021-04-23 18:10:54,588] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:10:54,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.940 seconds
[2021-04-23 18:11:25,395] {scheduler_job.py:182} INFO - Started process (PID=511) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:11:25,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:11:25,400] {logging_mixin.py:104} INFO - [2021-04-23 18:11:25,400] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:11:26,422] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:11:26,458] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:11:26,485] {logging_mixin.py:104} INFO - [2021-04-23 18:11:26,484] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:11:26,532] {logging_mixin.py:104} INFO - [2021-04-23 18:11:26,531] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:11:26,568] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.179 seconds
[2021-04-23 18:11:57,173] {scheduler_job.py:182} INFO - Started process (PID=513) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:11:57,186] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:11:57,190] {logging_mixin.py:104} INFO - [2021-04-23 18:11:57,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:11:58,765] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:11:58,874] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:11:58,964] {logging_mixin.py:104} INFO - [2021-04-23 18:11:58,962] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:11:59,017] {logging_mixin.py:104} INFO - [2021-04-23 18:11:59,016] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:11:59,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.875 seconds
[2021-04-23 18:12:29,366] {scheduler_job.py:182} INFO - Started process (PID=515) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:12:29,369] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:12:29,372] {logging_mixin.py:104} INFO - [2021-04-23 18:12:29,371] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:12:30,667] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:12:30,699] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:12:30,711] {logging_mixin.py:104} INFO - [2021-04-23 18:12:30,710] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:12:30,735] {logging_mixin.py:104} INFO - [2021-04-23 18:12:30,735] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:12:30,748] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.387 seconds
[2021-04-23 18:13:02,469] {scheduler_job.py:182} INFO - Started process (PID=517) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:13:02,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:13:02,515] {logging_mixin.py:104} INFO - [2021-04-23 18:13:02,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:13:07,330] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:13:07,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:13:08,636] {logging_mixin.py:104} INFO - [2021-04-23 18:13:08,510] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:13:09,056] {logging_mixin.py:104} INFO - [2021-04-23 18:13:09,056] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:13:09,392] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 7.147 seconds
[2021-04-23 18:13:39,687] {scheduler_job.py:182} INFO - Started process (PID=519) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:13:39,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:13:39,701] {logging_mixin.py:104} INFO - [2021-04-23 18:13:39,700] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:13:41,253] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:13:41,296] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:13:41,327] {logging_mixin.py:104} INFO - [2021-04-23 18:13:41,326] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:13:41,353] {logging_mixin.py:104} INFO - [2021-04-23 18:13:41,353] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:13:41,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.702 seconds
[2021-04-23 18:14:11,504] {scheduler_job.py:182} INFO - Started process (PID=521) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:14:11,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:14:11,508] {logging_mixin.py:104} INFO - [2021-04-23 18:14:11,508] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:14:12,178] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:14:12,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:14:12,217] {logging_mixin.py:104} INFO - [2021-04-23 18:14:12,216] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:14:12,236] {logging_mixin.py:104} INFO - [2021-04-23 18:14:12,235] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:14:12,244] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.745 seconds
[2021-04-23 18:14:42,396] {scheduler_job.py:182} INFO - Started process (PID=523) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:14:42,399] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:14:42,401] {logging_mixin.py:104} INFO - [2021-04-23 18:14:42,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:14:43,092] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:14:43,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:14:43,126] {logging_mixin.py:104} INFO - [2021-04-23 18:14:43,124] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:14:43,142] {logging_mixin.py:104} INFO - [2021-04-23 18:14:43,142] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:14:43,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.759 seconds
[2021-04-23 18:15:13,314] {scheduler_job.py:182} INFO - Started process (PID=525) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:15:13,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:15:13,321] {logging_mixin.py:104} INFO - [2021-04-23 18:15:13,321] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:15:14,600] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:15:14,626] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:15:14,641] {logging_mixin.py:104} INFO - [2021-04-23 18:15:14,640] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:15:14,664] {logging_mixin.py:104} INFO - [2021-04-23 18:15:14,663] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:15:14,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.368 seconds
[2021-04-23 18:15:44,748] {scheduler_job.py:182} INFO - Started process (PID=527) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:15:44,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:15:44,767] {logging_mixin.py:104} INFO - [2021-04-23 18:15:44,767] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:15:46,610] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:15:46,635] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:15:46,650] {logging_mixin.py:104} INFO - [2021-04-23 18:15:46,649] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:15:46,680] {logging_mixin.py:104} INFO - [2021-04-23 18:15:46,680] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:15:46,693] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.951 seconds
[2021-04-23 18:16:16,782] {scheduler_job.py:182} INFO - Started process (PID=529) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:16:16,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:16:16,789] {logging_mixin.py:104} INFO - [2021-04-23 18:16:16,789] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:16:17,644] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:16:17,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:16:17,685] {logging_mixin.py:104} INFO - [2021-04-23 18:16:17,684] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:16:17,705] {logging_mixin.py:104} INFO - [2021-04-23 18:16:17,705] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:16:17,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.938 seconds
[2021-04-23 18:16:47,836] {scheduler_job.py:182} INFO - Started process (PID=531) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:16:47,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:16:47,842] {logging_mixin.py:104} INFO - [2021-04-23 18:16:47,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:16:48,859] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:16:48,901] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:16:48,924] {logging_mixin.py:104} INFO - [2021-04-23 18:16:48,920] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:16:48,972] {logging_mixin.py:104} INFO - [2021-04-23 18:16:48,971] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:16:48,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.156 seconds
[2021-04-23 18:17:19,166] {scheduler_job.py:182} INFO - Started process (PID=533) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:17:19,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:17:19,173] {logging_mixin.py:104} INFO - [2021-04-23 18:17:19,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:17:20,212] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:17:20,254] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:17:20,300] {logging_mixin.py:104} INFO - [2021-04-23 18:17:20,299] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:17:20,333] {logging_mixin.py:104} INFO - [2021-04-23 18:17:20,333] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:17:20,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.181 seconds
[2021-04-23 18:17:50,438] {scheduler_job.py:182} INFO - Started process (PID=535) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:17:50,443] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:17:50,445] {logging_mixin.py:104} INFO - [2021-04-23 18:17:50,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:17:51,396] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:17:51,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:17:51,470] {logging_mixin.py:104} INFO - [2021-04-23 18:17:51,469] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:17:51,493] {logging_mixin.py:104} INFO - [2021-04-23 18:17:51,493] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:17:51,505] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.074 seconds
[2021-04-23 18:18:21,573] {scheduler_job.py:182} INFO - Started process (PID=537) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:18:21,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:18:21,579] {logging_mixin.py:104} INFO - [2021-04-23 18:18:21,579] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:18:22,803] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:18:22,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:18:22,859] {logging_mixin.py:104} INFO - [2021-04-23 18:18:22,857] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:18:22,938] {logging_mixin.py:104} INFO - [2021-04-23 18:18:22,937] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:18:22,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.400 seconds
[2021-04-23 18:18:53,087] {scheduler_job.py:182} INFO - Started process (PID=538) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:18:53,090] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:18:53,091] {logging_mixin.py:104} INFO - [2021-04-23 18:18:53,091] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:18:53,835] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:18:53,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:18:53,874] {logging_mixin.py:104} INFO - [2021-04-23 18:18:53,874] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:18:53,905] {logging_mixin.py:104} INFO - [2021-04-23 18:18:53,904] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:18:53,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.844 seconds
[2021-04-23 18:19:24,046] {scheduler_job.py:182} INFO - Started process (PID=540) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:19:24,049] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:19:24,051] {logging_mixin.py:104} INFO - [2021-04-23 18:19:24,050] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:19:24,727] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:19:24,749] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:19:24,759] {logging_mixin.py:104} INFO - [2021-04-23 18:19:24,758] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:19:24,776] {logging_mixin.py:104} INFO - [2021-04-23 18:19:24,776] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:19:24,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-23 18:19:54,884] {scheduler_job.py:182} INFO - Started process (PID=542) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:19:54,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:19:54,888] {logging_mixin.py:104} INFO - [2021-04-23 18:19:54,888] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:19:55,818] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:19:55,845] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:19:55,865] {logging_mixin.py:104} INFO - [2021-04-23 18:19:55,863] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:19:55,906] {logging_mixin.py:104} INFO - [2021-04-23 18:19:55,906] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:19:55,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.053 seconds
[2021-04-23 18:20:26,170] {scheduler_job.py:182} INFO - Started process (PID=545) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:20:26,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:20:26,206] {logging_mixin.py:104} INFO - [2021-04-23 18:20:26,206] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:20:26,929] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:20:26,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:20:26,960] {logging_mixin.py:104} INFO - [2021-04-23 18:20:26,959] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:20:26,977] {logging_mixin.py:104} INFO - [2021-04-23 18:20:26,977] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:20:26,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.831 seconds
[2021-04-23 18:20:57,184] {scheduler_job.py:182} INFO - Started process (PID=547) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:20:57,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:20:57,209] {logging_mixin.py:104} INFO - [2021-04-23 18:20:57,209] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:20:58,476] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:20:58,525] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:20:58,558] {logging_mixin.py:104} INFO - [2021-04-23 18:20:58,556] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:20:58,612] {logging_mixin.py:104} INFO - [2021-04-23 18:20:58,611] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:20:58,649] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.480 seconds
[2021-04-23 18:21:28,807] {scheduler_job.py:182} INFO - Started process (PID=549) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:21:28,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:21:28,829] {logging_mixin.py:104} INFO - [2021-04-23 18:21:28,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:21:30,386] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:21:30,447] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:21:30,477] {logging_mixin.py:104} INFO - [2021-04-23 18:21:30,476] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:21:30,518] {logging_mixin.py:104} INFO - [2021-04-23 18:21:30,518] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:21:30,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.745 seconds
[2021-04-23 18:22:02,044] {scheduler_job.py:182} INFO - Started process (PID=551) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:22:02,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:22:02,079] {logging_mixin.py:104} INFO - [2021-04-23 18:22:02,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:22:08,085] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:22:08,212] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:22:08,309] {logging_mixin.py:104} INFO - [2021-04-23 18:22:08,302] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:22:08,374] {logging_mixin.py:104} INFO - [2021-04-23 18:22:08,374] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:22:08,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 6.506 seconds
[2021-04-23 18:22:38,798] {scheduler_job.py:182} INFO - Started process (PID=553) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:22:38,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:22:38,804] {logging_mixin.py:104} INFO - [2021-04-23 18:22:38,804] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:22:39,662] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:22:39,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:22:39,716] {logging_mixin.py:104} INFO - [2021-04-23 18:22:39,715] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:22:39,744] {logging_mixin.py:104} INFO - [2021-04-23 18:22:39,744] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:22:39,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.962 seconds
[2021-04-23 18:23:10,471] {scheduler_job.py:182} INFO - Started process (PID=555) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:23:10,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:23:10,493] {logging_mixin.py:104} INFO - [2021-04-23 18:23:10,492] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:23:11,911] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:23:11,942] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:23:11,962] {logging_mixin.py:104} INFO - [2021-04-23 18:23:11,961] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:23:11,993] {logging_mixin.py:104} INFO - [2021-04-23 18:23:11,993] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:23:12,009] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.557 seconds
[2021-04-23 18:23:42,161] {scheduler_job.py:182} INFO - Started process (PID=557) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:23:42,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:23:42,170] {logging_mixin.py:104} INFO - [2021-04-23 18:23:42,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:23:42,779] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:23:42,802] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:23:42,814] {logging_mixin.py:104} INFO - [2021-04-23 18:23:42,813] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:23:42,831] {logging_mixin.py:104} INFO - [2021-04-23 18:23:42,831] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:23:42,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.694 seconds
[2021-04-23 18:24:12,982] {scheduler_job.py:182} INFO - Started process (PID=559) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:24:12,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:24:12,992] {logging_mixin.py:104} INFO - [2021-04-23 18:24:12,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:24:13,654] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:24:13,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:24:13,693] {logging_mixin.py:104} INFO - [2021-04-23 18:24:13,692] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:24:13,710] {logging_mixin.py:104} INFO - [2021-04-23 18:24:13,710] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:24:13,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.744 seconds
[2021-04-23 18:24:44,004] {scheduler_job.py:182} INFO - Started process (PID=561) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:24:44,019] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:24:44,033] {logging_mixin.py:104} INFO - [2021-04-23 18:24:44,033] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:24:45,515] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:24:45,579] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:24:45,604] {logging_mixin.py:104} INFO - [2021-04-23 18:24:45,603] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:24:45,654] {logging_mixin.py:104} INFO - [2021-04-23 18:24:45,654] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:24:45,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.684 seconds
[2021-04-23 18:25:15,947] {scheduler_job.py:182} INFO - Started process (PID=563) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:25:15,954] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:25:15,961] {logging_mixin.py:104} INFO - [2021-04-23 18:25:15,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:25:26,258] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:25:26,365] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:25:26,412] {logging_mixin.py:104} INFO - [2021-04-23 18:25:26,406] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:25:26,488] {logging_mixin.py:104} INFO - [2021-04-23 18:25:26,488] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:25:26,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 10.580 seconds
[2021-04-23 18:25:56,843] {scheduler_job.py:182} INFO - Started process (PID=565) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:25:56,848] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:25:56,851] {logging_mixin.py:104} INFO - [2021-04-23 18:25:56,851] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:25:58,180] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:25:58,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:25:58,262] {logging_mixin.py:104} INFO - [2021-04-23 18:25:58,261] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:25:58,296] {logging_mixin.py:104} INFO - [2021-04-23 18:25:58,296] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:25:58,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.479 seconds
[2021-04-23 18:26:28,480] {scheduler_job.py:182} INFO - Started process (PID=567) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:26:28,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:26:28,494] {logging_mixin.py:104} INFO - [2021-04-23 18:26:28,494] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:26:29,456] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:26:29,481] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:26:29,494] {logging_mixin.py:104} INFO - [2021-04-23 18:26:29,492] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:26:29,512] {logging_mixin.py:104} INFO - [2021-04-23 18:26:29,512] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:26:29,521] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.054 seconds
[2021-04-23 18:26:59,660] {scheduler_job.py:182} INFO - Started process (PID=569) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:26:59,666] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:26:59,674] {logging_mixin.py:104} INFO - [2021-04-23 18:26:59,674] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:27:00,756] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:27:00,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:27:00,812] {logging_mixin.py:104} INFO - [2021-04-23 18:27:00,810] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:27:00,838] {logging_mixin.py:104} INFO - [2021-04-23 18:27:00,838] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:27:00,852] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.204 seconds
[2021-04-23 18:27:31,093] {scheduler_job.py:182} INFO - Started process (PID=571) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:27:31,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:27:31,099] {logging_mixin.py:104} INFO - [2021-04-23 18:27:31,098] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:27:32,240] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:27:32,294] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:27:32,349] {logging_mixin.py:104} INFO - [2021-04-23 18:27:32,347] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:27:32,415] {logging_mixin.py:104} INFO - [2021-04-23 18:27:32,415] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:27:32,438] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.357 seconds
[2021-04-23 18:28:02,591] {scheduler_job.py:182} INFO - Started process (PID=573) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:28:02,564] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:28:02,572] {logging_mixin.py:104} INFO - [2021-04-23 18:28:02,572] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:28:03,777] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:28:03,823] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:28:03,841] {logging_mixin.py:104} INFO - [2021-04-23 18:28:03,838] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:28:03,877] {logging_mixin.py:104} INFO - [2021-04-23 18:28:03,877] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:28:03,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.342 seconds
[2021-04-23 18:28:34,585] {scheduler_job.py:182} INFO - Started process (PID=575) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:28:34,593] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:28:34,597] {logging_mixin.py:104} INFO - [2021-04-23 18:28:34,597] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:28:36,711] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:28:36,760] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:28:36,785] {logging_mixin.py:104} INFO - [2021-04-23 18:28:36,783] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:28:36,821] {logging_mixin.py:104} INFO - [2021-04-23 18:28:36,821] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:28:36,842] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.305 seconds
[2021-04-23 18:29:07,193] {scheduler_job.py:182} INFO - Started process (PID=577) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:29:07,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:29:07,199] {logging_mixin.py:104} INFO - [2021-04-23 18:29:07,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:29:08,354] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:29:08,401] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:29:08,422] {logging_mixin.py:104} INFO - [2021-04-23 18:29:08,419] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:29:08,456] {logging_mixin.py:104} INFO - [2021-04-23 18:29:08,456] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:29:08,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.283 seconds
[2021-04-23 18:29:38,682] {scheduler_job.py:182} INFO - Started process (PID=579) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:29:38,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:29:38,690] {logging_mixin.py:104} INFO - [2021-04-23 18:29:38,690] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:29:39,535] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:29:39,578] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:29:39,600] {logging_mixin.py:104} INFO - [2021-04-23 18:29:39,598] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:29:39,630] {logging_mixin.py:104} INFO - [2021-04-23 18:29:39,630] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:29:39,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.961 seconds
[2021-04-23 18:30:09,790] {scheduler_job.py:182} INFO - Started process (PID=581) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:30:09,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:30:09,796] {logging_mixin.py:104} INFO - [2021-04-23 18:30:09,796] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:30:10,597] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:30:10,622] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:30:10,639] {logging_mixin.py:104} INFO - [2021-04-23 18:30:10,638] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:30:10,660] {logging_mixin.py:104} INFO - [2021-04-23 18:30:10,660] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:30:10,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.885 seconds
[2021-04-23 18:30:40,829] {scheduler_job.py:182} INFO - Started process (PID=583) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:30:40,832] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:30:40,835] {logging_mixin.py:104} INFO - [2021-04-23 18:30:40,835] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:30:41,648] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:30:41,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:30:41,699] {logging_mixin.py:104} INFO - [2021-04-23 18:30:41,698] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:30:41,728] {logging_mixin.py:104} INFO - [2021-04-23 18:30:41,728] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:30:41,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.936 seconds
[2021-04-23 18:31:11,895] {scheduler_job.py:182} INFO - Started process (PID=585) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:31:11,899] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:31:11,901] {logging_mixin.py:104} INFO - [2021-04-23 18:31:11,900] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:31:13,179] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:31:13,232] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:31:13,278] {logging_mixin.py:104} INFO - [2021-04-23 18:31:13,275] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:31:13,342] {logging_mixin.py:104} INFO - [2021-04-23 18:31:13,341] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:31:13,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.468 seconds
[2021-04-23 18:31:43,455] {scheduler_job.py:182} INFO - Started process (PID=587) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:31:43,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:31:43,462] {logging_mixin.py:104} INFO - [2021-04-23 18:31:43,461] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:31:44,822] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:31:44,883] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:31:44,921] {logging_mixin.py:104} INFO - [2021-04-23 18:31:44,917] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:31:44,973] {logging_mixin.py:104} INFO - [2021-04-23 18:31:44,973] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:31:44,999] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.548 seconds
[2021-04-23 18:32:15,204] {scheduler_job.py:182} INFO - Started process (PID=589) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:32:15,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:32:15,209] {logging_mixin.py:104} INFO - [2021-04-23 18:32:15,209] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:32:16,315] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:32:16,346] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:32:16,364] {logging_mixin.py:104} INFO - [2021-04-23 18:32:16,362] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:32:16,391] {logging_mixin.py:104} INFO - [2021-04-23 18:32:16,391] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:32:16,409] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.209 seconds
[2021-04-23 18:32:46,509] {scheduler_job.py:182} INFO - Started process (PID=590) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:32:46,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:32:46,515] {logging_mixin.py:104} INFO - [2021-04-23 18:32:46,514] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:32:47,707] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:32:47,748] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:32:47,774] {logging_mixin.py:104} INFO - [2021-04-23 18:32:47,772] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:32:47,808] {logging_mixin.py:104} INFO - [2021-04-23 18:32:47,808] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:32:47,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.316 seconds
[2021-04-23 18:33:17,985] {scheduler_job.py:182} INFO - Started process (PID=592) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:33:17,989] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:33:17,991] {logging_mixin.py:104} INFO - [2021-04-23 18:33:17,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:33:18,834] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:33:18,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:33:19,006] {logging_mixin.py:104} INFO - [2021-04-23 18:33:18,999] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:33:19,064] {logging_mixin.py:104} INFO - [2021-04-23 18:33:19,064] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:33:19,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.115 seconds
[2021-04-23 18:33:49,192] {scheduler_job.py:182} INFO - Started process (PID=594) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:33:49,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:33:49,197] {logging_mixin.py:104} INFO - [2021-04-23 18:33:49,196] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:33:49,892] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:33:49,922] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:33:49,933] {logging_mixin.py:104} INFO - [2021-04-23 18:33:49,932] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:33:49,950] {logging_mixin.py:104} INFO - [2021-04-23 18:33:49,950] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:33:49,962] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.774 seconds
[2021-04-23 18:34:20,058] {scheduler_job.py:182} INFO - Started process (PID=596) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:34:20,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:34:20,063] {logging_mixin.py:104} INFO - [2021-04-23 18:34:20,063] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:34:20,886] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:34:20,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:34:20,985] {logging_mixin.py:104} INFO - [2021-04-23 18:34:20,983] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:34:21,016] {logging_mixin.py:104} INFO - [2021-04-23 18:34:21,016] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:34:21,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.988 seconds
[2021-04-23 18:34:51,262] {scheduler_job.py:182} INFO - Started process (PID=598) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:34:51,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:34:51,290] {logging_mixin.py:104} INFO - [2021-04-23 18:34:51,290] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:35:03,266] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:35:03,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:35:03,410] {logging_mixin.py:104} INFO - [2021-04-23 18:35:03,383] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:35:03,552] {logging_mixin.py:104} INFO - [2021-04-23 18:35:03,552] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:35:03,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 12.429 seconds
[2021-04-23 18:35:34,203] {scheduler_job.py:182} INFO - Started process (PID=600) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:35:34,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:35:34,207] {logging_mixin.py:104} INFO - [2021-04-23 18:35:34,207] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:35:35,169] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:35:35,194] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:35:35,218] {logging_mixin.py:104} INFO - [2021-04-23 18:35:35,217] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:35:35,242] {logging_mixin.py:104} INFO - [2021-04-23 18:35:35,242] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:35:35,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.061 seconds
[2021-04-23 18:36:05,381] {scheduler_job.py:182} INFO - Started process (PID=602) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:36:05,384] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:36:05,385] {logging_mixin.py:104} INFO - [2021-04-23 18:36:05,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:36:06,027] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:36:06,058] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:36:06,073] {logging_mixin.py:104} INFO - [2021-04-23 18:36:06,072] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:36:06,093] {logging_mixin.py:104} INFO - [2021-04-23 18:36:06,093] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:36:06,104] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.726 seconds
[2021-04-23 18:36:36,168] {scheduler_job.py:182} INFO - Started process (PID=604) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:36:36,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:36:36,172] {logging_mixin.py:104} INFO - [2021-04-23 18:36:36,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:36:36,865] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:36:36,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:36:36,896] {logging_mixin.py:104} INFO - [2021-04-23 18:36:36,894] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:36:36,916] {logging_mixin.py:104} INFO - [2021-04-23 18:36:36,916] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:36:36,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.761 seconds
[2021-04-23 18:37:07,078] {scheduler_job.py:182} INFO - Started process (PID=606) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:37:07,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:37:07,082] {logging_mixin.py:104} INFO - [2021-04-23 18:37:07,082] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:37:07,699] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:37:07,717] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:37:07,728] {logging_mixin.py:104} INFO - [2021-04-23 18:37:07,727] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:37:07,743] {logging_mixin.py:104} INFO - [2021-04-23 18:37:07,743] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:37:07,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.678 seconds
[2021-04-23 18:37:37,851] {scheduler_job.py:182} INFO - Started process (PID=608) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:37:37,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:37:37,860] {logging_mixin.py:104} INFO - [2021-04-23 18:37:37,860] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:37:38,842] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:37:38,867] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:37:38,879] {logging_mixin.py:104} INFO - [2021-04-23 18:37:38,878] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:37:38,901] {logging_mixin.py:104} INFO - [2021-04-23 18:37:38,900] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:37:38,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.067 seconds
[2021-04-23 18:38:09,023] {scheduler_job.py:182} INFO - Started process (PID=610) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:38:09,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:38:09,028] {logging_mixin.py:104} INFO - [2021-04-23 18:38:09,028] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:38:09,677] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:38:09,697] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:38:09,708] {logging_mixin.py:104} INFO - [2021-04-23 18:38:09,707] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:38:09,724] {logging_mixin.py:104} INFO - [2021-04-23 18:38:09,724] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:38:09,733] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-23 18:38:39,843] {scheduler_job.py:182} INFO - Started process (PID=612) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:38:39,853] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:38:39,857] {logging_mixin.py:104} INFO - [2021-04-23 18:38:39,857] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:38:40,669] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:38:40,697] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:38:40,717] {logging_mixin.py:104} INFO - [2021-04-23 18:38:40,715] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:38:40,746] {logging_mixin.py:104} INFO - [2021-04-23 18:38:40,746] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:38:40,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.925 seconds
[2021-04-23 18:39:10,888] {scheduler_job.py:182} INFO - Started process (PID=614) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:39:10,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:39:10,897] {logging_mixin.py:104} INFO - [2021-04-23 18:39:10,897] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:39:11,786] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:39:11,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:39:11,835] {logging_mixin.py:104} INFO - [2021-04-23 18:39:11,834] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:39:11,854] {logging_mixin.py:104} INFO - [2021-04-23 18:39:11,853] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:39:11,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.983 seconds
[2021-04-23 18:39:41,997] {scheduler_job.py:182} INFO - Started process (PID=616) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:39:42,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:39:42,002] {logging_mixin.py:104} INFO - [2021-04-23 18:39:42,002] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:39:42,615] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:39:42,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:39:42,651] {logging_mixin.py:104} INFO - [2021-04-23 18:39:42,650] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:39:42,668] {logging_mixin.py:104} INFO - [2021-04-23 18:39:42,668] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:39:42,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.693 seconds
[2021-04-23 18:40:12,777] {scheduler_job.py:182} INFO - Started process (PID=618) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:40:12,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:40:12,785] {logging_mixin.py:104} INFO - [2021-04-23 18:40:12,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:40:13,475] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:40:13,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:40:13,510] {logging_mixin.py:104} INFO - [2021-04-23 18:40:13,509] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:40:13,531] {logging_mixin.py:104} INFO - [2021-04-23 18:40:13,531] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:40:13,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.766 seconds
[2021-04-23 18:40:43,635] {scheduler_job.py:182} INFO - Started process (PID=620) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:40:43,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:40:43,639] {logging_mixin.py:104} INFO - [2021-04-23 18:40:43,639] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:40:44,245] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:40:44,266] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:40:44,279] {logging_mixin.py:104} INFO - [2021-04-23 18:40:44,278] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:40:44,296] {logging_mixin.py:104} INFO - [2021-04-23 18:40:44,296] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:40:44,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.675 seconds
[2021-04-23 18:41:14,397] {scheduler_job.py:182} INFO - Started process (PID=622) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:41:14,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:41:14,404] {logging_mixin.py:104} INFO - [2021-04-23 18:41:14,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:41:15,033] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:41:15,052] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:41:15,069] {logging_mixin.py:104} INFO - [2021-04-23 18:41:15,068] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:41:15,086] {logging_mixin.py:104} INFO - [2021-04-23 18:41:15,085] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:41:15,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.700 seconds
[2021-04-23 18:41:45,623] {scheduler_job.py:182} INFO - Started process (PID=625) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:41:45,638] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:41:45,643] {logging_mixin.py:104} INFO - [2021-04-23 18:41:45,642] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:41:46,672] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:41:46,706] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:41:46,731] {logging_mixin.py:104} INFO - [2021-04-23 18:41:46,730] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:41:46,767] {logging_mixin.py:104} INFO - [2021-04-23 18:41:46,767] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:41:46,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.166 seconds
[2021-04-23 18:42:16,937] {scheduler_job.py:182} INFO - Started process (PID=627) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:42:16,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:42:16,943] {logging_mixin.py:104} INFO - [2021-04-23 18:42:16,943] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:42:17,595] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:42:17,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:42:17,628] {logging_mixin.py:104} INFO - [2021-04-23 18:42:17,627] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:42:17,650] {logging_mixin.py:104} INFO - [2021-04-23 18:42:17,650] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:42:17,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.725 seconds
[2021-04-23 18:42:47,789] {scheduler_job.py:182} INFO - Started process (PID=629) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:42:47,791] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:42:47,793] {logging_mixin.py:104} INFO - [2021-04-23 18:42:47,792] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:42:48,442] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:42:48,466] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:42:48,486] {logging_mixin.py:104} INFO - [2021-04-23 18:42:48,484] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:42:48,519] {logging_mixin.py:104} INFO - [2021-04-23 18:42:48,518] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:42:48,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.747 seconds
[2021-04-23 18:43:18,671] {scheduler_job.py:182} INFO - Started process (PID=631) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:43:18,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:43:18,675] {logging_mixin.py:104} INFO - [2021-04-23 18:43:18,675] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:43:19,344] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:43:19,368] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:43:19,383] {logging_mixin.py:104} INFO - [2021-04-23 18:43:19,380] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:43:19,405] {logging_mixin.py:104} INFO - [2021-04-23 18:43:19,405] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:43:19,416] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.750 seconds
[2021-04-23 18:43:49,632] {scheduler_job.py:182} INFO - Started process (PID=633) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:43:49,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:43:49,637] {logging_mixin.py:104} INFO - [2021-04-23 18:43:49,636] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:43:50,317] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:43:50,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:43:50,361] {logging_mixin.py:104} INFO - [2021-04-23 18:43:50,359] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:43:50,382] {logging_mixin.py:104} INFO - [2021-04-23 18:43:50,382] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:43:50,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.763 seconds
[2021-04-23 18:44:20,489] {scheduler_job.py:182} INFO - Started process (PID=635) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:44:20,503] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:44:20,506] {logging_mixin.py:104} INFO - [2021-04-23 18:44:20,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:44:21,262] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:44:21,298] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:44:21,313] {logging_mixin.py:104} INFO - [2021-04-23 18:44:21,311] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:44:21,337] {logging_mixin.py:104} INFO - [2021-04-23 18:44:21,336] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:44:21,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.865 seconds
[2021-04-23 18:44:51,466] {scheduler_job.py:182} INFO - Started process (PID=637) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:44:51,470] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:44:51,472] {logging_mixin.py:104} INFO - [2021-04-23 18:44:51,471] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:44:52,290] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:44:52,330] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:44:52,353] {logging_mixin.py:104} INFO - [2021-04-23 18:44:52,351] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:44:52,401] {logging_mixin.py:104} INFO - [2021-04-23 18:44:52,400] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:44:52,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.969 seconds
[2021-04-23 18:45:22,598] {scheduler_job.py:182} INFO - Started process (PID=639) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:45:22,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:45:22,607] {logging_mixin.py:104} INFO - [2021-04-23 18:45:22,607] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:45:23,673] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:45:23,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:45:23,718] {logging_mixin.py:104} INFO - [2021-04-23 18:45:23,716] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:45:23,744] {logging_mixin.py:104} INFO - [2021-04-23 18:45:23,744] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:45:23,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.185 seconds
[2021-04-23 18:45:53,893] {scheduler_job.py:182} INFO - Started process (PID=641) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:45:53,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:45:53,906] {logging_mixin.py:104} INFO - [2021-04-23 18:45:53,905] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:45:54,713] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:45:54,744] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:45:54,758] {logging_mixin.py:104} INFO - [2021-04-23 18:45:54,756] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:45:54,777] {logging_mixin.py:104} INFO - [2021-04-23 18:45:54,777] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:45:54,785] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.900 seconds
[2021-04-23 18:46:24,916] {scheduler_job.py:182} INFO - Started process (PID=643) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:46:24,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:46:24,921] {logging_mixin.py:104} INFO - [2021-04-23 18:46:24,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:46:25,644] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:46:25,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:46:25,681] {logging_mixin.py:104} INFO - [2021-04-23 18:46:25,680] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:46:25,697] {logging_mixin.py:104} INFO - [2021-04-23 18:46:25,697] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:46:25,709] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.798 seconds
[2021-04-23 18:46:55,817] {scheduler_job.py:182} INFO - Started process (PID=645) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:46:55,821] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:46:55,825] {logging_mixin.py:104} INFO - [2021-04-23 18:46:55,824] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:46:56,523] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:46:56,563] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:46:56,578] {logging_mixin.py:104} INFO - [2021-04-23 18:46:56,577] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:46:56,597] {logging_mixin.py:104} INFO - [2021-04-23 18:46:56,597] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:46:56,607] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.796 seconds
[2021-04-23 18:47:26,767] {scheduler_job.py:182} INFO - Started process (PID=647) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:47:26,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:47:26,771] {logging_mixin.py:104} INFO - [2021-04-23 18:47:26,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:47:27,523] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:47:27,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:47:27,570] {logging_mixin.py:104} INFO - [2021-04-23 18:47:27,569] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:47:27,592] {logging_mixin.py:104} INFO - [2021-04-23 18:47:27,592] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:47:27,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.839 seconds
[2021-04-23 18:47:57,725] {scheduler_job.py:182} INFO - Started process (PID=649) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:47:57,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:47:57,731] {logging_mixin.py:104} INFO - [2021-04-23 18:47:57,731] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:47:58,528] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:47:58,560] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:47:58,573] {logging_mixin.py:104} INFO - [2021-04-23 18:47:58,572] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:47:58,589] {logging_mixin.py:104} INFO - [2021-04-23 18:47:58,589] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:47:58,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.876 seconds
[2021-04-23 18:48:28,729] {scheduler_job.py:182} INFO - Started process (PID=651) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:48:28,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:48:28,739] {logging_mixin.py:104} INFO - [2021-04-23 18:48:28,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:48:29,506] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:48:29,530] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:48:29,545] {logging_mixin.py:104} INFO - [2021-04-23 18:48:29,543] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:48:29,586] {logging_mixin.py:104} INFO - [2021-04-23 18:48:29,586] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:48:29,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.873 seconds
[2021-04-23 18:48:59,730] {scheduler_job.py:182} INFO - Started process (PID=653) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:48:59,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:48:59,737] {logging_mixin.py:104} INFO - [2021-04-23 18:48:59,737] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:49:00,399] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:49:00,428] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:49:00,440] {logging_mixin.py:104} INFO - [2021-04-23 18:49:00,439] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:49:00,463] {logging_mixin.py:104} INFO - [2021-04-23 18:49:00,463] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:49:00,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.749 seconds
[2021-04-23 18:49:30,604] {scheduler_job.py:182} INFO - Started process (PID=655) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:49:30,607] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:49:30,610] {logging_mixin.py:104} INFO - [2021-04-23 18:49:30,609] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:49:31,263] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:49:31,280] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:49:31,290] {logging_mixin.py:104} INFO - [2021-04-23 18:49:31,289] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:49:31,309] {logging_mixin.py:104} INFO - [2021-04-23 18:49:31,309] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:49:31,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.720 seconds
[2021-04-23 18:50:01,414] {scheduler_job.py:182} INFO - Started process (PID=657) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:50:01,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:50:01,418] {logging_mixin.py:104} INFO - [2021-04-23 18:50:01,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:50:02,048] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:50:02,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:50:02,085] {logging_mixin.py:104} INFO - [2021-04-23 18:50:02,084] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:50:02,103] {logging_mixin.py:104} INFO - [2021-04-23 18:50:02,102] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:50:02,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.700 seconds
[2021-04-23 18:50:32,239] {scheduler_job.py:182} INFO - Started process (PID=659) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:50:32,244] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:50:32,247] {logging_mixin.py:104} INFO - [2021-04-23 18:50:32,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:50:48,190] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:50:48,322] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:50:48,369] {logging_mixin.py:104} INFO - [2021-04-23 18:50:48,363] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:50:48,468] {logging_mixin.py:104} INFO - [2021-04-23 18:50:48,468] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:50:48,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 16.359 seconds
[2021-04-23 18:51:22,181] {scheduler_job.py:182} INFO - Started process (PID=661) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:51:22,199] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 18:51:22,208] {logging_mixin.py:104} INFO - [2021-04-23 18:51:22,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:51:25,644] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 18:51:25,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 18:51:25,704] {logging_mixin.py:104} INFO - [2021-04-23 18:51:25,702] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 18:51:25,740] {logging_mixin.py:104} INFO - [2021-04-23 18:51:25,740] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 18:51:25,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.598 seconds
[2021-04-23 19:22:14,304] {scheduler_job.py:182} INFO - Started process (PID=663) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:22:14,454] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:22:14,596] {logging_mixin.py:104} INFO - [2021-04-23 19:22:14,596] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:23:38,698] {scheduler_job.py:182} INFO - Started process (PID=666) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:23:38,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:23:38,939] {logging_mixin.py:104} INFO - [2021-04-23 19:23:38,938] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:24:04,122] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:24:06,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:24:10,851] {logging_mixin.py:104} INFO - [2021-04-23 19:24:10,434] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:24:13,092] {logging_mixin.py:104} INFO - [2021-04-23 19:24:13,069] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:24:14,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 36.061 seconds
[2021-04-23 19:24:52,620] {scheduler_job.py:182} INFO - Started process (PID=669) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:24:53,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:24:53,343] {logging_mixin.py:104} INFO - [2021-04-23 19:24:53,341] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:25:15,674] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:25:17,709] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:25:20,627] {logging_mixin.py:104} INFO - [2021-04-23 19:25:20,449] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:25:21,729] {logging_mixin.py:104} INFO - [2021-04-23 19:25:21,724] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:25:23,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 30.554 seconds
[2021-04-23 19:25:59,726] {scheduler_job.py:182} INFO - Started process (PID=671) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:25:59,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:26:00,044] {logging_mixin.py:104} INFO - [2021-04-23 19:26:00,043] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:26:14,019] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:26:14,531] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:26:14,946] {logging_mixin.py:104} INFO - [2021-04-23 19:26:14,926] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:26:16,380] {logging_mixin.py:104} INFO - [2021-04-23 19:26:16,379] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:26:16,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 17.356 seconds
[2021-04-23 19:26:48,175] {scheduler_job.py:182} INFO - Started process (PID=673) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:26:48,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:26:48,197] {logging_mixin.py:104} INFO - [2021-04-23 19:26:48,197] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:26:50,258] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:26:50,458] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:26:50,568] {logging_mixin.py:104} INFO - [2021-04-23 19:26:50,562] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:26:50,713] {logging_mixin.py:104} INFO - [2021-04-23 19:26:50,713] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:26:50,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.671 seconds
[2021-04-23 19:44:03,204] {scheduler_job.py:182} INFO - Started process (PID=675) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:44:03,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:44:03,382] {logging_mixin.py:104} INFO - [2021-04-23 19:44:03,366] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:44:24,359] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:44:25,967] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:44:31,104] {logging_mixin.py:104} INFO - [2021-04-23 19:44:30,409] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:44:32,221] {logging_mixin.py:104} INFO - [2021-04-23 19:44:32,221] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:44:32,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 29.394 seconds
[2021-04-23 19:52:20,724] {scheduler_job.py:182} INFO - Started process (PID=677) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:52:20,765] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:52:20,776] {logging_mixin.py:104} INFO - [2021-04-23 19:52:20,776] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:52:23,110] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:52:23,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:52:23,280] {logging_mixin.py:104} INFO - [2021-04-23 19:52:23,270] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:52:23,411] {logging_mixin.py:104} INFO - [2021-04-23 19:52:23,411] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:52:23,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.829 seconds
[2021-04-23 19:52:54,632] {scheduler_job.py:182} INFO - Started process (PID=679) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:52:54,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:52:54,654] {logging_mixin.py:104} INFO - [2021-04-23 19:52:54,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:52:55,990] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:52:56,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:52:56,074] {logging_mixin.py:104} INFO - [2021-04-23 19:52:56,071] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:52:56,131] {logging_mixin.py:104} INFO - [2021-04-23 19:52:56,130] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:52:56,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.562 seconds
[2021-04-23 19:53:26,674] {scheduler_job.py:182} INFO - Started process (PID=681) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:53:26,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:53:26,684] {logging_mixin.py:104} INFO - [2021-04-23 19:53:26,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:53:27,494] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:53:27,521] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:53:27,545] {logging_mixin.py:104} INFO - [2021-04-23 19:53:27,543] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:53:27,579] {logging_mixin.py:104} INFO - [2021-04-23 19:53:27,579] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:53:27,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.940 seconds
[2021-04-23 19:53:57,736] {scheduler_job.py:182} INFO - Started process (PID=683) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:53:57,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:53:57,742] {logging_mixin.py:104} INFO - [2021-04-23 19:53:57,741] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:53:58,046] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:53:58,063] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:53:58,079] {logging_mixin.py:104} INFO - [2021-04-23 19:53:58,077] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:53:58,100] {logging_mixin.py:104} INFO - [2021-04-23 19:53:58,100] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:53:58,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.386 seconds
[2021-04-23 19:54:28,231] {scheduler_job.py:182} INFO - Started process (PID=685) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:54:28,233] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:54:28,234] {logging_mixin.py:104} INFO - [2021-04-23 19:54:28,234] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:54:28,597] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:54:28,616] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:54:28,629] {logging_mixin.py:104} INFO - [2021-04-23 19:54:28,628] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:54:28,649] {logging_mixin.py:104} INFO - [2021-04-23 19:54:28,649] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:54:28,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.432 seconds
[2021-04-23 19:54:58,826] {scheduler_job.py:182} INFO - Started process (PID=687) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:54:58,838] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:54:58,843] {logging_mixin.py:104} INFO - [2021-04-23 19:54:58,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:54:59,353] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:54:59,373] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:54:59,391] {logging_mixin.py:104} INFO - [2021-04-23 19:54:59,390] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:54:59,413] {logging_mixin.py:104} INFO - [2021-04-23 19:54:59,412] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:54:59,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.601 seconds
[2021-04-23 19:55:30,167] {scheduler_job.py:182} INFO - Started process (PID=689) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:55:30,175] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:55:30,181] {logging_mixin.py:104} INFO - [2021-04-23 19:55:30,181] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:55:30,998] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:55:31,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:55:31,047] {logging_mixin.py:104} INFO - [2021-04-23 19:55:31,045] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:55:31,072] {logging_mixin.py:104} INFO - [2021-04-23 19:55:31,070] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:55:31,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.928 seconds
[2021-04-23 19:56:01,276] {scheduler_job.py:182} INFO - Started process (PID=691) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:56:01,280] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:56:01,282] {logging_mixin.py:104} INFO - [2021-04-23 19:56:01,281] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:56:01,788] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:56:01,814] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:56:01,829] {logging_mixin.py:104} INFO - [2021-04-23 19:56:01,827] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:56:01,848] {logging_mixin.py:104} INFO - [2021-04-23 19:56:01,848] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:56:01,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.589 seconds
[2021-04-23 19:56:32,028] {scheduler_job.py:182} INFO - Started process (PID=693) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:56:32,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:56:32,036] {logging_mixin.py:104} INFO - [2021-04-23 19:56:32,036] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:56:32,405] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:56:32,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:56:32,452] {logging_mixin.py:104} INFO - [2021-04-23 19:56:32,450] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:56:32,490] {logging_mixin.py:104} INFO - [2021-04-23 19:56:32,490] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:56:32,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.481 seconds
[2021-04-23 19:57:02,597] {scheduler_job.py:182} INFO - Started process (PID=694) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:57:02,599] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:57:02,602] {logging_mixin.py:104} INFO - [2021-04-23 19:57:02,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:57:02,909] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:57:02,931] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:57:02,944] {logging_mixin.py:104} INFO - [2021-04-23 19:57:02,943] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:57:02,963] {logging_mixin.py:104} INFO - [2021-04-23 19:57:02,963] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:57:02,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.381 seconds
[2021-04-23 19:57:36,337] {scheduler_job.py:182} INFO - Started process (PID=697) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:57:36,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:57:36,580] {logging_mixin.py:104} INFO - [2021-04-23 19:57:36,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:57:38,848] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:57:38,937] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:57:38,986] {logging_mixin.py:104} INFO - [2021-04-23 19:57:38,982] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:57:39,055] {logging_mixin.py:104} INFO - [2021-04-23 19:57:39,055] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:57:39,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.922 seconds
[2021-04-23 19:58:09,146] {scheduler_job.py:182} INFO - Started process (PID=699) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:58:09,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:58:09,155] {logging_mixin.py:104} INFO - [2021-04-23 19:58:09,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:58:09,478] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:58:09,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:58:09,512] {logging_mixin.py:104} INFO - [2021-04-23 19:58:09,511] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:58:09,531] {logging_mixin.py:104} INFO - [2021-04-23 19:58:09,531] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:58:09,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.396 seconds
[2021-04-23 19:58:39,735] {scheduler_job.py:182} INFO - Started process (PID=701) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:58:39,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:58:39,741] {logging_mixin.py:104} INFO - [2021-04-23 19:58:39,741] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:58:40,052] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:58:40,087] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:58:40,105] {logging_mixin.py:104} INFO - [2021-04-23 19:58:40,103] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:58:40,126] {logging_mixin.py:104} INFO - [2021-04-23 19:58:40,126] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:58:40,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.415 seconds
[2021-04-23 19:59:11,270] {scheduler_job.py:182} INFO - Started process (PID=703) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:59:11,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:59:11,291] {logging_mixin.py:104} INFO - [2021-04-23 19:59:11,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:59:12,357] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:59:12,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:59:12,436] {logging_mixin.py:104} INFO - [2021-04-23 19:59:12,433] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:59:12,494] {logging_mixin.py:104} INFO - [2021-04-23 19:59:12,494] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:59:12,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.275 seconds
[2021-04-23 19:59:42,608] {scheduler_job.py:182} INFO - Started process (PID=705) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:59:42,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 19:59:42,616] {logging_mixin.py:104} INFO - [2021-04-23 19:59:42,616] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:59:43,040] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 19:59:43,068] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 19:59:43,087] {logging_mixin.py:104} INFO - [2021-04-23 19:59:43,085] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 19:59:43,110] {logging_mixin.py:104} INFO - [2021-04-23 19:59:43,110] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 19:59:43,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.520 seconds
[2021-04-23 20:00:00,857] {scheduler_job.py:182} INFO - Started process (PID=706) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:00:00,862] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:00:00,868] {logging_mixin.py:104} INFO - [2021-04-23 20:00:00,867] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:00:01,447] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:00:01,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:00:01,531] {logging_mixin.py:104} INFO - [2021-04-23 20:00:01,529] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:00:01,557] {logging_mixin.py:104} INFO - [2021-04-23 20:00:01,557] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:00:01,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.725 seconds
[2021-04-23 20:00:31,672] {scheduler_job.py:182} INFO - Started process (PID=708) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:00:31,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:00:31,677] {logging_mixin.py:104} INFO - [2021-04-23 20:00:31,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:00:32,123] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:00:32,154] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:00:32,170] {logging_mixin.py:104} INFO - [2021-04-23 20:00:32,169] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:00:32,208] {logging_mixin.py:104} INFO - [2021-04-23 20:00:32,208] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:00:32,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.555 seconds
[2021-04-23 20:01:02,349] {scheduler_job.py:182} INFO - Started process (PID=710) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:01:02,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:01:02,354] {logging_mixin.py:104} INFO - [2021-04-23 20:01:02,354] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:01:02,771] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:01:02,803] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:01:02,825] {logging_mixin.py:104} INFO - [2021-04-23 20:01:02,823] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:01:02,861] {logging_mixin.py:104} INFO - [2021-04-23 20:01:02,861] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:01:02,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.538 seconds
[2021-04-23 20:01:32,938] {scheduler_job.py:182} INFO - Started process (PID=712) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:01:32,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:01:32,944] {logging_mixin.py:104} INFO - [2021-04-23 20:01:32,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:01:33,374] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:01:33,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:01:33,415] {logging_mixin.py:104} INFO - [2021-04-23 20:01:33,414] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:01:33,438] {logging_mixin.py:104} INFO - [2021-04-23 20:01:33,438] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:01:33,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.523 seconds
[2021-04-23 20:02:03,557] {scheduler_job.py:182} INFO - Started process (PID=714) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:02:03,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:02:03,562] {logging_mixin.py:104} INFO - [2021-04-23 20:02:03,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:02:03,899] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:02:03,934] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:02:03,955] {logging_mixin.py:104} INFO - [2021-04-23 20:02:03,952] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:02:03,974] {logging_mixin.py:104} INFO - [2021-04-23 20:02:03,974] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:02:03,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.434 seconds
[2021-04-23 20:02:34,092] {scheduler_job.py:182} INFO - Started process (PID=716) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:02:34,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:02:34,101] {logging_mixin.py:104} INFO - [2021-04-23 20:02:34,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:02:34,753] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:02:34,791] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:02:34,824] {logging_mixin.py:104} INFO - [2021-04-23 20:02:34,821] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:02:34,867] {logging_mixin.py:104} INFO - [2021-04-23 20:02:34,866] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:02:34,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.804 seconds
[2021-04-23 20:03:05,030] {scheduler_job.py:182} INFO - Started process (PID=718) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:03:05,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:03:05,039] {logging_mixin.py:104} INFO - [2021-04-23 20:03:05,038] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:03:05,568] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:03:05,593] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:03:05,611] {logging_mixin.py:104} INFO - [2021-04-23 20:03:05,610] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:03:05,638] {logging_mixin.py:104} INFO - [2021-04-23 20:03:05,638] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:03:05,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.630 seconds
[2021-04-23 20:03:35,771] {scheduler_job.py:182} INFO - Started process (PID=720) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:03:35,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:03:35,776] {logging_mixin.py:104} INFO - [2021-04-23 20:03:35,775] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:03:36,295] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:03:36,322] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:03:36,340] {logging_mixin.py:104} INFO - [2021-04-23 20:03:36,339] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:03:36,358] {logging_mixin.py:104} INFO - [2021-04-23 20:03:36,358] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:03:36,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.602 seconds
[2021-04-23 20:04:06,482] {scheduler_job.py:182} INFO - Started process (PID=722) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:04:06,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:04:06,494] {logging_mixin.py:104} INFO - [2021-04-23 20:04:06,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:04:07,060] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:04:07,088] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:04:07,105] {logging_mixin.py:104} INFO - [2021-04-23 20:04:07,103] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:04:07,127] {logging_mixin.py:104} INFO - [2021-04-23 20:04:07,127] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:04:07,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.667 seconds
[2021-04-23 20:04:37,678] {scheduler_job.py:182} INFO - Started process (PID=724) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:04:37,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:04:37,685] {logging_mixin.py:104} INFO - [2021-04-23 20:04:37,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:04:38,273] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:04:38,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:04:38,319] {logging_mixin.py:104} INFO - [2021-04-23 20:04:38,317] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:04:38,350] {logging_mixin.py:104} INFO - [2021-04-23 20:04:38,349] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:04:38,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.694 seconds
[2021-04-23 20:05:08,594] {scheduler_job.py:182} INFO - Started process (PID=726) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:05:08,597] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:05:08,601] {logging_mixin.py:104} INFO - [2021-04-23 20:05:08,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:05:09,110] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:05:09,136] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:05:09,155] {logging_mixin.py:104} INFO - [2021-04-23 20:05:09,153] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:05:09,175] {logging_mixin.py:104} INFO - [2021-04-23 20:05:09,175] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:05:09,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.598 seconds
[2021-04-23 20:05:39,275] {scheduler_job.py:182} INFO - Started process (PID=728) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:05:39,278] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:05:39,280] {logging_mixin.py:104} INFO - [2021-04-23 20:05:39,280] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:05:39,653] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:05:39,676] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:05:39,695] {logging_mixin.py:104} INFO - [2021-04-23 20:05:39,693] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:05:39,737] {logging_mixin.py:104} INFO - [2021-04-23 20:05:39,736] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:05:39,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.476 seconds
[2021-04-23 20:06:09,850] {scheduler_job.py:182} INFO - Started process (PID=730) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:06:09,854] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:06:09,856] {logging_mixin.py:104} INFO - [2021-04-23 20:06:09,856] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:06:10,212] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:06:10,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:06:10,241] {logging_mixin.py:104} INFO - [2021-04-23 20:06:10,240] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:06:10,260] {logging_mixin.py:104} INFO - [2021-04-23 20:06:10,260] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:06:10,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.424 seconds
[2021-04-23 20:06:40,452] {scheduler_job.py:182} INFO - Started process (PID=732) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:06:40,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:06:40,458] {logging_mixin.py:104} INFO - [2021-04-23 20:06:40,458] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:06:41,126] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:06:41,162] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:06:41,184] {logging_mixin.py:104} INFO - [2021-04-23 20:06:41,183] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:06:41,210] {logging_mixin.py:104} INFO - [2021-04-23 20:06:41,210] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:06:41,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.781 seconds
[2021-04-23 20:07:17,870] {scheduler_job.py:182} INFO - Started process (PID=734) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:07:17,902] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:07:17,910] {logging_mixin.py:104} INFO - [2021-04-23 20:07:17,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:07:20,244] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:07:20,318] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:07:20,403] {logging_mixin.py:104} INFO - [2021-04-23 20:07:20,391] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:07:20,456] {logging_mixin.py:104} INFO - [2021-04-23 20:07:20,456] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:07:20,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.715 seconds
[2021-04-23 20:07:50,583] {scheduler_job.py:182} INFO - Started process (PID=736) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:07:50,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:07:50,588] {logging_mixin.py:104} INFO - [2021-04-23 20:07:50,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:07:50,890] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:07:50,909] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:07:50,923] {logging_mixin.py:104} INFO - [2021-04-23 20:07:50,922] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:07:50,942] {logging_mixin.py:104} INFO - [2021-04-23 20:07:50,942] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:07:50,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.373 seconds
[2021-04-23 20:08:21,075] {scheduler_job.py:182} INFO - Started process (PID=738) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:08:21,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:08:21,080] {logging_mixin.py:104} INFO - [2021-04-23 20:08:21,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:08:21,458] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:08:21,474] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:08:21,488] {logging_mixin.py:104} INFO - [2021-04-23 20:08:21,487] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:08:21,510] {logging_mixin.py:104} INFO - [2021-04-23 20:08:21,510] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:08:21,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.450 seconds
[2021-04-23 20:08:51,577] {scheduler_job.py:182} INFO - Started process (PID=740) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:08:51,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:08:51,590] {logging_mixin.py:104} INFO - [2021-04-23 20:08:51,590] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:08:51,965] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:08:51,985] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:08:51,999] {logging_mixin.py:104} INFO - [2021-04-23 20:08:51,998] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:08:52,017] {logging_mixin.py:104} INFO - [2021-04-23 20:08:52,017] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:08:52,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.455 seconds
[2021-04-23 20:09:22,094] {scheduler_job.py:182} INFO - Started process (PID=742) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:09:22,096] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:09:22,098] {logging_mixin.py:104} INFO - [2021-04-23 20:09:22,098] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:09:22,577] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:09:22,597] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:09:22,619] {logging_mixin.py:104} INFO - [2021-04-23 20:09:22,618] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:09:22,640] {logging_mixin.py:104} INFO - [2021-04-23 20:09:22,640] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:09:22,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.564 seconds
[2021-04-23 20:09:52,764] {scheduler_job.py:182} INFO - Started process (PID=744) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:09:52,767] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:09:52,769] {logging_mixin.py:104} INFO - [2021-04-23 20:09:52,769] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:09:53,319] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:09:53,359] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:09:53,389] {logging_mixin.py:104} INFO - [2021-04-23 20:09:53,385] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:09:53,441] {logging_mixin.py:104} INFO - [2021-04-23 20:09:53,433] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:09:53,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.719 seconds
[2021-04-23 20:10:23,781] {scheduler_job.py:182} INFO - Started process (PID=746) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:10:23,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:10:23,785] {logging_mixin.py:104} INFO - [2021-04-23 20:10:23,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:10:24,182] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:10:24,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:10:24,270] {logging_mixin.py:104} INFO - [2021-04-23 20:10:24,261] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:10:24,319] {logging_mixin.py:104} INFO - [2021-04-23 20:10:24,319] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:10:24,336] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.561 seconds
[2021-04-23 20:11:01,472] {scheduler_job.py:182} INFO - Started process (PID=748) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:11:01,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:11:01,765] {logging_mixin.py:104} INFO - [2021-04-23 20:11:01,764] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:11:09,040] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:11:09,187] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:11:09,291] {logging_mixin.py:104} INFO - [2021-04-23 20:11:09,280] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:11:09,396] {logging_mixin.py:104} INFO - [2021-04-23 20:11:09,396] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:11:09,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 9.494 seconds
[2021-04-23 20:11:40,682] {scheduler_job.py:182} INFO - Started process (PID=751) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:11:40,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:11:40,732] {logging_mixin.py:104} INFO - [2021-04-23 20:11:40,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:11:42,157] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:11:42,192] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:11:42,234] {logging_mixin.py:104} INFO - [2021-04-23 20:11:42,232] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:11:42,282] {logging_mixin.py:104} INFO - [2021-04-23 20:11:42,282] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:11:42,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.661 seconds
[2021-04-23 20:12:13,038] {scheduler_job.py:182} INFO - Started process (PID=753) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:12:13,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:12:13,053] {logging_mixin.py:104} INFO - [2021-04-23 20:12:13,052] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:12:13,672] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:12:13,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:12:13,738] {logging_mixin.py:104} INFO - [2021-04-23 20:12:13,735] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:12:13,776] {logging_mixin.py:104} INFO - [2021-04-23 20:12:13,776] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:12:13,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.772 seconds
[2021-04-23 20:12:44,270] {scheduler_job.py:182} INFO - Started process (PID=755) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:12:44,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:12:44,280] {logging_mixin.py:104} INFO - [2021-04-23 20:12:44,280] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:12:44,795] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:12:44,830] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:12:44,847] {logging_mixin.py:104} INFO - [2021-04-23 20:12:44,845] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:12:44,875] {logging_mixin.py:104} INFO - [2021-04-23 20:12:44,875] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:12:44,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.620 seconds
[2021-04-23 20:13:15,581] {scheduler_job.py:182} INFO - Started process (PID=757) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:13:15,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:13:15,589] {logging_mixin.py:104} INFO - [2021-04-23 20:13:15,589] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:13:16,035] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:13:16,058] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:13:16,078] {logging_mixin.py:104} INFO - [2021-04-23 20:13:16,076] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:13:16,119] {logging_mixin.py:104} INFO - [2021-04-23 20:13:16,119] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:13:16,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.567 seconds
[2021-04-23 20:13:48,048] {scheduler_job.py:182} INFO - Started process (PID=759) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:13:48,058] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:13:48,069] {logging_mixin.py:104} INFO - [2021-04-23 20:13:48,068] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:13:49,373] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:13:49,411] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:13:49,453] {logging_mixin.py:104} INFO - [2021-04-23 20:13:49,450] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:13:49,526] {logging_mixin.py:104} INFO - [2021-04-23 20:13:49,526] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:13:49,549] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.513 seconds
[2021-04-23 20:14:19,712] {scheduler_job.py:182} INFO - Started process (PID=761) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:14:19,714] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:14:19,715] {logging_mixin.py:104} INFO - [2021-04-23 20:14:19,715] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:14:20,074] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:14:20,094] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:14:20,110] {logging_mixin.py:104} INFO - [2021-04-23 20:14:20,108] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:14:20,129] {logging_mixin.py:104} INFO - [2021-04-23 20:14:20,129] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:14:20,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.429 seconds
[2021-04-23 20:14:52,176] {scheduler_job.py:182} INFO - Started process (PID=763) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:14:52,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:14:52,268] {logging_mixin.py:104} INFO - [2021-04-23 20:14:52,245] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:14:54,291] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:14:54,414] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:14:54,625] {logging_mixin.py:104} INFO - [2021-04-23 20:14:54,572] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:14:54,774] {logging_mixin.py:104} INFO - [2021-04-23 20:14:54,773] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:14:54,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.665 seconds
[2021-04-23 20:15:24,985] {scheduler_job.py:182} INFO - Started process (PID=764) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:15:24,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:15:25,000] {logging_mixin.py:104} INFO - [2021-04-23 20:15:25,000] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:15:25,422] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:15:25,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:15:25,452] {logging_mixin.py:104} INFO - [2021-04-23 20:15:25,451] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:15:25,471] {logging_mixin.py:104} INFO - [2021-04-23 20:15:25,470] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:15:25,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.513 seconds
[2021-04-23 20:15:55,679] {scheduler_job.py:182} INFO - Started process (PID=767) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:15:55,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:15:55,690] {logging_mixin.py:104} INFO - [2021-04-23 20:15:55,689] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:15:56,153] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:15:56,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:15:56,189] {logging_mixin.py:104} INFO - [2021-04-23 20:15:56,187] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:15:56,226] {logging_mixin.py:104} INFO - [2021-04-23 20:15:56,225] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:15:56,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.570 seconds
[2021-04-23 20:16:26,421] {scheduler_job.py:182} INFO - Started process (PID=769) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:16:26,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:16:26,429] {logging_mixin.py:104} INFO - [2021-04-23 20:16:26,429] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:16:27,101] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:16:27,142] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:16:27,168] {logging_mixin.py:104} INFO - [2021-04-23 20:16:27,166] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:16:27,204] {logging_mixin.py:104} INFO - [2021-04-23 20:16:27,204] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:16:27,217] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.801 seconds
[2021-04-23 20:16:57,335] {scheduler_job.py:182} INFO - Started process (PID=771) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:16:57,337] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:16:57,340] {logging_mixin.py:104} INFO - [2021-04-23 20:16:57,340] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:16:57,728] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:16:57,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:16:57,779] {logging_mixin.py:104} INFO - [2021-04-23 20:16:57,777] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:16:57,815] {logging_mixin.py:104} INFO - [2021-04-23 20:16:57,815] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:16:57,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.505 seconds
[2021-04-23 20:17:28,050] {scheduler_job.py:182} INFO - Started process (PID=773) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:17:28,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:17:28,057] {logging_mixin.py:104} INFO - [2021-04-23 20:17:28,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:17:28,449] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:17:28,484] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:17:28,498] {logging_mixin.py:104} INFO - [2021-04-23 20:17:28,497] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:17:28,539] {logging_mixin.py:104} INFO - [2021-04-23 20:17:28,539] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:17:28,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.512 seconds
[2021-04-23 20:17:58,660] {scheduler_job.py:182} INFO - Started process (PID=775) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:17:58,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:17:58,665] {logging_mixin.py:104} INFO - [2021-04-23 20:17:58,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:17:58,979] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:17:59,003] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:17:59,017] {logging_mixin.py:104} INFO - [2021-04-23 20:17:59,015] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:17:59,040] {logging_mixin.py:104} INFO - [2021-04-23 20:17:59,040] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:17:59,050] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.395 seconds
[2021-04-23 20:18:29,349] {scheduler_job.py:182} INFO - Started process (PID=777) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:18:29,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:18:29,359] {logging_mixin.py:104} INFO - [2021-04-23 20:18:29,359] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:18:29,685] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:18:29,711] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:18:29,729] {logging_mixin.py:104} INFO - [2021-04-23 20:18:29,727] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:18:29,749] {logging_mixin.py:104} INFO - [2021-04-23 20:18:29,749] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:18:29,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.422 seconds
[2021-04-23 20:18:59,861] {scheduler_job.py:182} INFO - Started process (PID=779) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:18:59,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:18:59,873] {logging_mixin.py:104} INFO - [2021-04-23 20:18:59,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:19:00,199] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:19:00,216] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:19:00,228] {logging_mixin.py:104} INFO - [2021-04-23 20:19:00,227] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:19:00,250] {logging_mixin.py:104} INFO - [2021-04-23 20:19:00,250] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:19:00,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.402 seconds
[2021-04-23 20:19:30,375] {scheduler_job.py:182} INFO - Started process (PID=781) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:19:30,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:19:30,385] {logging_mixin.py:104} INFO - [2021-04-23 20:19:30,384] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:19:30,759] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:19:30,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:19:30,789] {logging_mixin.py:104} INFO - [2021-04-23 20:19:30,787] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:19:30,807] {logging_mixin.py:104} INFO - [2021-04-23 20:19:30,807] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:19:30,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.451 seconds
[2021-04-23 20:20:00,965] {scheduler_job.py:182} INFO - Started process (PID=783) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:20:00,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:20:00,970] {logging_mixin.py:104} INFO - [2021-04-23 20:20:00,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:20:01,447] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:20:01,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:20:01,485] {logging_mixin.py:104} INFO - [2021-04-23 20:20:01,484] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:20:01,524] {logging_mixin.py:104} INFO - [2021-04-23 20:20:01,524] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:20:01,535] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.579 seconds
[2021-04-23 20:20:31,697] {scheduler_job.py:182} INFO - Started process (PID=785) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:20:31,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:20:31,704] {logging_mixin.py:104} INFO - [2021-04-23 20:20:31,704] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:20:32,062] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:20:32,084] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:20:32,100] {logging_mixin.py:104} INFO - [2021-04-23 20:20:32,099] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:20:32,131] {logging_mixin.py:104} INFO - [2021-04-23 20:20:32,130] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:20:32,146] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.454 seconds
[2021-04-23 20:21:05,998] {scheduler_job.py:182} INFO - Started process (PID=787) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:21:06,028] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:21:06,319] {logging_mixin.py:104} INFO - [2021-04-23 20:21:06,064] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:21:08,833] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:21:08,867] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:21:08,930] {logging_mixin.py:104} INFO - [2021-04-23 20:21:08,923] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:21:09,012] {logging_mixin.py:104} INFO - [2021-04-23 20:21:09,012] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:21:09,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.170 seconds
[2021-04-23 20:21:39,301] {scheduler_job.py:182} INFO - Started process (PID=789) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:21:39,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:21:39,307] {logging_mixin.py:104} INFO - [2021-04-23 20:21:39,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:21:39,674] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:21:39,693] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:21:39,706] {logging_mixin.py:104} INFO - [2021-04-23 20:21:39,704] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:21:39,729] {logging_mixin.py:104} INFO - [2021-04-23 20:21:39,729] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:21:39,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.443 seconds
[2021-04-23 20:22:09,885] {scheduler_job.py:182} INFO - Started process (PID=791) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:22:09,892] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:22:09,894] {logging_mixin.py:104} INFO - [2021-04-23 20:22:09,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:22:10,474] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:22:10,496] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:22:10,519] {logging_mixin.py:104} INFO - [2021-04-23 20:22:10,517] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:22:10,560] {logging_mixin.py:104} INFO - [2021-04-23 20:22:10,559] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:22:10,579] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.700 seconds
[2021-04-23 20:22:40,875] {scheduler_job.py:182} INFO - Started process (PID=793) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:22:40,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:22:40,889] {logging_mixin.py:104} INFO - [2021-04-23 20:22:40,889] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:22:41,747] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:22:41,797] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:22:41,827] {logging_mixin.py:104} INFO - [2021-04-23 20:22:41,824] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:22:41,867] {logging_mixin.py:104} INFO - [2021-04-23 20:22:41,867] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:22:41,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.025 seconds
[2021-04-23 20:23:12,051] {scheduler_job.py:182} INFO - Started process (PID=795) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:23:12,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:23:12,059] {logging_mixin.py:104} INFO - [2021-04-23 20:23:12,058] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:23:12,766] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:23:12,805] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:23:12,857] {logging_mixin.py:104} INFO - [2021-04-23 20:23:12,855] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:23:12,894] {logging_mixin.py:104} INFO - [2021-04-23 20:23:12,894] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:23:12,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.870 seconds
[2021-04-23 20:23:43,058] {scheduler_job.py:182} INFO - Started process (PID=797) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:23:43,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:23:43,065] {logging_mixin.py:104} INFO - [2021-04-23 20:23:43,064] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:23:43,487] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:23:43,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:23:43,556] {logging_mixin.py:104} INFO - [2021-04-23 20:23:43,554] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:23:43,592] {logging_mixin.py:104} INFO - [2021-04-23 20:23:43,592] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:23:43,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.567 seconds
[2021-04-23 20:24:14,728] {scheduler_job.py:182} INFO - Started process (PID=799) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:24:14,765] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:24:14,772] {logging_mixin.py:104} INFO - [2021-04-23 20:24:14,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:24:16,569] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:24:16,617] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:24:16,648] {logging_mixin.py:104} INFO - [2021-04-23 20:24:16,647] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:24:16,679] {logging_mixin.py:104} INFO - [2021-04-23 20:24:16,679] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:24:16,693] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.981 seconds
[2021-04-23 20:24:46,887] {scheduler_job.py:182} INFO - Started process (PID=801) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:24:46,890] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:24:46,893] {logging_mixin.py:104} INFO - [2021-04-23 20:24:46,893] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:24:47,301] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:24:47,321] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:24:47,343] {logging_mixin.py:104} INFO - [2021-04-23 20:24:47,340] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:24:47,374] {logging_mixin.py:104} INFO - [2021-04-23 20:24:47,374] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:24:47,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.511 seconds
[2021-04-23 20:25:09,562] {scheduler_job.py:182} INFO - Started process (PID=802) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:25:09,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:25:09,569] {logging_mixin.py:104} INFO - [2021-04-23 20:25:09,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:25:10,002] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:25:10,025] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:25:10,057] {logging_mixin.py:104} INFO - [2021-04-23 20:25:10,056] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:25:10,090] {logging_mixin.py:104} INFO - [2021-04-23 20:25:10,089] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:25:10,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.558 seconds
[2021-04-23 20:25:40,895] {scheduler_job.py:182} INFO - Started process (PID=804) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:25:40,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:25:40,902] {logging_mixin.py:104} INFO - [2021-04-23 20:25:40,902] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:25:41,487] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:25:41,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:25:41,546] {logging_mixin.py:104} INFO - [2021-04-23 20:25:41,544] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:25:41,574] {logging_mixin.py:104} INFO - [2021-04-23 20:25:41,573] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T17:00:00+00:00
[2021-04-23 20:25:41,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.701 seconds
[2021-04-23 20:26:11,929] {scheduler_job.py:182} INFO - Started process (PID=806) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:26:11,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:26:11,934] {logging_mixin.py:104} INFO - [2021-04-23 20:26:11,933] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:26:12,275] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:26:12,319] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:26:12,350] {logging_mixin.py:104} INFO - [2021-04-23 20:26:12,348] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:26:12,373] {logging_mixin.py:104} INFO - [2021-04-23 20:26:12,373] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:26:12,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.497 seconds
[2021-04-23 20:26:42,581] {scheduler_job.py:182} INFO - Started process (PID=808) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:26:42,585] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:26:42,587] {logging_mixin.py:104} INFO - [2021-04-23 20:26:42,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:26:43,161] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:26:43,189] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:26:43,219] {logging_mixin.py:104} INFO - [2021-04-23 20:26:43,212] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:26:43,256] {logging_mixin.py:104} INFO - [2021-04-23 20:26:43,256] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:26:43,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.691 seconds
[2021-04-23 20:27:13,684] {scheduler_job.py:182} INFO - Started process (PID=810) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:27:13,688] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:27:13,689] {logging_mixin.py:104} INFO - [2021-04-23 20:27:13,689] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:27:14,023] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:27:14,056] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:27:14,074] {logging_mixin.py:104} INFO - [2021-04-23 20:27:14,072] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:27:14,096] {logging_mixin.py:104} INFO - [2021-04-23 20:27:14,096] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:27:14,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.430 seconds
[2021-04-23 20:27:44,602] {scheduler_job.py:182} INFO - Started process (PID=812) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:27:44,607] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:27:44,611] {logging_mixin.py:104} INFO - [2021-04-23 20:27:44,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:27:44,947] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:27:44,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:27:44,986] {logging_mixin.py:104} INFO - [2021-04-23 20:27:44,984] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:27:45,019] {logging_mixin.py:104} INFO - [2021-04-23 20:27:45,019] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:27:45,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.435 seconds
[2021-04-23 20:28:15,164] {scheduler_job.py:182} INFO - Started process (PID=814) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:28:15,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:28:15,170] {logging_mixin.py:104} INFO - [2021-04-23 20:28:15,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:28:15,480] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:28:15,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:28:15,521] {logging_mixin.py:104} INFO - [2021-04-23 20:28:15,519] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:28:15,540] {logging_mixin.py:104} INFO - [2021-04-23 20:28:15,540] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:28:15,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.390 seconds
[2021-04-23 20:28:45,656] {scheduler_job.py:182} INFO - Started process (PID=816) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:28:45,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:28:45,662] {logging_mixin.py:104} INFO - [2021-04-23 20:28:45,662] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:28:45,969] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:28:45,984] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:28:45,998] {logging_mixin.py:104} INFO - [2021-04-23 20:28:45,997] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:28:46,017] {logging_mixin.py:104} INFO - [2021-04-23 20:28:46,017] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:28:46,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.378 seconds
[2021-04-23 20:29:16,133] {scheduler_job.py:182} INFO - Started process (PID=818) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:29:16,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:29:16,137] {logging_mixin.py:104} INFO - [2021-04-23 20:29:16,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:29:16,419] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:29:16,437] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:29:16,450] {logging_mixin.py:104} INFO - [2021-04-23 20:29:16,448] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:29:16,469] {logging_mixin.py:104} INFO - [2021-04-23 20:29:16,469] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:29:16,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.351 seconds
[2021-04-23 20:29:47,230] {scheduler_job.py:182} INFO - Started process (PID=820) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:29:47,232] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:29:47,234] {logging_mixin.py:104} INFO - [2021-04-23 20:29:47,234] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:29:47,523] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:29:47,541] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:29:47,555] {logging_mixin.py:104} INFO - [2021-04-23 20:29:47,554] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:29:47,574] {logging_mixin.py:104} INFO - [2021-04-23 20:29:47,574] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:29:47,584] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.358 seconds
[2021-04-23 20:30:32,041] {scheduler_job.py:182} INFO - Started process (PID=822) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:30:32,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:30:32,244] {logging_mixin.py:104} INFO - [2021-04-23 20:30:32,242] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:30:43,302] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:30:43,488] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:30:43,603] {logging_mixin.py:104} INFO - [2021-04-23 20:30:43,593] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:30:43,723] {logging_mixin.py:104} INFO - [2021-04-23 20:30:43,722] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:30:43,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 12.010 seconds
[2021-04-23 20:31:14,249] {scheduler_job.py:182} INFO - Started process (PID=824) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:31:14,255] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:31:14,262] {logging_mixin.py:104} INFO - [2021-04-23 20:31:14,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:31:14,708] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:31:14,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:31:14,767] {logging_mixin.py:104} INFO - [2021-04-23 20:31:14,762] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:31:14,797] {logging_mixin.py:104} INFO - [2021-04-23 20:31:14,797] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:31:14,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.570 seconds
[2021-04-23 20:31:45,173] {scheduler_job.py:182} INFO - Started process (PID=826) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:31:45,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:31:45,182] {logging_mixin.py:104} INFO - [2021-04-23 20:31:45,181] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:31:45,734] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:31:45,751] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:31:45,765] {logging_mixin.py:104} INFO - [2021-04-23 20:31:45,764] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:31:45,783] {logging_mixin.py:104} INFO - [2021-04-23 20:31:45,783] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:31:45,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.635 seconds
[2021-04-23 20:32:15,896] {scheduler_job.py:182} INFO - Started process (PID=828) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:32:15,899] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:32:15,903] {logging_mixin.py:104} INFO - [2021-04-23 20:32:15,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:32:16,929] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:32:17,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:32:17,122] {logging_mixin.py:104} INFO - [2021-04-23 20:32:17,119] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:32:17,228] {logging_mixin.py:104} INFO - [2021-04-23 20:32:17,227] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:32:17,265] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.376 seconds
[2021-04-23 20:32:47,848] {scheduler_job.py:182} INFO - Started process (PID=830) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:32:47,854] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:32:47,859] {logging_mixin.py:104} INFO - [2021-04-23 20:32:47,858] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:32:48,649] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:32:48,715] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:32:48,771] {logging_mixin.py:104} INFO - [2021-04-23 20:32:48,765] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:32:48,867] {logging_mixin.py:104} INFO - [2021-04-23 20:32:48,866] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:32:48,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.084 seconds
[2021-04-23 20:33:20,783] {scheduler_job.py:182} INFO - Started process (PID=832) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:33:20,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:33:20,812] {logging_mixin.py:104} INFO - [2021-04-23 20:33:20,811] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:33:23,491] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:33:23,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:33:23,617] {logging_mixin.py:104} INFO - [2021-04-23 20:33:23,610] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:33:23,670] {logging_mixin.py:104} INFO - [2021-04-23 20:33:23,670] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:33:23,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.163 seconds
[2021-04-23 20:33:54,621] {scheduler_job.py:182} INFO - Started process (PID=834) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:33:54,636] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:33:54,649] {logging_mixin.py:104} INFO - [2021-04-23 20:33:54,649] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:33:56,522] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:33:56,562] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:33:56,596] {logging_mixin.py:104} INFO - [2021-04-23 20:33:56,593] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:33:56,729] {logging_mixin.py:104} INFO - [2021-04-23 20:33:56,729] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:33:56,765] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.173 seconds
[2021-04-23 20:34:27,183] {scheduler_job.py:182} INFO - Started process (PID=836) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:34:27,317] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:34:27,326] {logging_mixin.py:104} INFO - [2021-04-23 20:34:27,325] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:34:28,887] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:34:28,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:34:29,075] {logging_mixin.py:104} INFO - [2021-04-23 20:34:29,072] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:34:29,606] {logging_mixin.py:104} INFO - [2021-04-23 20:34:29,601] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:34:29,746] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.675 seconds
[2021-04-23 20:35:00,347] {scheduler_job.py:182} INFO - Started process (PID=838) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:35:00,350] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:35:00,352] {logging_mixin.py:104} INFO - [2021-04-23 20:35:00,352] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:35:00,824] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:35:00,869] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:35:00,887] {logging_mixin.py:104} INFO - [2021-04-23 20:35:00,884] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:35:00,920] {logging_mixin.py:104} INFO - [2021-04-23 20:35:00,920] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T18:00:00+00:00
[2021-04-23 20:35:00,946] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.608 seconds
[2021-04-23 20:35:31,058] {scheduler_job.py:182} INFO - Started process (PID=840) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:35:31,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:35:31,065] {logging_mixin.py:104} INFO - [2021-04-23 20:35:31,065] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:35:31,534] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:35:31,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:35:31,585] {logging_mixin.py:104} INFO - [2021-04-23 20:35:31,581] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:35:31,621] {logging_mixin.py:104} INFO - [2021-04-23 20:35:31,620] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:35:31,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.584 seconds
[2021-04-23 20:36:01,803] {scheduler_job.py:182} INFO - Started process (PID=842) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:36:01,809] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:36:01,812] {logging_mixin.py:104} INFO - [2021-04-23 20:36:01,811] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:36:02,159] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:36:02,182] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:36:02,196] {logging_mixin.py:104} INFO - [2021-04-23 20:36:02,195] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:36:02,217] {logging_mixin.py:104} INFO - [2021-04-23 20:36:02,217] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:36:02,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.432 seconds
[2021-04-23 20:36:32,392] {scheduler_job.py:182} INFO - Started process (PID=844) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:36:32,396] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:36:32,398] {logging_mixin.py:104} INFO - [2021-04-23 20:36:32,398] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:36:32,700] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:36:32,718] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:36:32,733] {logging_mixin.py:104} INFO - [2021-04-23 20:36:32,732] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:36:32,751] {logging_mixin.py:104} INFO - [2021-04-23 20:36:32,751] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:36:32,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.373 seconds
[2021-04-23 20:37:03,031] {scheduler_job.py:182} INFO - Started process (PID=846) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:37:03,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:37:03,047] {logging_mixin.py:104} INFO - [2021-04-23 20:37:03,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:37:04,339] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:37:04,442] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:37:04,558] {logging_mixin.py:104} INFO - [2021-04-23 20:37:04,549] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:37:04,657] {logging_mixin.py:104} INFO - [2021-04-23 20:37:04,657] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:37:04,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.676 seconds
[2021-04-23 20:37:35,705] {scheduler_job.py:182} INFO - Started process (PID=848) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:37:35,712] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:37:35,717] {logging_mixin.py:104} INFO - [2021-04-23 20:37:35,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:37:36,226] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:37:36,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:37:36,380] {logging_mixin.py:104} INFO - [2021-04-23 20:37:36,376] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:37:36,430] {logging_mixin.py:104} INFO - [2021-04-23 20:37:36,430] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:37:36,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.786 seconds
[2021-04-23 20:38:06,887] {scheduler_job.py:182} INFO - Started process (PID=850) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:38:06,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:38:06,898] {logging_mixin.py:104} INFO - [2021-04-23 20:38:06,898] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:38:07,479] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:38:07,532] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:38:07,589] {logging_mixin.py:104} INFO - [2021-04-23 20:38:07,587] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:38:07,665] {logging_mixin.py:104} INFO - [2021-04-23 20:38:07,665] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:38:07,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.832 seconds
[2021-04-23 20:38:38,186] {scheduler_job.py:182} INFO - Started process (PID=852) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:38:38,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:38:38,191] {logging_mixin.py:104} INFO - [2021-04-23 20:38:38,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:38:38,589] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:38:38,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:38:38,622] {logging_mixin.py:104} INFO - [2021-04-23 20:38:38,621] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:38:38,639] {logging_mixin.py:104} INFO - [2021-04-23 20:38:38,639] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:38:38,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.471 seconds
[2021-04-23 20:39:08,857] {scheduler_job.py:182} INFO - Started process (PID=854) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:39:08,864] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:39:08,874] {logging_mixin.py:104} INFO - [2021-04-23 20:39:08,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:39:09,300] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:39:09,338] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:39:09,361] {logging_mixin.py:104} INFO - [2021-04-23 20:39:09,360] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:39:09,383] {logging_mixin.py:104} INFO - [2021-04-23 20:39:09,383] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:39:09,395] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.556 seconds
[2021-04-23 20:39:41,986] {scheduler_job.py:182} INFO - Started process (PID=856) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:39:42,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:39:42,512] {logging_mixin.py:104} INFO - [2021-04-23 20:39:42,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:39:50,976] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:39:51,051] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:39:51,105] {logging_mixin.py:104} INFO - [2021-04-23 20:39:51,101] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:39:51,263] {logging_mixin.py:104} INFO - [2021-04-23 20:39:51,263] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:39:51,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 9.519 seconds
[2021-04-23 20:40:21,938] {scheduler_job.py:182} INFO - Started process (PID=858) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:40:21,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:40:21,953] {logging_mixin.py:104} INFO - [2021-04-23 20:40:21,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:40:22,578] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:40:22,618] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:40:22,669] {logging_mixin.py:104} INFO - [2021-04-23 20:40:22,668] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:40:22,719] {logging_mixin.py:104} INFO - [2021-04-23 20:40:22,719] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:40:22,733] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.808 seconds
[2021-04-23 20:40:53,340] {scheduler_job.py:182} INFO - Started process (PID=860) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:40:53,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:40:53,349] {logging_mixin.py:104} INFO - [2021-04-23 20:40:53,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:40:54,123] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:40:54,161] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:40:54,204] {logging_mixin.py:104} INFO - [2021-04-23 20:40:54,202] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:40:54,233] {logging_mixin.py:104} INFO - [2021-04-23 20:40:54,233] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:40:54,245] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.922 seconds
[2021-04-23 20:41:24,429] {scheduler_job.py:182} INFO - Started process (PID=862) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:41:24,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:41:24,437] {logging_mixin.py:104} INFO - [2021-04-23 20:41:24,437] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:41:24,928] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:41:24,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:41:25,015] {logging_mixin.py:104} INFO - [2021-04-23 20:41:25,014] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:41:25,048] {logging_mixin.py:104} INFO - [2021-04-23 20:41:25,048] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:41:25,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.642 seconds
[2021-04-23 20:41:55,638] {scheduler_job.py:182} INFO - Started process (PID=864) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:41:55,646] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:41:55,653] {logging_mixin.py:104} INFO - [2021-04-23 20:41:55,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:41:56,753] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:41:56,792] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:41:56,820] {logging_mixin.py:104} INFO - [2021-04-23 20:41:56,817] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:41:56,877] {logging_mixin.py:104} INFO - [2021-04-23 20:41:56,876] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:41:56,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.297 seconds
[2021-04-23 20:42:29,369] {scheduler_job.py:182} INFO - Started process (PID=866) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:42:29,410] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:42:29,468] {logging_mixin.py:104} INFO - [2021-04-23 20:42:29,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:42:41,344] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:42:41,559] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:42:41,966] {logging_mixin.py:104} INFO - [2021-04-23 20:42:41,910] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:42:42,328] {logging_mixin.py:104} INFO - [2021-04-23 20:42:42,328] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:42:42,466] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 13.259 seconds
[2021-04-23 20:43:15,130] {scheduler_job.py:182} INFO - Started process (PID=868) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:43:15,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:43:15,477] {logging_mixin.py:104} INFO - [2021-04-23 20:43:15,467] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:43:25,660] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:43:25,928] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:43:26,070] {logging_mixin.py:104} INFO - [2021-04-23 20:43:26,059] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:43:26,150] {logging_mixin.py:104} INFO - [2021-04-23 20:43:26,150] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:43:26,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 11.340 seconds
[2021-04-23 20:43:56,772] {scheduler_job.py:182} INFO - Started process (PID=870) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:43:56,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:43:56,779] {logging_mixin.py:104} INFO - [2021-04-23 20:43:56,778] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:43:57,472] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:43:57,524] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:43:57,603] {logging_mixin.py:104} INFO - [2021-04-23 20:43:57,599] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:43:57,663] {logging_mixin.py:104} INFO - [2021-04-23 20:43:57,663] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:43:57,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.934 seconds
[2021-04-23 20:44:27,927] {scheduler_job.py:182} INFO - Started process (PID=877) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:44:27,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:44:27,955] {logging_mixin.py:104} INFO - [2021-04-23 20:44:27,954] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:44:29,585] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:44:29,707] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:44:29,768] {logging_mixin.py:104} INFO - [2021-04-23 20:44:29,762] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:44:29,888] {logging_mixin.py:104} INFO - [2021-04-23 20:44:29,888] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:44:29,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.017 seconds
[2021-04-23 20:45:00,707] {scheduler_job.py:182} INFO - Started process (PID=879) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:45:00,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:45:00,863] {logging_mixin.py:104} INFO - [2021-04-23 20:45:00,861] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:45:04,968] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:45:05,137] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:45:05,197] {logging_mixin.py:104} INFO - [2021-04-23 20:45:05,193] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:45:05,285] {logging_mixin.py:104} INFO - [2021-04-23 20:45:05,285] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:45:05,381] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.695 seconds
[2021-04-23 20:45:37,029] {scheduler_job.py:182} INFO - Started process (PID=881) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:45:37,048] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:45:37,067] {logging_mixin.py:104} INFO - [2021-04-23 20:45:37,062] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:45:39,100] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:45:39,166] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:45:39,228] {logging_mixin.py:104} INFO - [2021-04-23 20:45:39,225] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:45:39,298] {logging_mixin.py:104} INFO - [2021-04-23 20:45:39,298] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:45:39,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.466 seconds
[2021-04-23 20:46:09,669] {scheduler_job.py:182} INFO - Started process (PID=883) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:46:09,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:46:09,691] {logging_mixin.py:104} INFO - [2021-04-23 20:46:09,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:46:10,457] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:46:10,502] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:46:10,540] {logging_mixin.py:104} INFO - [2021-04-23 20:46:10,538] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:46:10,581] {logging_mixin.py:104} INFO - [2021-04-23 20:46:10,581] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:46:10,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.951 seconds
[2021-04-23 20:46:41,893] {scheduler_job.py:182} INFO - Started process (PID=885) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:46:41,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:46:41,961] {logging_mixin.py:104} INFO - [2021-04-23 20:46:41,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:46:44,666] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:46:48,080] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:46:48,571] {logging_mixin.py:104} INFO - [2021-04-23 20:46:48,357] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:46:49,035] {logging_mixin.py:104} INFO - [2021-04-23 20:46:49,034] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:46:49,296] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 7.458 seconds
[2021-04-23 20:47:20,204] {scheduler_job.py:182} INFO - Started process (PID=887) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:47:20,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:47:20,285] {logging_mixin.py:104} INFO - [2021-04-23 20:47:20,285] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:47:24,426] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:47:24,520] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:47:24,588] {logging_mixin.py:104} INFO - [2021-04-23 20:47:24,582] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:47:24,642] {logging_mixin.py:104} INFO - [2021-04-23 20:47:24,642] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:47:24,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.537 seconds
[2021-04-23 20:47:55,106] {scheduler_job.py:182} INFO - Started process (PID=889) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:47:55,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:47:55,115] {logging_mixin.py:104} INFO - [2021-04-23 20:47:55,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:47:55,699] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:47:56,046] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:47:56,749] {logging_mixin.py:104} INFO - [2021-04-23 20:47:56,745] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:47:57,578] {logging_mixin.py:104} INFO - [2021-04-23 20:47:57,577] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:47:57,828] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.720 seconds
[2021-04-23 20:48:29,280] {scheduler_job.py:182} INFO - Started process (PID=891) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:48:29,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:48:29,312] {logging_mixin.py:104} INFO - [2021-04-23 20:48:29,311] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:48:30,206] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:48:30,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:48:30,346] {logging_mixin.py:104} INFO - [2021-04-23 20:48:30,344] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:48:30,432] {logging_mixin.py:104} INFO - [2021-04-23 20:48:30,432] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:48:30,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.216 seconds
[2021-04-23 20:49:01,502] {scheduler_job.py:182} INFO - Started process (PID=893) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:49:01,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:49:01,512] {logging_mixin.py:104} INFO - [2021-04-23 20:49:01,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:49:02,209] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:49:02,251] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:49:02,304] {logging_mixin.py:104} INFO - [2021-04-23 20:49:02,298] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:49:02,362] {logging_mixin.py:104} INFO - [2021-04-23 20:49:02,362] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:49:02,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.903 seconds
[2021-04-23 20:49:32,965] {scheduler_job.py:182} INFO - Started process (PID=895) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:49:32,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:49:32,991] {logging_mixin.py:104} INFO - [2021-04-23 20:49:32,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:49:33,743] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:49:33,904] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:49:33,989] {logging_mixin.py:104} INFO - [2021-04-23 20:49:33,979] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:49:34,063] {logging_mixin.py:104} INFO - [2021-04-23 20:49:34,063] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:49:34,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.134 seconds
[2021-04-23 20:50:04,464] {scheduler_job.py:182} INFO - Started process (PID=897) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:50:04,468] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:50:04,476] {logging_mixin.py:104} INFO - [2021-04-23 20:50:04,475] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:50:05,138] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:50:05,177] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:50:05,219] {logging_mixin.py:104} INFO - [2021-04-23 20:50:05,215] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:50:05,276] {logging_mixin.py:104} INFO - [2021-04-23 20:50:05,275] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:50:05,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.845 seconds
[2021-04-23 20:50:35,647] {scheduler_job.py:182} INFO - Started process (PID=899) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:50:35,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:50:35,655] {logging_mixin.py:104} INFO - [2021-04-23 20:50:35,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:50:36,254] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:50:36,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:50:36,326] {logging_mixin.py:104} INFO - [2021-04-23 20:50:36,323] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:50:36,364] {logging_mixin.py:104} INFO - [2021-04-23 20:50:36,364] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:50:36,386] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.745 seconds
[2021-04-23 20:51:14,751] {scheduler_job.py:182} INFO - Started process (PID=901) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:51:14,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:51:14,787] {logging_mixin.py:104} INFO - [2021-04-23 20:51:14,786] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:51:23,138] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:51:23,256] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:51:23,340] {logging_mixin.py:104} INFO - [2021-04-23 20:51:23,333] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:51:23,531] {logging_mixin.py:104} INFO - [2021-04-23 20:51:23,525] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T19:00:00+00:00
[2021-04-23 20:51:23,594] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 9.021 seconds
[2021-04-23 20:51:53,794] {scheduler_job.py:182} INFO - Started process (PID=903) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:51:53,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:51:53,804] {logging_mixin.py:104} INFO - [2021-04-23 20:51:53,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:51:54,337] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:51:54,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:51:54,386] {logging_mixin.py:104} INFO - [2021-04-23 20:51:54,385] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:51:54,416] {logging_mixin.py:104} INFO - [2021-04-23 20:51:54,416] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:51:54,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.645 seconds
[2021-04-23 20:52:24,610] {scheduler_job.py:182} INFO - Started process (PID=905) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:52:24,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:52:24,614] {logging_mixin.py:104} INFO - [2021-04-23 20:52:24,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:52:25,003] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:52:25,029] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:52:25,053] {logging_mixin.py:104} INFO - [2021-04-23 20:52:25,051] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:52:25,078] {logging_mixin.py:104} INFO - [2021-04-23 20:52:25,078] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:52:25,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.488 seconds
[2021-04-23 20:52:55,227] {scheduler_job.py:182} INFO - Started process (PID=907) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:52:55,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:52:55,233] {logging_mixin.py:104} INFO - [2021-04-23 20:52:55,232] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:52:55,584] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:52:55,604] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:52:55,619] {logging_mixin.py:104} INFO - [2021-04-23 20:52:55,618] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:52:55,637] {logging_mixin.py:104} INFO - [2021-04-23 20:52:55,637] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:52:55,646] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.423 seconds
[2021-04-23 20:53:25,867] {scheduler_job.py:182} INFO - Started process (PID=909) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:53:25,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:53:25,886] {logging_mixin.py:104} INFO - [2021-04-23 20:53:25,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:53:26,613] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:53:26,641] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:53:26,666] {logging_mixin.py:104} INFO - [2021-04-23 20:53:26,665] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:53:26,685] {logging_mixin.py:104} INFO - [2021-04-23 20:53:26,685] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:53:26,697] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.844 seconds
[2021-04-23 20:53:59,376] {scheduler_job.py:182} INFO - Started process (PID=911) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:53:59,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:53:59,448] {logging_mixin.py:104} INFO - [2021-04-23 20:53:59,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:54:12,556] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:54:12,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:54:12,768] {logging_mixin.py:104} INFO - [2021-04-23 20:54:12,742] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:54:13,123] {logging_mixin.py:104} INFO - [2021-04-23 20:54:13,123] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:54:13,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 13.984 seconds
[2021-04-23 20:54:44,329] {scheduler_job.py:182} INFO - Started process (PID=913) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:54:44,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:54:44,338] {logging_mixin.py:104} INFO - [2021-04-23 20:54:44,338] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:54:44,767] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:54:44,803] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:54:44,829] {logging_mixin.py:104} INFO - [2021-04-23 20:54:44,828] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:54:44,850] {logging_mixin.py:104} INFO - [2021-04-23 20:54:44,850] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:54:44,880] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.562 seconds
[2021-04-23 20:55:15,646] {scheduler_job.py:182} INFO - Started process (PID=915) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:55:15,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:55:15,657] {logging_mixin.py:104} INFO - [2021-04-23 20:55:15,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:55:16,120] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:55:16,151] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:55:16,169] {logging_mixin.py:104} INFO - [2021-04-23 20:55:16,168] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:55:16,193] {logging_mixin.py:104} INFO - [2021-04-23 20:55:16,193] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:55:16,205] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.566 seconds
[2021-04-23 20:55:50,633] {scheduler_job.py:182} INFO - Started process (PID=917) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:55:50,843] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:55:50,984] {logging_mixin.py:104} INFO - [2021-04-23 20:55:50,965] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:55:52,921] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:55:52,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:55:53,030] {logging_mixin.py:104} INFO - [2021-04-23 20:55:53,027] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:55:53,063] {logging_mixin.py:104} INFO - [2021-04-23 20:55:53,063] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:55:53,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.538 seconds
[2021-04-23 20:56:24,122] {scheduler_job.py:182} INFO - Started process (PID=919) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:56:24,127] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:56:24,132] {logging_mixin.py:104} INFO - [2021-04-23 20:56:24,131] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:56:24,826] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:56:24,872] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:56:24,899] {logging_mixin.py:104} INFO - [2021-04-23 20:56:24,896] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:56:24,959] {logging_mixin.py:104} INFO - [2021-04-23 20:56:24,958] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:56:24,973] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.866 seconds
[2021-04-23 20:56:55,204] {scheduler_job.py:182} INFO - Started process (PID=921) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:56:55,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:56:55,208] {logging_mixin.py:104} INFO - [2021-04-23 20:56:55,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:56:55,745] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:56:55,775] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:56:55,807] {logging_mixin.py:104} INFO - [2021-04-23 20:56:55,804] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:56:55,844] {logging_mixin.py:104} INFO - [2021-04-23 20:56:55,844] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:56:55,884] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.686 seconds
[2021-04-23 20:57:26,264] {scheduler_job.py:182} INFO - Started process (PID=923) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:57:26,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:57:26,273] {logging_mixin.py:104} INFO - [2021-04-23 20:57:26,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:57:26,677] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:57:26,716] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:57:26,734] {logging_mixin.py:104} INFO - [2021-04-23 20:57:26,733] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:57:26,758] {logging_mixin.py:104} INFO - [2021-04-23 20:57:26,757] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:57:26,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.517 seconds
[2021-04-23 20:57:57,023] {scheduler_job.py:182} INFO - Started process (PID=925) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:57:57,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:57:57,036] {logging_mixin.py:104} INFO - [2021-04-23 20:57:57,036] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:57:57,647] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:57:57,689] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:57:57,708] {logging_mixin.py:104} INFO - [2021-04-23 20:57:57,706] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:57:57,732] {logging_mixin.py:104} INFO - [2021-04-23 20:57:57,732] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:57:57,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.731 seconds
[2021-04-23 20:58:28,758] {scheduler_job.py:182} INFO - Started process (PID=927) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:58:28,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:58:28,975] {logging_mixin.py:104} INFO - [2021-04-23 20:58:28,974] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:58:36,286] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:58:36,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:58:36,390] {logging_mixin.py:104} INFO - [2021-04-23 20:58:36,387] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:58:36,459] {logging_mixin.py:104} INFO - [2021-04-23 20:58:36,457] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:58:36,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 7.815 seconds
[2021-04-23 20:59:07,469] {scheduler_job.py:182} INFO - Started process (PID=929) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:59:07,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:59:07,483] {logging_mixin.py:104} INFO - [2021-04-23 20:59:07,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:59:08,442] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:59:08,603] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:59:08,676] {logging_mixin.py:104} INFO - [2021-04-23 20:59:08,674] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:59:08,760] {logging_mixin.py:104} INFO - [2021-04-23 20:59:08,760] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:59:08,787] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.326 seconds
[2021-04-23 20:59:39,624] {scheduler_job.py:182} INFO - Started process (PID=930) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:59:39,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 20:59:39,635] {logging_mixin.py:104} INFO - [2021-04-23 20:59:39,635] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:59:41,040] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 20:59:41,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 20:59:41,201] {logging_mixin.py:104} INFO - [2021-04-23 20:59:41,197] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 20:59:41,248] {logging_mixin.py:104} INFO - [2021-04-23 20:59:41,248] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 20:59:41,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.688 seconds
[2021-04-23 21:00:11,620] {scheduler_job.py:182} INFO - Started process (PID=933) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:00:11,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:00:11,665] {logging_mixin.py:104} INFO - [2021-04-23 21:00:11,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:00:12,398] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:00:12,522] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:00:12,598] {logging_mixin.py:104} INFO - [2021-04-23 21:00:12,594] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:00:12,643] {logging_mixin.py:104} INFO - [2021-04-23 21:00:12,643] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:00:12,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.080 seconds
[2021-04-23 21:00:43,634] {scheduler_job.py:182} INFO - Started process (PID=935) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:00:43,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:00:43,668] {logging_mixin.py:104} INFO - [2021-04-23 21:00:43,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:00:45,995] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:00:46,123] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:00:46,186] {logging_mixin.py:104} INFO - [2021-04-23 21:00:46,176] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:00:46,315] {logging_mixin.py:104} INFO - [2021-04-23 21:00:46,315] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:00:46,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.792 seconds
[2021-04-23 21:01:16,604] {scheduler_job.py:182} INFO - Started process (PID=937) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:01:16,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:01:16,613] {logging_mixin.py:104} INFO - [2021-04-23 21:01:16,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:01:17,045] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:01:17,078] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:01:17,107] {logging_mixin.py:104} INFO - [2021-04-23 21:01:17,103] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:01:17,135] {logging_mixin.py:104} INFO - [2021-04-23 21:01:17,135] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:01:17,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.553 seconds
[2021-04-23 21:01:47,400] {scheduler_job.py:182} INFO - Started process (PID=939) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:01:47,407] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:01:47,410] {logging_mixin.py:104} INFO - [2021-04-23 21:01:47,410] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:01:48,102] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:01:48,141] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:01:48,180] {logging_mixin.py:104} INFO - [2021-04-23 21:01:48,178] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:01:48,213] {logging_mixin.py:104} INFO - [2021-04-23 21:01:48,213] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:01:48,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.867 seconds
[2021-04-23 21:02:18,576] {scheduler_job.py:182} INFO - Started process (PID=941) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:02:18,583] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:02:18,587] {logging_mixin.py:104} INFO - [2021-04-23 21:02:18,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:02:19,458] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:02:19,565] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:02:19,651] {logging_mixin.py:104} INFO - [2021-04-23 21:02:19,647] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:02:19,705] {logging_mixin.py:104} INFO - [2021-04-23 21:02:19,705] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:02:19,739] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.173 seconds
[2021-04-23 21:02:50,263] {scheduler_job.py:182} INFO - Started process (PID=943) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:02:50,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:02:50,271] {logging_mixin.py:104} INFO - [2021-04-23 21:02:50,271] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:02:51,164] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:02:51,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:02:51,335] {logging_mixin.py:104} INFO - [2021-04-23 21:02:51,332] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:02:51,389] {logging_mixin.py:104} INFO - [2021-04-23 21:02:51,389] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:02:51,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.163 seconds
[2021-04-23 21:03:21,617] {scheduler_job.py:182} INFO - Started process (PID=945) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:03:21,620] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:03:21,623] {logging_mixin.py:104} INFO - [2021-04-23 21:03:21,622] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:03:22,006] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:03:22,047] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:03:22,066] {logging_mixin.py:104} INFO - [2021-04-23 21:03:22,065] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:03:22,093] {logging_mixin.py:104} INFO - [2021-04-23 21:03:22,093] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:03:22,105] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.492 seconds
[2021-04-23 21:03:52,292] {scheduler_job.py:182} INFO - Started process (PID=947) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:03:52,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:03:52,303] {logging_mixin.py:104} INFO - [2021-04-23 21:03:52,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:03:52,777] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:03:52,822] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:03:52,838] {logging_mixin.py:104} INFO - [2021-04-23 21:03:52,836] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:03:52,859] {logging_mixin.py:104} INFO - [2021-04-23 21:03:52,859] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:03:52,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.581 seconds
[2021-04-23 21:04:24,606] {scheduler_job.py:182} INFO - Started process (PID=949) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:04:24,657] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:04:24,686] {logging_mixin.py:104} INFO - [2021-04-23 21:04:24,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:04:26,020] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:04:26,124] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:04:26,176] {logging_mixin.py:104} INFO - [2021-04-23 21:04:26,174] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:04:26,261] {logging_mixin.py:104} INFO - [2021-04-23 21:04:26,261] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:04:26,347] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.789 seconds
[2021-04-23 21:04:56,605] {scheduler_job.py:182} INFO - Started process (PID=951) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:04:56,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:04:56,624] {logging_mixin.py:104} INFO - [2021-04-23 21:04:56,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:04:57,329] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:04:57,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:04:57,669] {logging_mixin.py:104} INFO - [2021-04-23 21:04:57,668] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:04:57,708] {logging_mixin.py:104} INFO - [2021-04-23 21:04:57,707] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:04:57,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.132 seconds
[2021-04-23 21:05:27,997] {scheduler_job.py:182} INFO - Started process (PID=952) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:05:28,009] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:05:28,036] {logging_mixin.py:104} INFO - [2021-04-23 21:05:28,033] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:05:29,329] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:05:29,382] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:05:29,408] {logging_mixin.py:104} INFO - [2021-04-23 21:05:29,405] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:05:29,452] {logging_mixin.py:104} INFO - [2021-04-23 21:05:29,451] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:05:29,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.539 seconds
[2021-04-23 21:06:00,272] {scheduler_job.py:182} INFO - Started process (PID=955) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:06:00,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:06:00,280] {logging_mixin.py:104} INFO - [2021-04-23 21:06:00,280] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:06:00,986] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:06:01,043] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:06:01,062] {logging_mixin.py:104} INFO - [2021-04-23 21:06:01,061] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:06:01,083] {logging_mixin.py:104} INFO - [2021-04-23 21:06:01,083] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:06:01,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.831 seconds
[2021-04-23 21:06:32,366] {scheduler_job.py:182} INFO - Started process (PID=957) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:06:32,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:06:32,492] {logging_mixin.py:104} INFO - [2021-04-23 21:06:32,491] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:06:34,303] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:06:34,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:06:34,419] {logging_mixin.py:104} INFO - [2021-04-23 21:06:34,417] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:06:34,458] {logging_mixin.py:104} INFO - [2021-04-23 21:06:34,458] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:06:34,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.152 seconds
[2021-04-23 21:07:05,122] {scheduler_job.py:182} INFO - Started process (PID=959) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:07:05,128] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:07:05,132] {logging_mixin.py:104} INFO - [2021-04-23 21:07:05,132] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:07:05,796] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:07:05,845] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:07:05,874] {logging_mixin.py:104} INFO - [2021-04-23 21:07:05,871] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:07:05,912] {logging_mixin.py:104} INFO - [2021-04-23 21:07:05,912] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:07:05,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.816 seconds
[2021-04-23 21:07:36,587] {scheduler_job.py:182} INFO - Started process (PID=961) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:07:36,597] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:07:36,601] {logging_mixin.py:104} INFO - [2021-04-23 21:07:36,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:07:37,610] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:07:37,671] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:07:37,707] {logging_mixin.py:104} INFO - [2021-04-23 21:07:37,702] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:07:37,773] {logging_mixin.py:104} INFO - [2021-04-23 21:07:37,773] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:07:37,797] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.229 seconds
[2021-04-23 21:08:08,498] {scheduler_job.py:182} INFO - Started process (PID=963) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:08:08,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:08:08,568] {logging_mixin.py:104} INFO - [2021-04-23 21:08:08,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:08:10,392] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:08:10,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:08:10,538] {logging_mixin.py:104} INFO - [2021-04-23 21:08:10,536] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:08:10,588] {logging_mixin.py:104} INFO - [2021-04-23 21:08:10,588] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:08:10,620] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.145 seconds
[2021-04-23 21:08:41,199] {scheduler_job.py:182} INFO - Started process (PID=965) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:08:41,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:08:41,202] {logging_mixin.py:104} INFO - [2021-04-23 21:08:41,202] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:08:41,604] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:08:41,641] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:08:41,657] {logging_mixin.py:104} INFO - [2021-04-23 21:08:41,656] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:08:41,677] {logging_mixin.py:104} INFO - [2021-04-23 21:08:41,677] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:08:41,688] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.494 seconds
[2021-04-23 21:09:11,842] {scheduler_job.py:182} INFO - Started process (PID=967) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:09:11,851] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:09:11,854] {logging_mixin.py:104} INFO - [2021-04-23 21:09:11,854] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:09:12,253] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:09:12,285] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:09:12,297] {logging_mixin.py:104} INFO - [2021-04-23 21:09:12,296] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:09:12,320] {logging_mixin.py:104} INFO - [2021-04-23 21:09:12,320] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:09:12,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.499 seconds
[2021-04-23 21:09:42,446] {scheduler_job.py:182} INFO - Started process (PID=969) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:09:42,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:09:42,453] {logging_mixin.py:104} INFO - [2021-04-23 21:09:42,452] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:09:42,762] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:09:42,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:09:42,811] {logging_mixin.py:104} INFO - [2021-04-23 21:09:42,809] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:09:42,842] {logging_mixin.py:104} INFO - [2021-04-23 21:09:42,841] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:09:42,857] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.417 seconds
[2021-04-23 21:10:13,011] {scheduler_job.py:182} INFO - Started process (PID=971) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:10:13,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:10:13,017] {logging_mixin.py:104} INFO - [2021-04-23 21:10:13,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:10:13,332] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:10:13,365] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:10:13,380] {logging_mixin.py:104} INFO - [2021-04-23 21:10:13,378] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:10:13,402] {logging_mixin.py:104} INFO - [2021-04-23 21:10:13,402] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T20:00:00+00:00
[2021-04-23 21:10:13,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.415 seconds
[2021-04-23 21:10:43,761] {scheduler_job.py:182} INFO - Started process (PID=973) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:10:43,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:10:43,770] {logging_mixin.py:104} INFO - [2021-04-23 21:10:43,770] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:10:44,253] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:10:44,296] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:10:44,319] {logging_mixin.py:104} INFO - [2021-04-23 21:10:44,317] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:10:44,351] {logging_mixin.py:104} INFO - [2021-04-23 21:10:44,351] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:10:44,401] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.643 seconds
[2021-04-23 21:11:14,524] {scheduler_job.py:182} INFO - Started process (PID=975) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:11:14,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:11:14,529] {logging_mixin.py:104} INFO - [2021-04-23 21:11:14,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:11:14,870] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:11:14,901] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:11:14,915] {logging_mixin.py:104} INFO - [2021-04-23 21:11:14,913] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:11:14,938] {logging_mixin.py:104} INFO - [2021-04-23 21:11:14,938] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:11:14,948] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.432 seconds
[2021-04-23 21:11:45,086] {scheduler_job.py:182} INFO - Started process (PID=977) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:11:45,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:11:45,089] {logging_mixin.py:104} INFO - [2021-04-23 21:11:45,089] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:11:45,398] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:11:45,424] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:11:45,440] {logging_mixin.py:104} INFO - [2021-04-23 21:11:45,439] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:11:45,467] {logging_mixin.py:104} INFO - [2021-04-23 21:11:45,467] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:11:45,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.401 seconds
[2021-04-23 21:12:15,634] {scheduler_job.py:182} INFO - Started process (PID=979) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:12:15,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:12:15,638] {logging_mixin.py:104} INFO - [2021-04-23 21:12:15,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:12:15,949] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:12:15,989] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:12:16,005] {logging_mixin.py:104} INFO - [2021-04-23 21:12:16,004] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:12:16,024] {logging_mixin.py:104} INFO - [2021-04-23 21:12:16,024] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:12:16,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.406 seconds
[2021-04-23 21:12:46,236] {scheduler_job.py:182} INFO - Started process (PID=981) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:12:46,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:12:46,243] {logging_mixin.py:104} INFO - [2021-04-23 21:12:46,243] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:12:46,590] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:12:46,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:12:46,629] {logging_mixin.py:104} INFO - [2021-04-23 21:12:46,628] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:12:46,652] {logging_mixin.py:104} INFO - [2021-04-23 21:12:46,652] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:12:46,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.431 seconds
[2021-04-23 21:13:16,862] {scheduler_job.py:182} INFO - Started process (PID=983) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:13:16,864] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:13:16,866] {logging_mixin.py:104} INFO - [2021-04-23 21:13:16,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:13:17,176] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:13:17,204] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:13:17,218] {logging_mixin.py:104} INFO - [2021-04-23 21:13:17,217] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:13:17,240] {logging_mixin.py:104} INFO - [2021-04-23 21:13:17,240] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:13:17,250] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.394 seconds
[2021-04-23 21:13:47,387] {scheduler_job.py:182} INFO - Started process (PID=985) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:13:47,389] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:13:47,391] {logging_mixin.py:104} INFO - [2021-04-23 21:13:47,391] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:13:47,716] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:13:47,745] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:13:47,761] {logging_mixin.py:104} INFO - [2021-04-23 21:13:47,760] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:13:47,787] {logging_mixin.py:104} INFO - [2021-04-23 21:13:47,786] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:13:47,797] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.415 seconds
[2021-04-23 21:14:17,964] {scheduler_job.py:182} INFO - Started process (PID=987) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:14:17,970] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:14:17,976] {logging_mixin.py:104} INFO - [2021-04-23 21:14:17,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:14:18,423] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:14:18,466] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:14:18,487] {logging_mixin.py:104} INFO - [2021-04-23 21:14:18,485] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:14:18,510] {logging_mixin.py:104} INFO - [2021-04-23 21:14:18,509] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:14:18,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.561 seconds
[2021-04-23 21:14:48,693] {scheduler_job.py:182} INFO - Started process (PID=989) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:14:48,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:14:48,698] {logging_mixin.py:104} INFO - [2021-04-23 21:14:48,698] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:14:49,010] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:14:49,037] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:14:49,050] {logging_mixin.py:104} INFO - [2021-04-23 21:14:49,049] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:14:49,073] {logging_mixin.py:104} INFO - [2021-04-23 21:14:49,072] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:14:49,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.395 seconds
[2021-04-23 21:15:19,213] {scheduler_job.py:182} INFO - Started process (PID=991) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:15:19,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:15:19,222] {logging_mixin.py:104} INFO - [2021-04-23 21:15:19,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:15:19,563] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:15:19,593] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:15:19,610] {logging_mixin.py:104} INFO - [2021-04-23 21:15:19,608] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:15:19,633] {logging_mixin.py:104} INFO - [2021-04-23 21:15:19,633] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:15:19,644] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.442 seconds
[2021-04-23 21:15:49,774] {scheduler_job.py:182} INFO - Started process (PID=993) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:15:49,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:15:49,782] {logging_mixin.py:104} INFO - [2021-04-23 21:15:49,781] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:15:50,142] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:15:50,171] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:15:50,186] {logging_mixin.py:104} INFO - [2021-04-23 21:15:50,184] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:15:50,213] {logging_mixin.py:104} INFO - [2021-04-23 21:15:50,213] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:15:50,223] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.454 seconds
[2021-04-23 21:16:20,397] {scheduler_job.py:182} INFO - Started process (PID=995) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:16:20,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:16:20,402] {logging_mixin.py:104} INFO - [2021-04-23 21:16:20,402] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:16:20,709] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:16:20,741] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:16:20,755] {logging_mixin.py:104} INFO - [2021-04-23 21:16:20,754] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:16:20,774] {logging_mixin.py:104} INFO - [2021-04-23 21:16:20,774] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:16:20,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.429 seconds
[2021-04-23 21:16:50,961] {scheduler_job.py:182} INFO - Started process (PID=997) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:16:50,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:16:50,965] {logging_mixin.py:104} INFO - [2021-04-23 21:16:50,965] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:16:51,274] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:16:51,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:16:51,314] {logging_mixin.py:104} INFO - [2021-04-23 21:16:51,312] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:16:51,333] {logging_mixin.py:104} INFO - [2021-04-23 21:16:51,333] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:16:51,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.385 seconds
[2021-04-23 21:17:21,566] {scheduler_job.py:182} INFO - Started process (PID=999) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:17:21,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:17:21,575] {logging_mixin.py:104} INFO - [2021-04-23 21:17:21,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:17:22,381] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:17:22,580] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:17:22,617] {logging_mixin.py:104} INFO - [2021-04-23 21:17:22,614] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:17:22,752] {logging_mixin.py:104} INFO - [2021-04-23 21:17:22,750] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:17:22,780] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.227 seconds
[2021-04-23 21:17:53,331] {scheduler_job.py:182} INFO - Started process (PID=1001) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:17:53,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:17:53,347] {logging_mixin.py:104} INFO - [2021-04-23 21:17:53,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:17:54,030] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:17:54,079] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:17:54,105] {logging_mixin.py:104} INFO - [2021-04-23 21:17:54,102] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:17:54,160] {logging_mixin.py:104} INFO - [2021-04-23 21:17:54,159] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:17:54,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.866 seconds
[2021-04-23 21:18:25,122] {scheduler_job.py:182} INFO - Started process (PID=1003) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:18:25,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:18:25,247] {logging_mixin.py:104} INFO - [2021-04-23 21:18:25,244] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:18:27,441] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:18:27,510] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:18:27,571] {logging_mixin.py:104} INFO - [2021-04-23 21:18:27,562] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:18:27,659] {logging_mixin.py:104} INFO - [2021-04-23 21:18:27,659] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:18:27,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.666 seconds
[2021-04-23 21:18:58,039] {scheduler_job.py:182} INFO - Started process (PID=1005) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:18:58,045] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:18:58,049] {logging_mixin.py:104} INFO - [2021-04-23 21:18:58,048] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:18:58,564] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:18:58,612] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:18:58,632] {logging_mixin.py:104} INFO - [2021-04-23 21:18:58,630] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:18:58,677] {logging_mixin.py:104} INFO - [2021-04-23 21:18:58,677] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:18:58,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.669 seconds
[2021-04-23 21:19:28,792] {scheduler_job.py:182} INFO - Started process (PID=1007) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:19:28,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:19:28,797] {logging_mixin.py:104} INFO - [2021-04-23 21:19:28,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:19:29,147] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:19:29,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:19:29,193] {logging_mixin.py:104} INFO - [2021-04-23 21:19:29,192] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:19:29,212] {logging_mixin.py:104} INFO - [2021-04-23 21:19:29,212] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:19:29,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.433 seconds
[2021-04-23 21:19:59,415] {scheduler_job.py:182} INFO - Started process (PID=1009) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:19:59,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:19:59,422] {logging_mixin.py:104} INFO - [2021-04-23 21:19:59,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:19:59,784] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:19:59,816] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:19:59,830] {logging_mixin.py:104} INFO - [2021-04-23 21:19:59,829] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:19:59,850] {logging_mixin.py:104} INFO - [2021-04-23 21:19:59,850] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:19:59,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.461 seconds
[2021-04-23 21:20:30,136] {scheduler_job.py:182} INFO - Started process (PID=1011) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:20:30,139] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:20:30,140] {logging_mixin.py:104} INFO - [2021-04-23 21:20:30,140] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:20:30,459] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:20:30,492] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:20:30,506] {logging_mixin.py:104} INFO - [2021-04-23 21:20:30,505] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:20:30,532] {logging_mixin.py:104} INFO - [2021-04-23 21:20:30,531] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:20:30,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.411 seconds
[2021-04-23 21:21:00,892] {scheduler_job.py:182} INFO - Started process (PID=1013) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:21:00,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:21:00,904] {logging_mixin.py:104} INFO - [2021-04-23 21:21:00,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:21:01,277] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:21:01,302] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:21:01,316] {logging_mixin.py:104} INFO - [2021-04-23 21:21:01,315] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:21:01,336] {logging_mixin.py:104} INFO - [2021-04-23 21:21:01,336] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:21:01,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.483 seconds
[2021-04-23 21:21:31,536] {scheduler_job.py:182} INFO - Started process (PID=1015) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:21:31,542] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:21:31,548] {logging_mixin.py:104} INFO - [2021-04-23 21:21:31,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:21:31,908] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:21:31,946] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:21:31,962] {logging_mixin.py:104} INFO - [2021-04-23 21:21:31,960] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:21:31,985] {logging_mixin.py:104} INFO - [2021-04-23 21:21:31,985] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:21:32,000] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.473 seconds
[2021-04-23 21:22:02,250] {scheduler_job.py:182} INFO - Started process (PID=1017) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:22:02,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:22:02,263] {logging_mixin.py:104} INFO - [2021-04-23 21:22:02,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:22:02,686] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:22:02,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:22:02,739] {logging_mixin.py:104} INFO - [2021-04-23 21:22:02,738] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:22:02,760] {logging_mixin.py:104} INFO - [2021-04-23 21:22:02,760] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:22:02,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.535 seconds
[2021-04-23 21:22:32,986] {scheduler_job.py:182} INFO - Started process (PID=1019) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:22:32,989] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:22:32,991] {logging_mixin.py:104} INFO - [2021-04-23 21:22:32,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:22:33,318] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:22:33,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:22:33,362] {logging_mixin.py:104} INFO - [2021-04-23 21:22:33,360] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:22:33,384] {logging_mixin.py:104} INFO - [2021-04-23 21:22:33,384] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:22:33,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.423 seconds
[2021-04-23 21:23:03,544] {scheduler_job.py:182} INFO - Started process (PID=1021) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:23:03,550] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:23:03,553] {logging_mixin.py:104} INFO - [2021-04-23 21:23:03,553] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:23:03,989] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:23:04,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:23:04,034] {logging_mixin.py:104} INFO - [2021-04-23 21:23:04,033] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:23:04,053] {logging_mixin.py:104} INFO - [2021-04-23 21:23:04,053] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:23:04,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.534 seconds
[2021-04-23 21:23:34,186] {scheduler_job.py:182} INFO - Started process (PID=1023) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:23:34,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:23:34,192] {logging_mixin.py:104} INFO - [2021-04-23 21:23:34,192] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:23:34,538] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:23:34,576] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:23:34,595] {logging_mixin.py:104} INFO - [2021-04-23 21:23:34,594] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:23:34,623] {logging_mixin.py:104} INFO - [2021-04-23 21:23:34,622] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:23:34,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.459 seconds
[2021-04-23 21:24:04,788] {scheduler_job.py:182} INFO - Started process (PID=1025) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:24:04,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:24:04,795] {logging_mixin.py:104} INFO - [2021-04-23 21:24:04,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:24:05,262] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:24:05,297] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:24:05,311] {logging_mixin.py:104} INFO - [2021-04-23 21:24:05,310] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:24:05,338] {logging_mixin.py:104} INFO - [2021-04-23 21:24:05,338] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:24:05,350] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.568 seconds
[2021-04-23 21:24:35,544] {scheduler_job.py:182} INFO - Started process (PID=1027) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:24:35,548] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:24:35,551] {logging_mixin.py:104} INFO - [2021-04-23 21:24:35,550] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:24:35,924] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:24:35,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:24:35,966] {logging_mixin.py:104} INFO - [2021-04-23 21:24:35,965] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:24:36,003] {logging_mixin.py:104} INFO - [2021-04-23 21:24:36,002] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:24:36,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.474 seconds
[2021-04-23 21:25:06,206] {scheduler_job.py:182} INFO - Started process (PID=1029) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:25:06,212] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:25:06,214] {logging_mixin.py:104} INFO - [2021-04-23 21:25:06,214] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:25:06,621] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:25:06,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:25:06,661] {logging_mixin.py:104} INFO - [2021-04-23 21:25:06,659] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:25:06,677] {logging_mixin.py:104} INFO - [2021-04-23 21:25:06,677] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:25:06,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.486 seconds
[2021-04-23 21:25:36,901] {scheduler_job.py:182} INFO - Started process (PID=1031) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:25:36,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:25:36,925] {logging_mixin.py:104} INFO - [2021-04-23 21:25:36,925] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:25:37,391] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:25:37,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:25:37,443] {logging_mixin.py:104} INFO - [2021-04-23 21:25:37,442] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:25:37,462] {logging_mixin.py:104} INFO - [2021-04-23 21:25:37,462] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:25:37,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.609 seconds
[2021-04-23 21:26:07,635] {scheduler_job.py:182} INFO - Started process (PID=1033) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:26:07,638] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:26:07,639] {logging_mixin.py:104} INFO - [2021-04-23 21:26:07,639] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:26:07,984] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:26:08,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:26:08,056] {logging_mixin.py:104} INFO - [2021-04-23 21:26:08,055] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:26:08,080] {logging_mixin.py:104} INFO - [2021-04-23 21:26:08,080] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:26:08,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.460 seconds
[2021-04-23 21:26:38,227] {scheduler_job.py:182} INFO - Started process (PID=1035) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:26:38,231] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:26:38,236] {logging_mixin.py:104} INFO - [2021-04-23 21:26:38,235] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:26:38,799] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:26:38,833] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:26:38,846] {logging_mixin.py:104} INFO - [2021-04-23 21:26:38,845] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:26:38,869] {logging_mixin.py:104} INFO - [2021-04-23 21:26:38,869] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:26:38,882] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.664 seconds
[2021-04-23 21:27:09,757] {scheduler_job.py:182} INFO - Started process (PID=1037) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:27:09,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:27:09,764] {logging_mixin.py:104} INFO - [2021-04-23 21:27:09,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:27:10,686] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:27:10,831] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:27:10,881] {logging_mixin.py:104} INFO - [2021-04-23 21:27:10,872] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:27:10,948] {logging_mixin.py:104} INFO - [2021-04-23 21:27:10,948] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:27:10,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.223 seconds
[2021-04-23 21:27:41,124] {scheduler_job.py:182} INFO - Started process (PID=1039) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:27:41,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:27:41,140] {logging_mixin.py:104} INFO - [2021-04-23 21:27:41,140] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:27:41,621] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:27:41,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:27:41,699] {logging_mixin.py:104} INFO - [2021-04-23 21:27:41,689] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:27:41,748] {logging_mixin.py:104} INFO - [2021-04-23 21:27:41,748] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:27:41,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.650 seconds
[2021-04-23 21:28:12,830] {scheduler_job.py:182} INFO - Started process (PID=1041) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:28:12,838] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:28:12,843] {logging_mixin.py:104} INFO - [2021-04-23 21:28:12,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:28:13,355] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:28:13,404] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:28:13,426] {logging_mixin.py:104} INFO - [2021-04-23 21:28:13,423] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:28:13,457] {logging_mixin.py:104} INFO - [2021-04-23 21:28:13,457] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:28:13,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.644 seconds
[2021-04-23 21:28:43,682] {scheduler_job.py:182} INFO - Started process (PID=1043) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:28:43,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:28:43,688] {logging_mixin.py:104} INFO - [2021-04-23 21:28:43,688] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:28:44,026] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:28:44,053] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:28:44,066] {logging_mixin.py:104} INFO - [2021-04-23 21:28:44,064] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:28:44,086] {logging_mixin.py:104} INFO - [2021-04-23 21:28:44,086] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:28:44,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.420 seconds
[2021-04-23 21:29:14,220] {scheduler_job.py:182} INFO - Started process (PID=1045) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:29:14,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:29:14,227] {logging_mixin.py:104} INFO - [2021-04-23 21:29:14,226] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:29:14,556] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:29:14,585] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:29:14,598] {logging_mixin.py:104} INFO - [2021-04-23 21:29:14,597] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:29:14,617] {logging_mixin.py:104} INFO - [2021-04-23 21:29:14,617] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:29:14,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.423 seconds
[2021-04-23 21:29:44,772] {scheduler_job.py:182} INFO - Started process (PID=1047) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:29:44,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:29:44,777] {logging_mixin.py:104} INFO - [2021-04-23 21:29:44,777] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:29:45,287] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:29:45,323] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:29:45,344] {logging_mixin.py:104} INFO - [2021-04-23 21:29:45,342] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:29:45,374] {logging_mixin.py:104} INFO - [2021-04-23 21:29:45,374] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:29:45,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.627 seconds
[2021-04-23 21:30:15,944] {scheduler_job.py:182} INFO - Started process (PID=1049) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:30:15,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:30:15,967] {logging_mixin.py:104} INFO - [2021-04-23 21:30:15,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:30:16,670] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:30:16,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:30:16,741] {logging_mixin.py:104} INFO - [2021-04-23 21:30:16,739] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:30:16,776] {logging_mixin.py:104} INFO - [2021-04-23 21:30:16,776] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:30:16,795] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.860 seconds
[2021-04-23 21:30:46,992] {scheduler_job.py:182} INFO - Started process (PID=1051) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:30:46,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:30:46,997] {logging_mixin.py:104} INFO - [2021-04-23 21:30:46,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:30:47,450] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:30:47,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:30:47,524] {logging_mixin.py:104} INFO - [2021-04-23 21:30:47,522] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:30:47,557] {logging_mixin.py:104} INFO - [2021-04-23 21:30:47,556] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:30:47,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.588 seconds
[2021-04-23 21:31:17,734] {scheduler_job.py:182} INFO - Started process (PID=1053) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:31:17,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:31:17,745] {logging_mixin.py:104} INFO - [2021-04-23 21:31:17,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:31:18,183] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:31:18,232] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:31:18,254] {logging_mixin.py:104} INFO - [2021-04-23 21:31:18,252] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:31:18,283] {logging_mixin.py:104} INFO - [2021-04-23 21:31:18,283] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:31:18,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.571 seconds
[2021-04-23 21:31:48,440] {scheduler_job.py:182} INFO - Started process (PID=1055) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:31:48,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:31:48,449] {logging_mixin.py:104} INFO - [2021-04-23 21:31:48,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:31:48,885] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:31:48,917] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:31:48,929] {logging_mixin.py:104} INFO - [2021-04-23 21:31:48,928] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:31:48,946] {logging_mixin.py:104} INFO - [2021-04-23 21:31:48,946] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:31:48,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.542 seconds
[2021-04-23 21:32:19,144] {scheduler_job.py:182} INFO - Started process (PID=1057) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:32:19,148] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:32:19,150] {logging_mixin.py:104} INFO - [2021-04-23 21:32:19,150] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:32:19,576] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:32:19,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:32:19,631] {logging_mixin.py:104} INFO - [2021-04-23 21:32:19,629] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:32:19,654] {logging_mixin.py:104} INFO - [2021-04-23 21:32:19,654] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:32:19,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.528 seconds
[2021-04-23 21:32:49,976] {scheduler_job.py:182} INFO - Started process (PID=1059) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:32:49,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:32:49,984] {logging_mixin.py:104} INFO - [2021-04-23 21:32:49,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:32:50,294] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:32:50,324] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:32:50,345] {logging_mixin.py:104} INFO - [2021-04-23 21:32:50,344] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:32:50,365] {logging_mixin.py:104} INFO - [2021-04-23 21:32:50,365] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:32:50,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.455 seconds
[2021-04-23 21:33:20,578] {scheduler_job.py:182} INFO - Started process (PID=1061) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:33:20,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:33:20,584] {logging_mixin.py:104} INFO - [2021-04-23 21:33:20,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:33:20,919] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:33:20,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:33:20,957] {logging_mixin.py:104} INFO - [2021-04-23 21:33:20,955] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:33:20,977] {logging_mixin.py:104} INFO - [2021-04-23 21:33:20,976] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:33:20,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.413 seconds
[2021-04-23 21:33:51,174] {scheduler_job.py:182} INFO - Started process (PID=1063) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:33:51,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:33:51,193] {logging_mixin.py:104} INFO - [2021-04-23 21:33:51,192] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:33:51,545] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:33:51,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:33:51,589] {logging_mixin.py:104} INFO - [2021-04-23 21:33:51,587] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:33:51,608] {logging_mixin.py:104} INFO - [2021-04-23 21:33:51,608] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:33:51,618] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.451 seconds
[2021-04-23 21:34:21,822] {scheduler_job.py:182} INFO - Started process (PID=1065) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:34:21,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:34:21,828] {logging_mixin.py:104} INFO - [2021-04-23 21:34:21,828] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:34:22,260] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-23 21:34:22,318] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:34:22,359] {logging_mixin.py:104} INFO - [2021-04-23 21:34:22,355] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-23 21:34:22,401] {logging_mixin.py:104} INFO - [2021-04-23 21:34:22,401] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-23 21:34:22,425] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.617 seconds
[2021-04-23 21:34:52,563] {scheduler_job.py:182} INFO - Started process (PID=1067) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:34:52,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:34:52,568] {logging_mixin.py:104} INFO - [2021-04-23 21:34:52,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:34:52,594] {logging_mixin.py:104} INFO - [2021-04-23 21:34:52,584] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:34:52,597] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:34:52,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.075 seconds
[2021-04-23 21:35:22,772] {scheduler_job.py:182} INFO - Started process (PID=1068) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:35:22,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:35:22,777] {logging_mixin.py:104} INFO - [2021-04-23 21:35:22,777] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:35:22,791] {logging_mixin.py:104} INFO - [2021-04-23 21:35:22,790] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:35:22,793] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:35:22,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.052 seconds
[2021-04-23 21:35:53,004] {scheduler_job.py:182} INFO - Started process (PID=1070) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:35:53,052] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:35:53,055] {logging_mixin.py:104} INFO - [2021-04-23 21:35:53,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:35:53,101] {logging_mixin.py:104} INFO - [2021-04-23 21:35:53,100] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:35:53,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:35:53,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.137 seconds
[2021-04-23 21:36:25,398] {scheduler_job.py:182} INFO - Started process (PID=1072) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:36:25,418] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:36:25,430] {logging_mixin.py:104} INFO - [2021-04-23 21:36:25,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:36:25,472] {logging_mixin.py:104} INFO - [2021-04-23 21:36:25,468] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:36:25,488] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:36:25,635] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.326 seconds
[2021-04-23 21:36:55,717] {scheduler_job.py:182} INFO - Started process (PID=1074) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:36:55,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:36:55,725] {logging_mixin.py:104} INFO - [2021-04-23 21:36:55,725] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:36:55,742] {logging_mixin.py:104} INFO - [2021-04-23 21:36:55,741] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:36:55,745] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:36:55,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.059 seconds
[2021-04-23 21:37:25,952] {scheduler_job.py:182} INFO - Started process (PID=1076) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:37:25,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:37:25,959] {logging_mixin.py:104} INFO - [2021-04-23 21:37:25,959] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:37:25,980] {logging_mixin.py:104} INFO - [2021-04-23 21:37:25,978] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:37:25,984] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:37:26,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.072 seconds
[2021-04-23 21:37:56,712] {scheduler_job.py:182} INFO - Started process (PID=1078) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:37:56,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:37:56,727] {logging_mixin.py:104} INFO - [2021-04-23 21:37:56,726] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:37:56,796] {logging_mixin.py:104} INFO - [2021-04-23 21:37:56,781] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:37:56,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:37:56,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.234 seconds
[2021-04-23 21:38:27,696] {scheduler_job.py:182} INFO - Started process (PID=1080) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:38:27,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:38:27,703] {logging_mixin.py:104} INFO - [2021-04-23 21:38:27,702] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:38:27,735] {logging_mixin.py:104} INFO - [2021-04-23 21:38:27,734] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:38:27,748] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:38:27,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.111 seconds
[2021-04-23 21:38:57,935] {scheduler_job.py:182} INFO - Started process (PID=1082) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:38:57,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:38:57,940] {logging_mixin.py:104} INFO - [2021-04-23 21:38:57,940] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:38:57,952] {logging_mixin.py:104} INFO - [2021-04-23 21:38:57,951] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:38:57,956] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:38:57,982] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.051 seconds
[2021-04-23 21:39:28,114] {scheduler_job.py:182} INFO - Started process (PID=1084) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:39:28,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:39:28,119] {logging_mixin.py:104} INFO - [2021-04-23 21:39:28,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:39:28,130] {logging_mixin.py:104} INFO - [2021-04-23 21:39:28,129] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:39:28,132] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:39:28,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.050 seconds
[2021-04-23 21:39:58,311] {scheduler_job.py:182} INFO - Started process (PID=1086) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:39:58,317] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:39:58,319] {logging_mixin.py:104} INFO - [2021-04-23 21:39:58,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:39:58,354] {logging_mixin.py:104} INFO - [2021-04-23 21:39:58,352] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:39:58,360] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:39:58,416] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.111 seconds
[2021-04-23 21:40:28,546] {scheduler_job.py:182} INFO - Started process (PID=1088) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:40:28,549] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:40:28,551] {logging_mixin.py:104} INFO - [2021-04-23 21:40:28,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:40:28,563] {logging_mixin.py:104} INFO - [2021-04-23 21:40:28,562] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:40:28,566] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:40:28,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.047 seconds
[2021-04-23 21:40:58,697] {scheduler_job.py:182} INFO - Started process (PID=1090) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:40:58,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:40:58,703] {logging_mixin.py:104} INFO - [2021-04-23 21:40:58,702] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:40:58,715] {logging_mixin.py:104} INFO - [2021-04-23 21:40:58,714] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:40:58,718] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:40:58,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.058 seconds
[2021-04-23 21:41:29,319] {scheduler_job.py:182} INFO - Started process (PID=1092) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:41:29,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:41:29,354] {logging_mixin.py:104} INFO - [2021-04-23 21:41:29,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:41:29,390] {logging_mixin.py:104} INFO - [2021-04-23 21:41:29,382] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:41:29,405] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:41:29,578] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.285 seconds
[2021-04-23 21:41:59,793] {scheduler_job.py:182} INFO - Started process (PID=1094) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:41:59,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:41:59,799] {logging_mixin.py:104} INFO - [2021-04-23 21:41:59,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:41:59,810] {logging_mixin.py:104} INFO - [2021-04-23 21:41:59,810] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:41:59,813] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:41:59,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.046 seconds
[2021-04-23 21:42:30,059] {scheduler_job.py:182} INFO - Started process (PID=1096) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:42:30,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:42:30,083] {logging_mixin.py:104} INFO - [2021-04-23 21:42:30,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:42:30,126] {logging_mixin.py:104} INFO - [2021-04-23 21:42:30,122] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:42:30,153] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:42:30,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.173 seconds
[2021-04-23 21:43:00,329] {scheduler_job.py:182} INFO - Started process (PID=1098) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:43:00,332] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:43:00,334] {logging_mixin.py:104} INFO - [2021-04-23 21:43:00,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:43:00,345] {logging_mixin.py:104} INFO - [2021-04-23 21:43:00,344] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:43:00,347] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:43:00,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.047 seconds
[2021-04-23 21:43:30,546] {scheduler_job.py:182} INFO - Started process (PID=1100) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:43:30,550] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:43:30,551] {logging_mixin.py:104} INFO - [2021-04-23 21:43:30,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:43:30,566] {logging_mixin.py:104} INFO - [2021-04-23 21:43:30,565] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:43:30,570] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:43:30,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.060 seconds
[2021-04-23 21:44:00,707] {scheduler_job.py:182} INFO - Started process (PID=1102) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:44:00,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:44:00,711] {logging_mixin.py:104} INFO - [2021-04-23 21:44:00,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:44:00,723] {logging_mixin.py:104} INFO - [2021-04-23 21:44:00,722] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:44:00,726] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:44:00,751] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.048 seconds
[2021-04-23 21:44:30,874] {scheduler_job.py:182} INFO - Started process (PID=1104) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:44:30,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:44:30,878] {logging_mixin.py:104} INFO - [2021-04-23 21:44:30,878] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:44:30,887] {logging_mixin.py:104} INFO - [2021-04-23 21:44:30,886] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:44:30,891] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:44:30,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.051 seconds
[2021-04-23 21:45:01,021] {scheduler_job.py:182} INFO - Started process (PID=1106) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:45:01,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:45:01,027] {logging_mixin.py:104} INFO - [2021-04-23 21:45:01,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:45:01,038] {logging_mixin.py:104} INFO - [2021-04-23 21:45:01,037] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:45:01,040] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:45:01,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.046 seconds
[2021-04-23 21:45:31,160] {scheduler_job.py:182} INFO - Started process (PID=1108) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:45:31,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:45:31,164] {logging_mixin.py:104} INFO - [2021-04-23 21:45:31,164] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:45:31,173] {logging_mixin.py:104} INFO - [2021-04-23 21:45:31,172] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:45:31,178] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:45:31,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.044 seconds
[2021-04-23 21:46:01,324] {scheduler_job.py:182} INFO - Started process (PID=1110) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:46:01,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:46:01,331] {logging_mixin.py:104} INFO - [2021-04-23 21:46:01,331] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:46:01,340] {logging_mixin.py:104} INFO - [2021-04-23 21:46:01,339] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:46:01,344] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:46:01,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.044 seconds
[2021-04-23 21:46:31,488] {scheduler_job.py:182} INFO - Started process (PID=1112) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:46:31,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:46:31,493] {logging_mixin.py:104} INFO - [2021-04-23 21:46:31,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:46:31,504] {logging_mixin.py:104} INFO - [2021-04-23 21:46:31,503] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:46:31,507] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:46:31,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.052 seconds
[2021-04-23 21:47:01,655] {scheduler_job.py:182} INFO - Started process (PID=1114) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:47:01,658] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:47:01,661] {logging_mixin.py:104} INFO - [2021-04-23 21:47:01,661] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:47:01,680] {logging_mixin.py:104} INFO - [2021-04-23 21:47:01,678] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:47:01,687] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:47:01,723] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.074 seconds
[2021-04-23 21:47:31,819] {scheduler_job.py:182} INFO - Started process (PID=1116) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:47:31,822] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:47:31,824] {logging_mixin.py:104} INFO - [2021-04-23 21:47:31,823] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:47:31,834] {logging_mixin.py:104} INFO - [2021-04-23 21:47:31,832] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:47:31,836] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:47:31,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.049 seconds
[2021-04-23 21:48:01,975] {scheduler_job.py:182} INFO - Started process (PID=1118) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:48:01,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:48:01,982] {logging_mixin.py:104} INFO - [2021-04-23 21:48:01,981] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:48:01,990] {logging_mixin.py:104} INFO - [2021-04-23 21:48:01,989] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:48:01,995] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:48:02,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.049 seconds
[2021-04-23 21:48:32,109] {scheduler_job.py:182} INFO - Started process (PID=1120) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:48:32,113] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:48:32,115] {logging_mixin.py:104} INFO - [2021-04-23 21:48:32,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:48:32,127] {logging_mixin.py:104} INFO - [2021-04-23 21:48:32,125] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:48:32,129] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:48:32,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.059 seconds
[2021-04-23 21:49:02,284] {scheduler_job.py:182} INFO - Started process (PID=1122) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:49:02,286] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:49:02,290] {logging_mixin.py:104} INFO - [2021-04-23 21:49:02,289] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:49:02,304] {logging_mixin.py:104} INFO - [2021-04-23 21:49:02,303] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:49:02,308] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:49:02,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.049 seconds
[2021-04-23 21:49:32,510] {scheduler_job.py:182} INFO - Started process (PID=1124) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:49:32,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:49:32,515] {logging_mixin.py:104} INFO - [2021-04-23 21:49:32,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:49:32,526] {logging_mixin.py:104} INFO - [2021-04-23 21:49:32,525] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:49:32,531] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:49:32,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.056 seconds
[2021-04-23 21:50:02,661] {scheduler_job.py:182} INFO - Started process (PID=1126) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:50:02,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:50:02,666] {logging_mixin.py:104} INFO - [2021-04-23 21:50:02,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:50:02,674] {logging_mixin.py:104} INFO - [2021-04-23 21:50:02,674] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:50:02,677] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:50:02,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.044 seconds
[2021-04-23 21:50:32,799] {scheduler_job.py:182} INFO - Started process (PID=1128) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:50:32,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:50:32,803] {logging_mixin.py:104} INFO - [2021-04-23 21:50:32,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:50:32,814] {logging_mixin.py:104} INFO - [2021-04-23 21:50:32,813] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:50:32,818] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:50:32,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.067 seconds
[2021-04-23 21:51:02,950] {scheduler_job.py:182} INFO - Started process (PID=1130) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:51:02,954] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:51:02,956] {logging_mixin.py:104} INFO - [2021-04-23 21:51:02,956] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:51:02,967] {logging_mixin.py:104} INFO - [2021-04-23 21:51:02,966] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:51:02,969] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:51:02,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.046 seconds
[2021-04-23 21:51:33,108] {scheduler_job.py:182} INFO - Started process (PID=1132) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:51:33,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:51:33,113] {logging_mixin.py:104} INFO - [2021-04-23 21:51:33,113] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:51:33,125] {logging_mixin.py:104} INFO - [2021-04-23 21:51:33,124] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:51:33,128] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:51:33,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.047 seconds
[2021-04-23 21:52:03,298] {scheduler_job.py:182} INFO - Started process (PID=1134) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:52:03,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:52:03,303] {logging_mixin.py:104} INFO - [2021-04-23 21:52:03,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:52:03,314] {logging_mixin.py:104} INFO - [2021-04-23 21:52:03,313] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:52:03,317] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:52:03,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.051 seconds
[2021-04-23 21:52:33,560] {scheduler_job.py:182} INFO - Started process (PID=1135) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:52:33,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:52:33,569] {logging_mixin.py:104} INFO - [2021-04-23 21:52:33,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:52:33,585] {logging_mixin.py:104} INFO - [2021-04-23 21:52:33,584] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:52:33,588] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:52:33,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.091 seconds
[2021-04-23 21:53:03,779] {scheduler_job.py:182} INFO - Started process (PID=1137) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:53:03,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:53:03,789] {logging_mixin.py:104} INFO - [2021-04-23 21:53:03,787] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:53:03,808] {logging_mixin.py:104} INFO - [2021-04-23 21:53:03,807] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:53:03,811] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:53:03,846] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.073 seconds
[2021-04-23 21:53:34,015] {scheduler_job.py:182} INFO - Started process (PID=1139) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:53:34,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:53:34,024] {logging_mixin.py:104} INFO - [2021-04-23 21:53:34,023] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:53:34,039] {logging_mixin.py:104} INFO - [2021-04-23 21:53:34,038] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:53:34,046] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:53:34,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.075 seconds
[2021-04-23 21:54:04,442] {scheduler_job.py:182} INFO - Started process (PID=1141) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:54:04,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:54:04,452] {logging_mixin.py:104} INFO - [2021-04-23 21:54:04,452] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:54:04,464] {logging_mixin.py:104} INFO - [2021-04-23 21:54:04,463] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:54:04,469] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:54:04,498] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.063 seconds
[2021-04-23 21:54:34,622] {scheduler_job.py:182} INFO - Started process (PID=1143) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:54:34,625] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:54:34,626] {logging_mixin.py:104} INFO - [2021-04-23 21:54:34,626] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:54:34,641] {logging_mixin.py:104} INFO - [2021-04-23 21:54:34,639] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:54:34,644] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:54:34,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.048 seconds
[2021-04-23 21:55:04,777] {scheduler_job.py:182} INFO - Started process (PID=1145) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:55:04,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:55:04,787] {logging_mixin.py:104} INFO - [2021-04-23 21:55:04,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:55:04,798] {logging_mixin.py:104} INFO - [2021-04-23 21:55:04,798] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:55:04,801] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:55:04,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.060 seconds
[2021-04-23 21:55:34,934] {scheduler_job.py:182} INFO - Started process (PID=1147) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:55:34,936] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:55:34,939] {logging_mixin.py:104} INFO - [2021-04-23 21:55:34,939] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:55:34,950] {logging_mixin.py:104} INFO - [2021-04-23 21:55:34,949] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:55:34,954] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:55:34,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.059 seconds
[2021-04-23 21:56:05,248] {scheduler_job.py:182} INFO - Started process (PID=1149) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:56:05,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:56:05,263] {logging_mixin.py:104} INFO - [2021-04-23 21:56:05,263] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:56:05,397] {logging_mixin.py:104} INFO - [2021-04-23 21:56:05,380] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:56:05,409] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:56:05,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.337 seconds
[2021-04-23 21:56:36,314] {scheduler_job.py:182} INFO - Started process (PID=1151) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:56:36,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:56:36,318] {logging_mixin.py:104} INFO - [2021-04-23 21:56:36,318] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:56:36,326] {logging_mixin.py:104} INFO - [2021-04-23 21:56:36,326] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:56:36,329] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:56:36,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.070 seconds
[2021-04-23 21:57:06,509] {scheduler_job.py:182} INFO - Started process (PID=1153) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:57:06,513] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:57:06,514] {logging_mixin.py:104} INFO - [2021-04-23 21:57:06,514] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:57:06,524] {logging_mixin.py:104} INFO - [2021-04-23 21:57:06,523] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:57:06,528] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:57:06,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.042 seconds
[2021-04-23 21:57:36,754] {scheduler_job.py:182} INFO - Started process (PID=1155) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:57:36,756] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:57:36,758] {logging_mixin.py:104} INFO - [2021-04-23 21:57:36,758] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:57:36,766] {logging_mixin.py:104} INFO - [2021-04-23 21:57:36,765] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:57:36,769] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:57:36,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.051 seconds
[2021-04-23 21:58:06,924] {scheduler_job.py:182} INFO - Started process (PID=1157) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:58:06,926] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:58:06,928] {logging_mixin.py:104} INFO - [2021-04-23 21:58:06,928] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:58:06,937] {logging_mixin.py:104} INFO - [2021-04-23 21:58:06,937] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:58:06,940] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:58:06,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.046 seconds
[2021-04-23 21:58:37,124] {scheduler_job.py:182} INFO - Started process (PID=1159) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:58:37,128] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:58:37,130] {logging_mixin.py:104} INFO - [2021-04-23 21:58:37,130] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:58:37,143] {logging_mixin.py:104} INFO - [2021-04-23 21:58:37,142] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:58:37,147] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:58:37,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.059 seconds
[2021-04-23 21:59:07,287] {scheduler_job.py:182} INFO - Started process (PID=1161) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:59:07,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:59:07,291] {logging_mixin.py:104} INFO - [2021-04-23 21:59:07,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:59:07,300] {logging_mixin.py:104} INFO - [2021-04-23 21:59:07,300] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:59:07,303] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:59:07,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.045 seconds
[2021-04-23 21:59:37,449] {scheduler_job.py:182} INFO - Started process (PID=1163) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:59:37,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 21:59:37,455] {logging_mixin.py:104} INFO - [2021-04-23 21:59:37,454] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:59:37,469] {logging_mixin.py:104} INFO - [2021-04-23 21:59:37,466] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 21:59:37,472] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 21:59:37,505] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.062 seconds
[2021-04-23 22:00:07,642] {scheduler_job.py:182} INFO - Started process (PID=1165) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:00:07,646] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:00:07,651] {logging_mixin.py:104} INFO - [2021-04-23 22:00:07,651] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:00:07,663] {logging_mixin.py:104} INFO - [2021-04-23 22:00:07,662] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:00:07,666] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:00:07,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.055 seconds
[2021-04-23 22:00:37,792] {scheduler_job.py:182} INFO - Started process (PID=1167) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:00:37,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:00:37,797] {logging_mixin.py:104} INFO - [2021-04-23 22:00:37,796] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:00:37,807] {logging_mixin.py:104} INFO - [2021-04-23 22:00:37,807] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:00:37,810] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:00:37,834] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.046 seconds
[2021-04-23 22:01:07,957] {scheduler_job.py:182} INFO - Started process (PID=1169) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:01:07,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:01:07,963] {logging_mixin.py:104} INFO - [2021-04-23 22:01:07,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:01:07,973] {logging_mixin.py:104} INFO - [2021-04-23 22:01:07,972] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:01:07,976] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:01:08,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.060 seconds
[2021-04-23 22:01:38,250] {scheduler_job.py:182} INFO - Started process (PID=1171) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:01:38,252] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:01:38,254] {logging_mixin.py:104} INFO - [2021-04-23 22:01:38,254] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:01:38,265] {logging_mixin.py:104} INFO - [2021-04-23 22:01:38,264] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:01:38,268] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:01:38,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.053 seconds
[2021-04-23 22:02:08,416] {scheduler_job.py:182} INFO - Started process (PID=1173) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:02:08,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:02:08,420] {logging_mixin.py:104} INFO - [2021-04-23 22:02:08,420] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:02:08,431] {logging_mixin.py:104} INFO - [2021-04-23 22:02:08,430] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:02:08,433] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:02:08,456] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.044 seconds
[2021-04-23 22:02:38,583] {scheduler_job.py:182} INFO - Started process (PID=1175) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:02:38,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:02:38,587] {logging_mixin.py:104} INFO - [2021-04-23 22:02:38,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:02:38,597] {logging_mixin.py:104} INFO - [2021-04-23 22:02:38,596] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:02:38,600] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:02:38,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.044 seconds
[2021-04-23 22:03:08,789] {scheduler_job.py:182} INFO - Started process (PID=1177) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:03:08,798] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:03:08,804] {logging_mixin.py:104} INFO - [2021-04-23 22:03:08,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:03:08,837] {logging_mixin.py:104} INFO - [2021-04-23 22:03:08,829] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:03:08,840] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:03:08,896] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.131 seconds
[2021-04-23 22:03:38,995] {scheduler_job.py:182} INFO - Started process (PID=1179) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:03:39,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:03:39,023] {logging_mixin.py:104} INFO - [2021-04-23 22:03:39,022] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:03:39,034] {logging_mixin.py:104} INFO - [2021-04-23 22:03:39,033] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:03:39,037] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:03:39,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.081 seconds
[2021-04-23 22:04:09,210] {scheduler_job.py:182} INFO - Started process (PID=1181) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:04:09,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:04:09,215] {logging_mixin.py:104} INFO - [2021-04-23 22:04:09,215] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:04:09,227] {logging_mixin.py:104} INFO - [2021-04-23 22:04:09,226] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:04:09,231] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:04:09,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.055 seconds
[2021-04-23 22:04:39,356] {scheduler_job.py:182} INFO - Started process (PID=1183) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:04:39,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:04:39,360] {logging_mixin.py:104} INFO - [2021-04-23 22:04:39,360] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:04:39,373] {logging_mixin.py:104} INFO - [2021-04-23 22:04:39,372] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:04:39,378] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:04:39,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.055 seconds
[2021-04-23 22:05:09,528] {scheduler_job.py:182} INFO - Started process (PID=1185) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:05:09,532] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:05:09,534] {logging_mixin.py:104} INFO - [2021-04-23 22:05:09,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:05:09,545] {logging_mixin.py:104} INFO - [2021-04-23 22:05:09,544] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:05:09,548] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:05:09,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.054 seconds
[2021-04-23 22:05:39,698] {scheduler_job.py:182} INFO - Started process (PID=1187) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:05:39,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:05:39,703] {logging_mixin.py:104} INFO - [2021-04-23 22:05:39,703] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:05:39,721] {logging_mixin.py:104} INFO - [2021-04-23 22:05:39,716] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:05:39,725] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:05:39,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.058 seconds
[2021-04-23 22:06:09,894] {scheduler_job.py:182} INFO - Started process (PID=1189) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:06:09,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:06:09,898] {logging_mixin.py:104} INFO - [2021-04-23 22:06:09,898] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:06:09,906] {logging_mixin.py:104} INFO - [2021-04-23 22:06:09,905] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:06:09,909] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:06:09,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.045 seconds
[2021-04-23 22:06:40,050] {scheduler_job.py:182} INFO - Started process (PID=1191) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:06:40,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:06:40,056] {logging_mixin.py:104} INFO - [2021-04-23 22:06:40,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:06:40,065] {logging_mixin.py:104} INFO - [2021-04-23 22:06:40,064] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:06:40,068] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:06:40,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.056 seconds
[2021-04-23 22:07:10,223] {scheduler_job.py:182} INFO - Started process (PID=1193) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:07:10,225] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:07:10,227] {logging_mixin.py:104} INFO - [2021-04-23 22:07:10,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:07:10,235] {logging_mixin.py:104} INFO - [2021-04-23 22:07:10,234] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:07:10,238] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:07:10,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.042 seconds
[2021-04-23 22:07:40,407] {scheduler_job.py:182} INFO - Started process (PID=1195) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:07:40,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:07:40,414] {logging_mixin.py:104} INFO - [2021-04-23 22:07:40,413] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:07:40,423] {logging_mixin.py:104} INFO - [2021-04-23 22:07:40,422] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:07:40,425] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:07:40,457] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.053 seconds
[2021-04-23 22:08:10,542] {scheduler_job.py:182} INFO - Started process (PID=1197) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:08:10,545] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:08:10,547] {logging_mixin.py:104} INFO - [2021-04-23 22:08:10,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:08:10,560] {logging_mixin.py:104} INFO - [2021-04-23 22:08:10,559] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:08:10,563] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:08:10,585] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.048 seconds
[2021-04-23 22:08:40,725] {scheduler_job.py:182} INFO - Started process (PID=1199) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:08:40,728] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:08:40,732] {logging_mixin.py:104} INFO - [2021-04-23 22:08:40,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:08:40,745] {logging_mixin.py:104} INFO - [2021-04-23 22:08:40,743] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:08:40,748] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:08:40,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.064 seconds
[2021-04-23 22:09:10,907] {scheduler_job.py:182} INFO - Started process (PID=1200) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:09:10,910] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:09:10,913] {logging_mixin.py:104} INFO - [2021-04-23 22:09:10,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:09:10,930] {logging_mixin.py:104} INFO - [2021-04-23 22:09:10,928] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:09:10,935] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:09:10,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.064 seconds
[2021-04-23 22:09:41,094] {scheduler_job.py:182} INFO - Started process (PID=1202) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:09:41,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:09:41,102] {logging_mixin.py:104} INFO - [2021-04-23 22:09:41,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:09:41,121] {logging_mixin.py:104} INFO - [2021-04-23 22:09:41,120] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:09:41,128] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:09:41,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.087 seconds
[2021-04-23 22:10:11,529] {scheduler_job.py:182} INFO - Started process (PID=1204) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:10:11,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:10:11,548] {logging_mixin.py:104} INFO - [2021-04-23 22:10:11,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:10:11,597] {logging_mixin.py:104} INFO - [2021-04-23 22:10:11,589] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:10:11,602] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:10:11,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.160 seconds
[2021-04-23 22:10:41,975] {scheduler_job.py:182} INFO - Started process (PID=1206) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:10:41,983] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:10:41,992] {logging_mixin.py:104} INFO - [2021-04-23 22:10:41,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:10:42,020] {logging_mixin.py:104} INFO - [2021-04-23 22:10:42,015] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:10:42,027] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:10:42,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.323 seconds
[2021-04-23 22:11:13,122] {scheduler_job.py:182} INFO - Started process (PID=1208) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:11:13,127] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:11:13,133] {logging_mixin.py:104} INFO - [2021-04-23 22:11:13,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:11:13,145] {logging_mixin.py:104} INFO - [2021-04-23 22:11:13,143] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:11:13,148] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:11:13,183] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.067 seconds
[2021-04-23 22:11:43,306] {scheduler_job.py:182} INFO - Started process (PID=1210) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:11:43,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:11:43,311] {logging_mixin.py:104} INFO - [2021-04-23 22:11:43,311] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:11:43,320] {logging_mixin.py:104} INFO - [2021-04-23 22:11:43,319] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:11:43,323] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:11:43,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.043 seconds
[2021-04-23 22:12:13,484] {scheduler_job.py:182} INFO - Started process (PID=1212) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:12:13,489] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:12:13,492] {logging_mixin.py:104} INFO - [2021-04-23 22:12:13,492] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:12:13,513] {logging_mixin.py:104} INFO - [2021-04-23 22:12:13,511] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:12:13,516] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:12:13,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.062 seconds
[2021-04-23 22:12:43,715] {scheduler_job.py:182} INFO - Started process (PID=1214) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:12:43,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:12:43,723] {logging_mixin.py:104} INFO - [2021-04-23 22:12:43,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:12:43,739] {logging_mixin.py:104} INFO - [2021-04-23 22:12:43,738] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:12:43,743] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:12:43,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.067 seconds
[2021-04-23 22:13:13,906] {scheduler_job.py:182} INFO - Started process (PID=1216) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:13:13,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:13:13,914] {logging_mixin.py:104} INFO - [2021-04-23 22:13:13,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:13:13,923] {logging_mixin.py:104} INFO - [2021-04-23 22:13:13,922] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:13:13,929] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:13:13,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.066 seconds
[2021-04-23 22:13:44,120] {scheduler_job.py:182} INFO - Started process (PID=1218) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:13:44,123] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:13:44,126] {logging_mixin.py:104} INFO - [2021-04-23 22:13:44,126] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:13:44,142] {logging_mixin.py:104} INFO - [2021-04-23 22:13:44,138] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:13:44,146] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:13:44,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.072 seconds
[2021-04-23 22:14:14,299] {scheduler_job.py:182} INFO - Started process (PID=1220) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:14:14,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:14:14,308] {logging_mixin.py:104} INFO - [2021-04-23 22:14:14,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:14:14,316] {logging_mixin.py:104} INFO - [2021-04-23 22:14:14,315] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:14:14,318] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:14:14,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.053 seconds
[2021-04-23 22:14:44,474] {scheduler_job.py:182} INFO - Started process (PID=1222) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:14:44,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:14:44,481] {logging_mixin.py:104} INFO - [2021-04-23 22:14:44,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:14:44,502] {logging_mixin.py:104} INFO - [2021-04-23 22:14:44,499] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:14:44,508] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:14:44,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.061 seconds
[2021-04-23 22:15:14,688] {scheduler_job.py:182} INFO - Started process (PID=1224) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:15:14,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:15:14,694] {logging_mixin.py:104} INFO - [2021-04-23 22:15:14,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:15:14,708] {logging_mixin.py:104} INFO - [2021-04-23 22:15:14,707] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:15:14,712] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:15:14,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.059 seconds
[2021-04-23 22:15:44,999] {scheduler_job.py:182} INFO - Started process (PID=1226) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:15:45,005] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:15:45,008] {logging_mixin.py:104} INFO - [2021-04-23 22:15:45,008] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:15:45,044] {logging_mixin.py:104} INFO - [2021-04-23 22:15:45,042] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:15:45,050] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:15:45,130] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.138 seconds
[2021-04-23 22:16:15,311] {scheduler_job.py:182} INFO - Started process (PID=1228) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:16:15,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:16:15,323] {logging_mixin.py:104} INFO - [2021-04-23 22:16:15,323] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:16:15,344] {logging_mixin.py:104} INFO - [2021-04-23 22:16:15,342] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:16:15,349] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:16:15,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.078 seconds
[2021-04-23 22:16:45,492] {scheduler_job.py:182} INFO - Started process (PID=1230) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:16:45,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:16:45,497] {logging_mixin.py:104} INFO - [2021-04-23 22:16:45,497] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:16:45,509] {logging_mixin.py:104} INFO - [2021-04-23 22:16:45,507] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:16:45,512] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:16:45,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.051 seconds
[2021-04-23 22:17:15,662] {scheduler_job.py:182} INFO - Started process (PID=1232) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:17:15,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:17:15,669] {logging_mixin.py:104} INFO - [2021-04-23 22:17:15,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:17:15,679] {logging_mixin.py:104} INFO - [2021-04-23 22:17:15,678] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:17:15,682] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:17:15,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.048 seconds
[2021-04-23 22:17:45,890] {scheduler_job.py:182} INFO - Started process (PID=1234) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:17:45,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:17:45,897] {logging_mixin.py:104} INFO - [2021-04-23 22:17:45,896] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:17:45,917] {logging_mixin.py:104} INFO - [2021-04-23 22:17:45,913] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:17:45,921] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:17:45,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.068 seconds
[2021-04-23 22:18:16,077] {scheduler_job.py:182} INFO - Started process (PID=1236) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:18:16,082] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:18:16,084] {logging_mixin.py:104} INFO - [2021-04-23 22:18:16,084] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:18:16,100] {logging_mixin.py:104} INFO - [2021-04-23 22:18:16,099] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:18:16,106] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:18:16,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.088 seconds
[2021-04-23 22:18:46,264] {scheduler_job.py:182} INFO - Started process (PID=1238) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:18:46,268] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:18:46,272] {logging_mixin.py:104} INFO - [2021-04-23 22:18:46,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:18:46,296] {logging_mixin.py:104} INFO - [2021-04-23 22:18:46,294] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:18:46,324] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:18:46,370] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.113 seconds
[2021-04-23 22:19:16,483] {scheduler_job.py:182} INFO - Started process (PID=1240) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:19:16,486] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:19:16,488] {logging_mixin.py:104} INFO - [2021-04-23 22:19:16,488] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:19:16,502] {logging_mixin.py:104} INFO - [2021-04-23 22:19:16,501] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:19:16,507] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:19:16,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.058 seconds
[2021-04-23 22:19:46,667] {scheduler_job.py:182} INFO - Started process (PID=1242) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:19:46,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:19:46,678] {logging_mixin.py:104} INFO - [2021-04-23 22:19:46,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:19:46,711] {logging_mixin.py:104} INFO - [2021-04-23 22:19:46,708] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:19:46,718] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:19:46,765] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.105 seconds
[2021-04-23 22:20:16,923] {scheduler_job.py:182} INFO - Started process (PID=1244) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:20:16,927] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:20:16,930] {logging_mixin.py:104} INFO - [2021-04-23 22:20:16,930] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:20:16,958] {logging_mixin.py:104} INFO - [2021-04-23 22:20:16,956] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:20:16,964] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:20:17,000] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.082 seconds
[2021-04-23 22:20:47,113] {scheduler_job.py:182} INFO - Started process (PID=1246) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:20:47,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:20:47,122] {logging_mixin.py:104} INFO - [2021-04-23 22:20:47,121] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:20:47,135] {logging_mixin.py:104} INFO - [2021-04-23 22:20:47,133] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:20:47,142] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:20:47,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.065 seconds
[2021-04-23 22:21:17,280] {scheduler_job.py:182} INFO - Started process (PID=1248) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:21:17,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:21:17,287] {logging_mixin.py:104} INFO - [2021-04-23 22:21:17,287] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:21:17,306] {logging_mixin.py:104} INFO - [2021-04-23 22:21:17,304] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:21:17,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:21:17,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.075 seconds
[2021-04-23 22:21:47,686] {scheduler_job.py:182} INFO - Started process (PID=1250) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:21:47,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:21:47,707] {logging_mixin.py:104} INFO - [2021-04-23 22:21:47,706] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:21:47,752] {logging_mixin.py:104} INFO - [2021-04-23 22:21:47,749] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:21:47,759] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:21:47,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.275 seconds
[2021-04-23 22:22:18,300] {scheduler_job.py:182} INFO - Started process (PID=1252) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:22:18,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:22:18,304] {logging_mixin.py:104} INFO - [2021-04-23 22:22:18,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:22:18,315] {logging_mixin.py:104} INFO - [2021-04-23 22:22:18,314] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:22:18,318] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:22:18,355] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.059 seconds
[2021-04-23 22:22:48,709] {scheduler_job.py:182} INFO - Started process (PID=1254) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:22:48,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:22:48,727] {logging_mixin.py:104} INFO - [2021-04-23 22:22:48,726] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:22:48,773] {logging_mixin.py:104} INFO - [2021-04-23 22:22:48,767] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:22:48,795] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:22:48,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.185 seconds
[2021-04-23 22:23:19,042] {scheduler_job.py:182} INFO - Started process (PID=1256) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:23:19,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:23:19,055] {logging_mixin.py:104} INFO - [2021-04-23 22:23:19,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:23:19,070] {logging_mixin.py:104} INFO - [2021-04-23 22:23:19,069] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:23:19,076] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:23:19,105] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.071 seconds
[2021-04-23 22:23:49,177] {scheduler_job.py:182} INFO - Started process (PID=1258) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:23:49,180] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:23:49,183] {logging_mixin.py:104} INFO - [2021-04-23 22:23:49,183] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:23:49,198] {logging_mixin.py:104} INFO - [2021-04-23 22:23:49,197] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:23:49,202] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:23:49,238] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.066 seconds
[2021-04-23 22:24:19,524] {scheduler_job.py:182} INFO - Started process (PID=1260) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:24:19,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:24:19,612] {logging_mixin.py:104} INFO - [2021-04-23 22:24:19,595] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:24:19,831] {logging_mixin.py:104} INFO - [2021-04-23 22:24:19,821] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:24:19,880] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:24:20,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.536 seconds
[2021-04-23 22:24:51,000] {scheduler_job.py:182} INFO - Started process (PID=1261) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:24:51,005] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:24:51,007] {logging_mixin.py:104} INFO - [2021-04-23 22:24:51,007] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:24:51,031] {logging_mixin.py:104} INFO - [2021-04-23 22:24:51,026] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:24:51,035] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:24:51,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.091 seconds
[2021-04-23 22:25:21,204] {scheduler_job.py:182} INFO - Started process (PID=1263) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:25:21,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:25:21,212] {logging_mixin.py:104} INFO - [2021-04-23 22:25:21,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:25:21,226] {logging_mixin.py:104} INFO - [2021-04-23 22:25:21,224] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:25:21,230] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:25:21,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.056 seconds
[2021-04-23 22:25:51,701] {scheduler_job.py:182} INFO - Started process (PID=1265) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:25:51,708] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-23 22:25:51,712] {logging_mixin.py:104} INFO - [2021-04-23 22:25:51,712] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:25:51,742] {logging_mixin.py:104} INFO - [2021-04-23 22:25:51,739] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 63
    gs://spotimood-landing-dev/model/ml_model.sav
        ^
SyntaxError: invalid syntax
[2021-04-23 22:25:51,747] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-23 22:25:51,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.100 seconds
