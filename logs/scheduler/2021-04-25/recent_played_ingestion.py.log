[2021-04-25 09:33:44,666] {scheduler_job.py:182} INFO - Started process (PID=23) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:33:44,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:33:44,675] {logging_mixin.py:104} INFO - [2021-04-25 09:33:44,674] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:33:50,821] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:33:50,984] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:33:51,064] {logging_mixin.py:104} INFO - [2021-04-25 09:33:51,063] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:33:51,127] {logging_mixin.py:104} INFO - [2021-04-25 09:33:51,127] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-25 09:33:51,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 6.515 seconds
[2021-04-25 09:34:21,464] {scheduler_job.py:182} INFO - Started process (PID=25) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:34:21,470] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:34:21,474] {logging_mixin.py:104} INFO - [2021-04-25 09:34:21,474] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:34:23,469] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:34:23,520] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:34:23,567] {logging_mixin.py:104} INFO - [2021-04-25 09:34:23,563] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:34:23,682] {logging_mixin.py:104} INFO - [2021-04-25 09:34:23,682] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-23T21:00:00+00:00
[2021-04-25 09:34:23,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.241 seconds
[2021-04-25 09:34:53,904] {scheduler_job.py:182} INFO - Started process (PID=27) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:34:53,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:34:53,918] {logging_mixin.py:104} INFO - [2021-04-25 09:34:53,917] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:34:54,958] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:34:54,993] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:34:55,009] {logging_mixin.py:104} INFO - [2021-04-25 09:34:55,008] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:34:55,026] {logging_mixin.py:104} INFO - [2021-04-25 09:34:55,024] {dag.py:1837} INFO - Creating ORM DAG for recent_played_ingestion
[2021-04-25 09:34:55,043] {logging_mixin.py:104} INFO - [2021-04-25 09:34:55,043] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:34:55,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.181 seconds
[2021-04-25 09:35:25,304] {scheduler_job.py:182} INFO - Started process (PID=29) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:35:25,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:35:25,309] {logging_mixin.py:104} INFO - [2021-04-25 09:35:25,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:35:26,498] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:35:26,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:35:26,540] {logging_mixin.py:104} INFO - [2021-04-25 09:35:26,539] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:35:26,569] {logging_mixin.py:104} INFO - [2021-04-25 09:35:26,568] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:35:26,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.296 seconds
[2021-04-25 09:35:57,184] {scheduler_job.py:182} INFO - Started process (PID=31) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:35:57,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:35:57,194] {logging_mixin.py:104} INFO - [2021-04-25 09:35:57,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:35:58,335] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:35:58,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:35:58,385] {logging_mixin.py:104} INFO - [2021-04-25 09:35:58,384] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:35:58,406] {logging_mixin.py:104} INFO - [2021-04-25 09:35:58,406] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:35:58,417] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.253 seconds
[2021-04-25 09:36:28,642] {scheduler_job.py:182} INFO - Started process (PID=33) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:36:28,646] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:36:28,648] {logging_mixin.py:104} INFO - [2021-04-25 09:36:28,648] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:36:29,940] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:36:30,014] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:36:30,037] {logging_mixin.py:104} INFO - [2021-04-25 09:36:30,034] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:36:30,076] {logging_mixin.py:104} INFO - [2021-04-25 09:36:30,076] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:36:30,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.455 seconds
[2021-04-25 09:37:00,223] {scheduler_job.py:182} INFO - Started process (PID=35) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:37:00,225] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:37:00,228] {logging_mixin.py:104} INFO - [2021-04-25 09:37:00,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:37:01,305] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:37:01,335] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:37:01,348] {logging_mixin.py:104} INFO - [2021-04-25 09:37:01,347] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:37:01,369] {logging_mixin.py:104} INFO - [2021-04-25 09:37:01,368] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:37:01,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.170 seconds
[2021-04-25 09:37:31,781] {scheduler_job.py:182} INFO - Started process (PID=37) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:37:31,785] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:37:31,790] {logging_mixin.py:104} INFO - [2021-04-25 09:37:31,790] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:37:32,687] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:37:32,739] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:37:32,763] {logging_mixin.py:104} INFO - [2021-04-25 09:37:32,759] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:37:32,800] {logging_mixin.py:104} INFO - [2021-04-25 09:37:32,800] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:37:32,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.040 seconds
[2021-04-25 09:38:02,905] {scheduler_job.py:182} INFO - Started process (PID=39) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:38:02,909] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:38:02,914] {logging_mixin.py:104} INFO - [2021-04-25 09:38:02,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:38:03,784] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:38:03,814] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:38:03,829] {logging_mixin.py:104} INFO - [2021-04-25 09:38:03,826] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:38:03,853] {logging_mixin.py:104} INFO - [2021-04-25 09:38:03,853] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:38:03,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.965 seconds
[2021-04-25 09:38:34,132] {scheduler_job.py:182} INFO - Started process (PID=41) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:38:34,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:38:34,138] {logging_mixin.py:104} INFO - [2021-04-25 09:38:34,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:38:34,894] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:38:34,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:38:34,937] {logging_mixin.py:104} INFO - [2021-04-25 09:38:34,935] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:38:34,954] {logging_mixin.py:104} INFO - [2021-04-25 09:38:34,954] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:38:34,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.835 seconds
[2021-04-25 09:39:05,144] {scheduler_job.py:182} INFO - Started process (PID=43) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:39:05,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:39:05,152] {logging_mixin.py:104} INFO - [2021-04-25 09:39:05,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:39:05,803] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:39:05,842] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:39:05,858] {logging_mixin.py:104} INFO - [2021-04-25 09:39:05,856] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:39:05,888] {logging_mixin.py:104} INFO - [2021-04-25 09:39:05,888] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:39:05,897] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.781 seconds
[2021-04-25 09:39:36,027] {scheduler_job.py:182} INFO - Started process (PID=45) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:39:36,030] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:39:36,032] {logging_mixin.py:104} INFO - [2021-04-25 09:39:36,031] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:39:36,698] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:39:36,723] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:39:36,735] {logging_mixin.py:104} INFO - [2021-04-25 09:39:36,734] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:39:36,757] {logging_mixin.py:104} INFO - [2021-04-25 09:39:36,757] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:39:36,765] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.743 seconds
[2021-04-25 09:40:07,128] {scheduler_job.py:182} INFO - Started process (PID=47) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:40:07,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:40:07,134] {logging_mixin.py:104} INFO - [2021-04-25 09:40:07,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:40:08,085] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:40:08,125] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:40:08,144] {logging_mixin.py:104} INFO - [2021-04-25 09:40:08,142] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:40:08,178] {logging_mixin.py:104} INFO - [2021-04-25 09:40:08,177] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T08:00:00+00:00
[2021-04-25 09:40:08,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.065 seconds
[2021-04-25 09:40:38,358] {scheduler_job.py:182} INFO - Started process (PID=49) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:40:38,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:40:38,362] {logging_mixin.py:104} INFO - [2021-04-25 09:40:38,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:40:39,197] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:40:39,239] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:40:39,251] {logging_mixin.py:104} INFO - [2021-04-25 09:40:39,249] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:40:39,267] {logging_mixin.py:104} INFO - [2021-04-25 09:40:39,266] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:40:39,276] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.922 seconds
[2021-04-25 09:41:09,444] {scheduler_job.py:182} INFO - Started process (PID=51) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:41:09,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:41:09,452] {logging_mixin.py:104} INFO - [2021-04-25 09:41:09,452] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:41:10,161] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:41:10,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:41:10,204] {logging_mixin.py:104} INFO - [2021-04-25 09:41:10,203] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:41:10,219] {logging_mixin.py:104} INFO - [2021-04-25 09:41:10,219] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:41:10,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.787 seconds
[2021-04-25 09:41:40,363] {scheduler_job.py:182} INFO - Started process (PID=53) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:41:40,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:41:40,370] {logging_mixin.py:104} INFO - [2021-04-25 09:41:40,370] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:41:41,015] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:41:41,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:41:41,080] {logging_mixin.py:104} INFO - [2021-04-25 09:41:41,079] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:41:41,098] {logging_mixin.py:104} INFO - [2021-04-25 09:41:41,098] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:41:41,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.749 seconds
[2021-04-25 09:42:11,234] {scheduler_job.py:182} INFO - Started process (PID=55) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:42:11,237] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:42:11,238] {logging_mixin.py:104} INFO - [2021-04-25 09:42:11,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:42:11,844] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:42:11,883] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:42:11,900] {logging_mixin.py:104} INFO - [2021-04-25 09:42:11,899] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:42:11,924] {logging_mixin.py:104} INFO - [2021-04-25 09:42:11,924] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:42:11,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.702 seconds
[2021-04-25 09:42:42,077] {scheduler_job.py:182} INFO - Started process (PID=57) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:42:42,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:42:42,084] {logging_mixin.py:104} INFO - [2021-04-25 09:42:42,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:42:42,853] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:42:42,883] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:42:42,897] {logging_mixin.py:104} INFO - [2021-04-25 09:42:42,895] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:42:42,926] {logging_mixin.py:104} INFO - [2021-04-25 09:42:42,925] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:42:42,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.878 seconds
[2021-04-25 09:43:13,046] {scheduler_job.py:182} INFO - Started process (PID=59) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:43:13,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:43:13,053] {logging_mixin.py:104} INFO - [2021-04-25 09:43:13,052] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:43:13,859] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:43:13,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:43:13,895] {logging_mixin.py:104} INFO - [2021-04-25 09:43:13,894] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:43:13,939] {logging_mixin.py:104} INFO - [2021-04-25 09:43:13,939] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:43:13,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.906 seconds
[2021-04-25 09:43:44,049] {scheduler_job.py:182} INFO - Started process (PID=61) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:43:44,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:43:44,057] {logging_mixin.py:104} INFO - [2021-04-25 09:43:44,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:43:44,815] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:43:44,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:43:44,857] {logging_mixin.py:104} INFO - [2021-04-25 09:43:44,856] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:43:44,874] {logging_mixin.py:104} INFO - [2021-04-25 09:43:44,874] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:43:44,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.848 seconds
[2021-04-25 09:44:15,119] {scheduler_job.py:182} INFO - Started process (PID=63) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:44:15,123] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:44:15,126] {logging_mixin.py:104} INFO - [2021-04-25 09:44:15,126] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:44:16,567] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:44:16,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:44:16,625] {logging_mixin.py:104} INFO - [2021-04-25 09:44:16,623] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:44:16,650] {logging_mixin.py:104} INFO - [2021-04-25 09:44:16,650] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:44:16,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.555 seconds
[2021-04-25 09:44:46,762] {scheduler_job.py:182} INFO - Started process (PID=65) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:44:46,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:44:46,765] {logging_mixin.py:104} INFO - [2021-04-25 09:44:46,765] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:44:47,858] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:44:47,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:44:48,003] {logging_mixin.py:104} INFO - [2021-04-25 09:44:47,996] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:44:48,108] {logging_mixin.py:104} INFO - [2021-04-25 09:44:48,108] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:44:48,191] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.435 seconds
[2021-04-25 09:45:18,369] {scheduler_job.py:182} INFO - Started process (PID=67) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:45:18,372] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:45:18,374] {logging_mixin.py:104} INFO - [2021-04-25 09:45:18,374] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:45:19,224] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:45:19,252] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:45:19,268] {logging_mixin.py:104} INFO - [2021-04-25 09:45:19,267] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:45:19,283] {logging_mixin.py:104} INFO - [2021-04-25 09:45:19,283] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:45:19,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.928 seconds
[2021-04-25 09:45:49,424] {scheduler_job.py:182} INFO - Started process (PID=69) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:45:49,430] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:45:49,436] {logging_mixin.py:104} INFO - [2021-04-25 09:45:49,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:45:50,853] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:45:50,886] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:45:50,898] {logging_mixin.py:104} INFO - [2021-04-25 09:45:50,897] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:45:50,915] {logging_mixin.py:104} INFO - [2021-04-25 09:45:50,915] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:45:50,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.505 seconds
[2021-04-25 09:46:20,964] {scheduler_job.py:182} INFO - Started process (PID=71) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:46:20,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:46:20,967] {logging_mixin.py:104} INFO - [2021-04-25 09:46:20,967] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:46:21,824] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:46:21,862] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:46:21,882] {logging_mixin.py:104} INFO - [2021-04-25 09:46:21,879] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:46:21,902] {logging_mixin.py:104} INFO - [2021-04-25 09:46:21,902] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:46:21,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.952 seconds
[2021-04-25 09:46:52,010] {scheduler_job.py:182} INFO - Started process (PID=73) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:46:52,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:46:52,015] {logging_mixin.py:104} INFO - [2021-04-25 09:46:52,015] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:46:52,734] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:46:52,769] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:46:52,785] {logging_mixin.py:104} INFO - [2021-04-25 09:46:52,783] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:46:52,802] {logging_mixin.py:104} INFO - [2021-04-25 09:46:52,802] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:46:52,812] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.810 seconds
[2021-04-25 09:47:22,916] {scheduler_job.py:182} INFO - Started process (PID=75) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:47:22,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:47:22,920] {logging_mixin.py:104} INFO - [2021-04-25 09:47:22,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:47:23,788] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:47:23,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:47:23,903] {logging_mixin.py:104} INFO - [2021-04-25 09:47:23,901] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:47:23,933] {logging_mixin.py:104} INFO - [2021-04-25 09:47:23,933] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:47:23,942] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.032 seconds
[2021-04-25 09:47:54,237] {scheduler_job.py:182} INFO - Started process (PID=77) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:47:54,241] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:47:54,245] {logging_mixin.py:104} INFO - [2021-04-25 09:47:54,245] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:47:56,400] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:47:56,443] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:47:56,463] {logging_mixin.py:104} INFO - [2021-04-25 09:47:56,462] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:47:56,487] {logging_mixin.py:104} INFO - [2021-04-25 09:47:56,487] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:47:56,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.271 seconds
[2021-04-25 09:48:26,638] {scheduler_job.py:182} INFO - Started process (PID=79) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:48:26,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:48:26,645] {logging_mixin.py:104} INFO - [2021-04-25 09:48:26,644] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:48:27,516] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:48:27,544] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:48:27,555] {logging_mixin.py:104} INFO - [2021-04-25 09:48:27,554] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:48:27,574] {logging_mixin.py:104} INFO - [2021-04-25 09:48:27,574] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:48:27,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.951 seconds
[2021-04-25 09:48:57,718] {scheduler_job.py:182} INFO - Started process (PID=81) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:48:57,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:48:57,726] {logging_mixin.py:104} INFO - [2021-04-25 09:48:57,726] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:48:58,427] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:48:58,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:48:58,475] {logging_mixin.py:104} INFO - [2021-04-25 09:48:58,474] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:48:58,501] {logging_mixin.py:104} INFO - [2021-04-25 09:48:58,501] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:48:58,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.803 seconds
[2021-04-25 09:49:28,579] {scheduler_job.py:182} INFO - Started process (PID=83) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:49:28,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:49:28,583] {logging_mixin.py:104} INFO - [2021-04-25 09:49:28,583] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:49:29,407] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:49:29,434] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:49:29,447] {logging_mixin.py:104} INFO - [2021-04-25 09:49:29,446] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:49:29,462] {logging_mixin.py:104} INFO - [2021-04-25 09:49:29,462] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:49:29,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.910 seconds
[2021-04-25 09:49:59,619] {scheduler_job.py:182} INFO - Started process (PID=85) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:49:59,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:49:59,624] {logging_mixin.py:104} INFO - [2021-04-25 09:49:59,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:50:00,307] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:50:00,345] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:50:00,373] {logging_mixin.py:104} INFO - [2021-04-25 09:50:00,371] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:50:00,442] {logging_mixin.py:104} INFO - [2021-04-25 09:50:00,442] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:50:00,510] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.896 seconds
[2021-04-25 09:50:30,650] {scheduler_job.py:182} INFO - Started process (PID=87) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:50:30,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:50:30,654] {logging_mixin.py:104} INFO - [2021-04-25 09:50:30,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:50:31,537] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:50:31,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:50:31,624] {logging_mixin.py:104} INFO - [2021-04-25 09:50:31,622] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:50:31,645] {logging_mixin.py:104} INFO - [2021-04-25 09:50:31,645] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:50:31,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.008 seconds
[2021-04-25 09:51:01,846] {scheduler_job.py:182} INFO - Started process (PID=89) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:51:01,851] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:51:01,853] {logging_mixin.py:104} INFO - [2021-04-25 09:51:01,853] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:51:02,908] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:51:02,943] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:51:02,957] {logging_mixin.py:104} INFO - [2021-04-25 09:51:02,956] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:51:02,979] {logging_mixin.py:104} INFO - [2021-04-25 09:51:02,978] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:51:02,988] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.149 seconds
[2021-04-25 09:51:33,103] {scheduler_job.py:182} INFO - Started process (PID=91) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:51:33,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:51:33,108] {logging_mixin.py:104} INFO - [2021-04-25 09:51:33,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:51:34,073] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:51:34,115] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:51:34,129] {logging_mixin.py:104} INFO - [2021-04-25 09:51:34,128] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:51:34,147] {logging_mixin.py:104} INFO - [2021-04-25 09:51:34,147] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:51:34,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.057 seconds
[2021-04-25 09:52:04,275] {scheduler_job.py:182} INFO - Started process (PID=93) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:52:04,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:52:04,280] {logging_mixin.py:104} INFO - [2021-04-25 09:52:04,280] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:52:04,984] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:52:05,034] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:52:05,054] {logging_mixin.py:104} INFO - [2021-04-25 09:52:05,053] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:52:05,079] {logging_mixin.py:104} INFO - [2021-04-25 09:52:05,078] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:52:05,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.819 seconds
[2021-04-25 09:52:35,247] {scheduler_job.py:182} INFO - Started process (PID=95) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:52:35,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:52:35,254] {logging_mixin.py:104} INFO - [2021-04-25 09:52:35,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:52:35,934] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:52:35,977] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:52:35,998] {logging_mixin.py:104} INFO - [2021-04-25 09:52:35,996] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:52:36,019] {logging_mixin.py:104} INFO - [2021-04-25 09:52:36,019] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:52:36,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.790 seconds
[2021-04-25 09:53:06,121] {scheduler_job.py:182} INFO - Started process (PID=97) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:53:06,124] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:53:06,126] {logging_mixin.py:104} INFO - [2021-04-25 09:53:06,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:53:06,786] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:53:06,826] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:53:06,836] {logging_mixin.py:104} INFO - [2021-04-25 09:53:06,835] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:53:06,852] {logging_mixin.py:104} INFO - [2021-04-25 09:53:06,852] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:53:06,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.744 seconds
[2021-04-25 09:53:36,938] {scheduler_job.py:182} INFO - Started process (PID=99) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:53:36,944] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:53:36,946] {logging_mixin.py:104} INFO - [2021-04-25 09:53:36,946] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:53:38,427] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:53:38,483] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:53:38,509] {logging_mixin.py:104} INFO - [2021-04-25 09:53:38,506] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:53:38,561] {logging_mixin.py:104} INFO - [2021-04-25 09:53:38,561] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:53:38,578] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.651 seconds
[2021-04-25 09:54:08,683] {scheduler_job.py:182} INFO - Started process (PID=101) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:54:08,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:54:08,688] {logging_mixin.py:104} INFO - [2021-04-25 09:54:08,688] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:54:09,405] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:54:09,450] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:54:09,468] {logging_mixin.py:104} INFO - [2021-04-25 09:54:09,466] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:54:09,494] {logging_mixin.py:104} INFO - [2021-04-25 09:54:09,494] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:54:09,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.830 seconds
[2021-04-25 09:54:39,653] {scheduler_job.py:182} INFO - Started process (PID=103) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:54:39,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:54:39,671] {logging_mixin.py:104} INFO - [2021-04-25 09:54:39,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:54:40,408] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:54:40,453] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:54:40,470] {logging_mixin.py:104} INFO - [2021-04-25 09:54:40,469] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:54:40,490] {logging_mixin.py:104} INFO - [2021-04-25 09:54:40,490] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:54:40,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.852 seconds
[2021-04-25 09:55:10,609] {scheduler_job.py:182} INFO - Started process (PID=105) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:55:10,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:55:10,617] {logging_mixin.py:104} INFO - [2021-04-25 09:55:10,617] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:55:11,398] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:55:11,429] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:55:11,441] {logging_mixin.py:104} INFO - [2021-04-25 09:55:11,440] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:55:11,459] {logging_mixin.py:104} INFO - [2021-04-25 09:55:11,459] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:55:11,466] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.863 seconds
[2021-04-25 09:55:41,587] {scheduler_job.py:182} INFO - Started process (PID=107) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:55:41,589] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:55:41,591] {logging_mixin.py:104} INFO - [2021-04-25 09:55:41,590] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:55:42,234] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:55:42,271] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:55:42,285] {logging_mixin.py:104} INFO - [2021-04-25 09:55:42,284] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:55:42,303] {logging_mixin.py:104} INFO - [2021-04-25 09:55:42,302] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:55:42,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.727 seconds
[2021-04-25 09:56:12,410] {scheduler_job.py:182} INFO - Started process (PID=109) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:56:12,416] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:56:12,418] {logging_mixin.py:104} INFO - [2021-04-25 09:56:12,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:56:13,252] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:56:13,293] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:56:13,318] {logging_mixin.py:104} INFO - [2021-04-25 09:56:13,317] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:56:13,351] {logging_mixin.py:104} INFO - [2021-04-25 09:56:13,351] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:56:13,361] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.955 seconds
[2021-04-25 09:56:43,430] {scheduler_job.py:182} INFO - Started process (PID=111) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:56:43,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:56:43,436] {logging_mixin.py:104} INFO - [2021-04-25 09:56:43,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:56:44,341] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:56:44,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:56:44,384] {logging_mixin.py:104} INFO - [2021-04-25 09:56:44,383] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:56:44,403] {logging_mixin.py:104} INFO - [2021-04-25 09:56:44,403] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:56:44,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.986 seconds
[2021-04-25 09:57:14,719] {scheduler_job.py:182} INFO - Started process (PID=113) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:57:14,724] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:57:14,727] {logging_mixin.py:104} INFO - [2021-04-25 09:57:14,726] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:57:15,916] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:57:15,973] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:57:15,993] {logging_mixin.py:104} INFO - [2021-04-25 09:57:15,991] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:57:16,012] {logging_mixin.py:104} INFO - [2021-04-25 09:57:16,012] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:57:16,022] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.313 seconds
[2021-04-25 09:57:46,164] {scheduler_job.py:182} INFO - Started process (PID=115) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:57:46,166] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:57:46,172] {logging_mixin.py:104} INFO - [2021-04-25 09:57:46,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:57:46,949] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:57:46,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:57:46,991] {logging_mixin.py:104} INFO - [2021-04-25 09:57:46,990] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:57:47,007] {logging_mixin.py:104} INFO - [2021-04-25 09:57:47,007] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:57:47,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.855 seconds
[2021-04-25 09:58:17,146] {scheduler_job.py:182} INFO - Started process (PID=117) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:58:17,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:58:17,151] {logging_mixin.py:104} INFO - [2021-04-25 09:58:17,151] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:58:17,781] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:58:17,827] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:58:17,847] {logging_mixin.py:104} INFO - [2021-04-25 09:58:17,845] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:58:17,882] {logging_mixin.py:104} INFO - [2021-04-25 09:58:17,882] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:58:17,893] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.753 seconds
[2021-04-25 09:58:48,044] {scheduler_job.py:182} INFO - Started process (PID=119) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:58:48,047] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:58:48,049] {logging_mixin.py:104} INFO - [2021-04-25 09:58:48,049] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:58:48,982] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:58:49,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:58:49,044] {logging_mixin.py:104} INFO - [2021-04-25 09:58:49,042] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:58:49,070] {logging_mixin.py:104} INFO - [2021-04-25 09:58:49,070] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:58:49,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.042 seconds
[2021-04-25 09:59:19,204] {scheduler_job.py:182} INFO - Started process (PID=121) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:59:19,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:59:19,219] {logging_mixin.py:104} INFO - [2021-04-25 09:59:19,218] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:59:20,331] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:59:20,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:59:20,396] {logging_mixin.py:104} INFO - [2021-04-25 09:59:20,395] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:59:20,417] {logging_mixin.py:104} INFO - [2021-04-25 09:59:20,417] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:59:20,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.231 seconds
[2021-04-25 09:59:50,645] {scheduler_job.py:182} INFO - Started process (PID=123) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:59:50,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 09:59:50,650] {logging_mixin.py:104} INFO - [2021-04-25 09:59:50,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:59:51,569] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 09:59:51,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 09:59:51,628] {logging_mixin.py:104} INFO - [2021-04-25 09:59:51,627] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 09:59:51,645] {logging_mixin.py:104} INFO - [2021-04-25 09:59:51,645] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 09:59:51,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.022 seconds
[2021-04-25 10:00:21,757] {scheduler_job.py:182} INFO - Started process (PID=125) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:00:21,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:00:21,761] {logging_mixin.py:104} INFO - [2021-04-25 10:00:21,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:00:22,542] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:00:22,582] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:00:22,597] {logging_mixin.py:104} INFO - [2021-04-25 10:00:22,596] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:00:22,622] {logging_mixin.py:104} INFO - [2021-04-25 10:00:22,622] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:00:22,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.881 seconds
[2021-04-25 10:00:52,775] {scheduler_job.py:182} INFO - Started process (PID=127) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:00:52,784] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:00:52,793] {logging_mixin.py:104} INFO - [2021-04-25 10:00:52,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:00:53,833] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:00:53,879] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:00:53,896] {logging_mixin.py:104} INFO - [2021-04-25 10:00:53,895] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:00:53,921] {logging_mixin.py:104} INFO - [2021-04-25 10:00:53,921] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:00:53,932] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.167 seconds
[2021-04-25 10:01:24,091] {scheduler_job.py:182} INFO - Started process (PID=129) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:01:24,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:01:24,094] {logging_mixin.py:104} INFO - [2021-04-25 10:01:24,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:01:24,899] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:01:24,931] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:01:24,943] {logging_mixin.py:104} INFO - [2021-04-25 10:01:24,942] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:01:24,960] {logging_mixin.py:104} INFO - [2021-04-25 10:01:24,960] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:01:24,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.884 seconds
[2021-04-25 10:01:55,118] {scheduler_job.py:182} INFO - Started process (PID=131) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:01:55,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:01:55,124] {logging_mixin.py:104} INFO - [2021-04-25 10:01:55,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:01:56,606] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:01:56,674] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:01:56,706] {logging_mixin.py:104} INFO - [2021-04-25 10:01:56,703] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:01:56,750] {logging_mixin.py:104} INFO - [2021-04-25 10:01:56,750] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:01:56,762] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.650 seconds
[2021-04-25 10:02:26,902] {scheduler_job.py:182} INFO - Started process (PID=133) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:02:26,905] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:02:26,908] {logging_mixin.py:104} INFO - [2021-04-25 10:02:26,907] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:02:27,957] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:02:28,132] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:02:28,173] {logging_mixin.py:104} INFO - [2021-04-25 10:02:28,167] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:02:28,212] {logging_mixin.py:104} INFO - [2021-04-25 10:02:28,212] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:02:28,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.329 seconds
[2021-04-25 10:02:58,301] {scheduler_job.py:182} INFO - Started process (PID=135) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:02:58,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:02:58,307] {logging_mixin.py:104} INFO - [2021-04-25 10:02:58,306] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:02:59,104] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:02:59,144] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:02:59,167] {logging_mixin.py:104} INFO - [2021-04-25 10:02:59,165] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:02:59,197] {logging_mixin.py:104} INFO - [2021-04-25 10:02:59,197] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:02:59,206] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.909 seconds
[2021-04-25 10:03:29,290] {scheduler_job.py:182} INFO - Started process (PID=137) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:03:29,293] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:03:29,294] {logging_mixin.py:104} INFO - [2021-04-25 10:03:29,294] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:03:30,240] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:03:30,271] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:03:30,286] {logging_mixin.py:104} INFO - [2021-04-25 10:03:30,285] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:03:30,303] {logging_mixin.py:104} INFO - [2021-04-25 10:03:30,303] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:03:30,312] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.027 seconds
[2021-04-25 10:04:00,423] {scheduler_job.py:182} INFO - Started process (PID=139) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:04:00,425] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:04:00,426] {logging_mixin.py:104} INFO - [2021-04-25 10:04:00,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:04:01,095] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:04:01,124] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:04:01,138] {logging_mixin.py:104} INFO - [2021-04-25 10:04:01,137] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:04:01,156] {logging_mixin.py:104} INFO - [2021-04-25 10:04:01,155] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:04:01,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.749 seconds
[2021-04-25 10:04:31,297] {scheduler_job.py:182} INFO - Started process (PID=141) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:04:31,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:04:31,307] {logging_mixin.py:104} INFO - [2021-04-25 10:04:31,306] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:04:31,963] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:04:31,991] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:04:32,003] {logging_mixin.py:104} INFO - [2021-04-25 10:04:32,002] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:04:32,018] {logging_mixin.py:104} INFO - [2021-04-25 10:04:32,018] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:04:32,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.732 seconds
[2021-04-25 10:05:02,149] {scheduler_job.py:182} INFO - Started process (PID=143) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:05:02,151] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:05:02,152] {logging_mixin.py:104} INFO - [2021-04-25 10:05:02,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:05:02,783] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:05:02,811] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:05:02,833] {logging_mixin.py:104} INFO - [2021-04-25 10:05:02,832] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:05:02,848] {logging_mixin.py:104} INFO - [2021-04-25 10:05:02,847] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:05:02,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.709 seconds
[2021-04-25 10:05:32,954] {scheduler_job.py:182} INFO - Started process (PID=145) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:05:32,958] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:05:32,960] {logging_mixin.py:104} INFO - [2021-04-25 10:05:32,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:05:33,735] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:05:33,772] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:05:33,789] {logging_mixin.py:104} INFO - [2021-04-25 10:05:33,788] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:05:33,811] {logging_mixin.py:104} INFO - [2021-04-25 10:05:33,811] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:05:33,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.870 seconds
[2021-04-25 10:06:03,912] {scheduler_job.py:182} INFO - Started process (PID=147) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:06:03,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:06:03,916] {logging_mixin.py:104} INFO - [2021-04-25 10:06:03,915] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:06:04,693] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:06:04,737] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:06:04,753] {logging_mixin.py:104} INFO - [2021-04-25 10:06:04,752] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:06:04,785] {logging_mixin.py:104} INFO - [2021-04-25 10:06:04,784] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:06:04,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.917 seconds
[2021-04-25 10:06:35,033] {scheduler_job.py:182} INFO - Started process (PID=149) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:06:35,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:06:35,039] {logging_mixin.py:104} INFO - [2021-04-25 10:06:35,039] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:06:35,814] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:06:35,841] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:06:35,851] {logging_mixin.py:104} INFO - [2021-04-25 10:06:35,851] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:06:35,868] {logging_mixin.py:104} INFO - [2021-04-25 10:06:35,868] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:06:35,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.846 seconds
[2021-04-25 10:07:05,959] {scheduler_job.py:182} INFO - Started process (PID=151) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:07:05,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:07:05,964] {logging_mixin.py:104} INFO - [2021-04-25 10:07:05,964] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:07:06,716] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:07:06,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:07:06,763] {logging_mixin.py:104} INFO - [2021-04-25 10:07:06,762] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:07:06,786] {logging_mixin.py:104} INFO - [2021-04-25 10:07:06,786] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:07:06,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.840 seconds
[2021-04-25 10:07:36,899] {scheduler_job.py:182} INFO - Started process (PID=153) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:07:36,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:07:36,904] {logging_mixin.py:104} INFO - [2021-04-25 10:07:36,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:07:37,522] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:07:37,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:07:37,573] {logging_mixin.py:104} INFO - [2021-04-25 10:07:37,573] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:07:37,594] {logging_mixin.py:104} INFO - [2021-04-25 10:07:37,594] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:07:37,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-25 10:08:07,730] {scheduler_job.py:182} INFO - Started process (PID=155) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:08:07,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:08:07,734] {logging_mixin.py:104} INFO - [2021-04-25 10:08:07,734] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:08:08,431] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:08:08,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:08:08,474] {logging_mixin.py:104} INFO - [2021-04-25 10:08:08,473] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:08:08,490] {logging_mixin.py:104} INFO - [2021-04-25 10:08:08,490] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:08:08,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.772 seconds
[2021-04-25 10:08:38,632] {scheduler_job.py:182} INFO - Started process (PID=157) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:08:38,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:08:38,638] {logging_mixin.py:104} INFO - [2021-04-25 10:08:38,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:08:40,095] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:08:40,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:08:40,208] {logging_mixin.py:104} INFO - [2021-04-25 10:08:40,203] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:08:40,244] {logging_mixin.py:104} INFO - [2021-04-25 10:08:40,244] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:08:40,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.642 seconds
[2021-04-25 10:09:10,571] {scheduler_job.py:182} INFO - Started process (PID=159) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:09:10,574] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:09:10,575] {logging_mixin.py:104} INFO - [2021-04-25 10:09:10,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:09:11,233] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:09:11,262] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:09:11,274] {logging_mixin.py:104} INFO - [2021-04-25 10:09:11,273] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:09:11,295] {logging_mixin.py:104} INFO - [2021-04-25 10:09:11,295] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:09:11,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-25 10:09:41,430] {scheduler_job.py:182} INFO - Started process (PID=161) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:09:41,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:09:41,439] {logging_mixin.py:104} INFO - [2021-04-25 10:09:41,438] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:09:42,152] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:09:42,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:09:42,221] {logging_mixin.py:104} INFO - [2021-04-25 10:09:42,219] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:09:42,248] {logging_mixin.py:104} INFO - [2021-04-25 10:09:42,248] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:09:42,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.838 seconds
[2021-04-25 10:10:12,456] {scheduler_job.py:182} INFO - Started process (PID=163) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:10:12,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:10:12,460] {logging_mixin.py:104} INFO - [2021-04-25 10:10:12,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:10:13,199] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:10:13,224] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:10:13,238] {logging_mixin.py:104} INFO - [2021-04-25 10:10:13,237] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:10:13,255] {logging_mixin.py:104} INFO - [2021-04-25 10:10:13,255] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:10:13,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.817 seconds
[2021-04-25 10:10:43,386] {scheduler_job.py:182} INFO - Started process (PID=165) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:10:43,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:10:43,391] {logging_mixin.py:104} INFO - [2021-04-25 10:10:43,391] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:10:44,060] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:10:44,087] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:10:44,099] {logging_mixin.py:104} INFO - [2021-04-25 10:10:44,098] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:10:44,115] {logging_mixin.py:104} INFO - [2021-04-25 10:10:44,115] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:10:44,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-25 10:11:14,290] {scheduler_job.py:182} INFO - Started process (PID=167) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:11:14,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:11:14,305] {logging_mixin.py:104} INFO - [2021-04-25 10:11:14,305] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:11:15,119] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:11:15,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:11:15,180] {logging_mixin.py:104} INFO - [2021-04-25 10:11:15,179] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:11:15,202] {logging_mixin.py:104} INFO - [2021-04-25 10:11:15,202] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:11:15,216] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.933 seconds
[2021-04-25 10:11:45,494] {scheduler_job.py:182} INFO - Started process (PID=169) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:11:45,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:11:45,498] {logging_mixin.py:104} INFO - [2021-04-25 10:11:45,498] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:11:46,275] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:11:46,341] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:11:46,366] {logging_mixin.py:104} INFO - [2021-04-25 10:11:46,364] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:11:46,528] {logging_mixin.py:104} INFO - [2021-04-25 10:11:46,527] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:11:46,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.094 seconds
[2021-04-25 10:12:16,676] {scheduler_job.py:182} INFO - Started process (PID=172) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:12:16,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:12:16,681] {logging_mixin.py:104} INFO - [2021-04-25 10:12:16,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:12:17,407] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:12:17,442] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:12:17,459] {logging_mixin.py:104} INFO - [2021-04-25 10:12:17,458] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:12:17,490] {logging_mixin.py:104} INFO - [2021-04-25 10:12:17,490] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:12:17,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.828 seconds
[2021-04-25 10:12:47,585] {scheduler_job.py:182} INFO - Started process (PID=173) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:12:47,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:12:47,595] {logging_mixin.py:104} INFO - [2021-04-25 10:12:47,594] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:12:48,377] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:12:48,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:12:48,444] {logging_mixin.py:104} INFO - [2021-04-25 10:12:48,443] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:12:48,474] {logging_mixin.py:104} INFO - [2021-04-25 10:12:48,474] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:12:48,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.908 seconds
[2021-04-25 10:13:18,587] {scheduler_job.py:182} INFO - Started process (PID=175) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:13:18,591] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:13:18,594] {logging_mixin.py:104} INFO - [2021-04-25 10:13:18,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:13:19,255] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:13:19,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:13:19,294] {logging_mixin.py:104} INFO - [2021-04-25 10:13:19,293] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:13:19,310] {logging_mixin.py:104} INFO - [2021-04-25 10:13:19,310] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:13:19,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.739 seconds
[2021-04-25 10:13:49,582] {scheduler_job.py:182} INFO - Started process (PID=177) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:13:49,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:13:49,605] {logging_mixin.py:104} INFO - [2021-04-25 10:13:49,604] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:13:50,844] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:13:50,896] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:13:50,923] {logging_mixin.py:104} INFO - [2021-04-25 10:13:50,921] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:13:50,963] {logging_mixin.py:104} INFO - [2021-04-25 10:13:50,963] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:13:50,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.410 seconds
[2021-04-25 10:14:21,166] {scheduler_job.py:182} INFO - Started process (PID=179) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:14:21,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:14:21,171] {logging_mixin.py:104} INFO - [2021-04-25 10:14:21,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:14:21,959] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:14:22,000] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:14:22,023] {logging_mixin.py:104} INFO - [2021-04-25 10:14:22,020] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:14:22,059] {logging_mixin.py:104} INFO - [2021-04-25 10:14:22,058] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:14:22,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.910 seconds
[2021-04-25 10:14:52,199] {scheduler_job.py:182} INFO - Started process (PID=181) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:14:52,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:14:52,204] {logging_mixin.py:104} INFO - [2021-04-25 10:14:52,204] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:14:52,863] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:14:52,892] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:14:52,901] {logging_mixin.py:104} INFO - [2021-04-25 10:14:52,901] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:14:52,918] {logging_mixin.py:104} INFO - [2021-04-25 10:14:52,917] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:14:52,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.730 seconds
[2021-04-25 10:15:23,102] {scheduler_job.py:182} INFO - Started process (PID=183) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:15:23,105] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:15:23,107] {logging_mixin.py:104} INFO - [2021-04-25 10:15:23,107] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:15:23,973] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:15:24,022] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:15:24,037] {logging_mixin.py:104} INFO - [2021-04-25 10:15:24,036] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:15:24,057] {logging_mixin.py:104} INFO - [2021-04-25 10:15:24,056] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:15:24,066] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.969 seconds
[2021-04-25 10:15:54,247] {scheduler_job.py:182} INFO - Started process (PID=185) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:15:54,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:15:54,251] {logging_mixin.py:104} INFO - [2021-04-25 10:15:54,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:15:54,894] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:15:54,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:15:54,933] {logging_mixin.py:104} INFO - [2021-04-25 10:15:54,933] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:15:54,950] {logging_mixin.py:104} INFO - [2021-04-25 10:15:54,950] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:15:54,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.717 seconds
[2021-04-25 10:16:25,095] {scheduler_job.py:182} INFO - Started process (PID=187) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:16:25,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:16:25,100] {logging_mixin.py:104} INFO - [2021-04-25 10:16:25,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:16:26,077] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:16:26,130] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:16:26,153] {logging_mixin.py:104} INFO - [2021-04-25 10:16:26,150] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:16:26,186] {logging_mixin.py:104} INFO - [2021-04-25 10:16:26,186] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:16:26,198] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.111 seconds
[2021-04-25 10:16:56,297] {scheduler_job.py:182} INFO - Started process (PID=190) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:16:56,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:16:56,303] {logging_mixin.py:104} INFO - [2021-04-25 10:16:56,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:16:57,069] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:16:57,099] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:16:57,112] {logging_mixin.py:104} INFO - [2021-04-25 10:16:57,110] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:16:57,134] {logging_mixin.py:104} INFO - [2021-04-25 10:16:57,133] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:16:57,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.851 seconds
[2021-04-25 10:17:27,262] {scheduler_job.py:182} INFO - Started process (PID=192) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:17:27,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:17:27,267] {logging_mixin.py:104} INFO - [2021-04-25 10:17:27,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:17:28,023] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:17:28,057] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:17:28,073] {logging_mixin.py:104} INFO - [2021-04-25 10:17:28,071] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:17:28,095] {logging_mixin.py:104} INFO - [2021-04-25 10:17:28,095] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:17:28,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.845 seconds
[2021-04-25 10:17:58,147] {scheduler_job.py:182} INFO - Started process (PID=193) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:17:58,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:17:58,155] {logging_mixin.py:104} INFO - [2021-04-25 10:17:58,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:17:59,049] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:17:59,087] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:17:59,107] {logging_mixin.py:104} INFO - [2021-04-25 10:17:59,105] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:17:59,158] {logging_mixin.py:104} INFO - [2021-04-25 10:17:59,158] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:17:59,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.029 seconds
[2021-04-25 10:18:29,351] {scheduler_job.py:182} INFO - Started process (PID=195) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:18:29,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:18:29,356] {logging_mixin.py:104} INFO - [2021-04-25 10:18:29,356] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:18:30,247] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:18:30,284] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:18:30,305] {logging_mixin.py:104} INFO - [2021-04-25 10:18:30,303] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:18:30,329] {logging_mixin.py:104} INFO - [2021-04-25 10:18:30,329] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:18:30,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.007 seconds
[2021-04-25 10:19:00,474] {scheduler_job.py:182} INFO - Started process (PID=197) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:19:00,477] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:19:00,478] {logging_mixin.py:104} INFO - [2021-04-25 10:19:00,478] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:19:01,099] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:19:01,124] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:19:01,138] {logging_mixin.py:104} INFO - [2021-04-25 10:19:01,137] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:19:01,155] {logging_mixin.py:104} INFO - [2021-04-25 10:19:01,155] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:19:01,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.693 seconds
[2021-04-25 10:19:31,316] {scheduler_job.py:182} INFO - Started process (PID=199) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:19:31,320] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:19:31,322] {logging_mixin.py:104} INFO - [2021-04-25 10:19:31,322] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:19:32,308] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:19:32,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:19:32,355] {logging_mixin.py:104} INFO - [2021-04-25 10:19:32,354] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:19:32,376] {logging_mixin.py:104} INFO - [2021-04-25 10:19:32,376] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:19:32,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.079 seconds
[2021-04-25 10:20:02,525] {scheduler_job.py:182} INFO - Started process (PID=201) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:20:02,529] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:20:02,531] {logging_mixin.py:104} INFO - [2021-04-25 10:20:02,531] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:20:03,435] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:20:03,531] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:20:03,562] {logging_mixin.py:104} INFO - [2021-04-25 10:20:03,560] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:20:03,605] {logging_mixin.py:104} INFO - [2021-04-25 10:20:03,605] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:20:03,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.096 seconds
[2021-04-25 10:20:33,790] {scheduler_job.py:182} INFO - Started process (PID=203) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:20:33,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:20:33,794] {logging_mixin.py:104} INFO - [2021-04-25 10:20:33,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:20:34,860] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:20:35,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:20:35,077] {logging_mixin.py:104} INFO - [2021-04-25 10:20:35,066] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:20:35,335] {logging_mixin.py:104} INFO - [2021-04-25 10:20:35,335] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:20:35,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.608 seconds
[2021-04-25 10:21:05,533] {scheduler_job.py:182} INFO - Started process (PID=205) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:21:05,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:21:05,539] {logging_mixin.py:104} INFO - [2021-04-25 10:21:05,539] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:21:06,844] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:21:06,889] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:21:06,914] {logging_mixin.py:104} INFO - [2021-04-25 10:21:06,913] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:21:06,946] {logging_mixin.py:104} INFO - [2021-04-25 10:21:06,946] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:21:06,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.438 seconds
[2021-04-25 10:21:37,354] {scheduler_job.py:182} INFO - Started process (PID=207) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:21:37,356] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:21:37,357] {logging_mixin.py:104} INFO - [2021-04-25 10:21:37,357] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:21:38,648] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:21:38,679] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:21:38,709] {logging_mixin.py:104} INFO - [2021-04-25 10:21:38,707] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:21:38,757] {logging_mixin.py:104} INFO - [2021-04-25 10:21:38,757] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:21:38,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.472 seconds
[2021-04-25 10:22:08,896] {scheduler_job.py:182} INFO - Started process (PID=210) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:22:08,899] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:22:08,901] {logging_mixin.py:104} INFO - [2021-04-25 10:22:08,901] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:22:09,734] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:22:09,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:22:09,780] {logging_mixin.py:104} INFO - [2021-04-25 10:22:09,780] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:22:09,800] {logging_mixin.py:104} INFO - [2021-04-25 10:22:09,800] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:22:09,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.916 seconds
[2021-04-25 10:22:39,868] {scheduler_job.py:182} INFO - Started process (PID=212) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:22:39,870] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:22:39,872] {logging_mixin.py:104} INFO - [2021-04-25 10:22:39,872] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:22:40,654] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:22:40,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:22:40,705] {logging_mixin.py:104} INFO - [2021-04-25 10:22:40,704] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:22:40,753] {logging_mixin.py:104} INFO - [2021-04-25 10:22:40,753] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:22:40,768] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.904 seconds
[2021-04-25 10:23:11,099] {scheduler_job.py:182} INFO - Started process (PID=213) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:23:11,103] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:23:11,106] {logging_mixin.py:104} INFO - [2021-04-25 10:23:11,106] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:23:12,267] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:23:12,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:23:12,332] {logging_mixin.py:104} INFO - [2021-04-25 10:23:12,330] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:23:12,363] {logging_mixin.py:104} INFO - [2021-04-25 10:23:12,363] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:23:12,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.287 seconds
[2021-04-25 10:23:42,448] {scheduler_job.py:182} INFO - Started process (PID=215) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:23:42,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:23:42,451] {logging_mixin.py:104} INFO - [2021-04-25 10:23:42,451] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:23:43,270] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:23:43,305] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:23:43,317] {logging_mixin.py:104} INFO - [2021-04-25 10:23:43,316] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:23:43,340] {logging_mixin.py:104} INFO - [2021-04-25 10:23:43,339] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:23:43,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.909 seconds
[2021-04-25 10:24:13,556] {scheduler_job.py:182} INFO - Started process (PID=217) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:24:13,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:24:13,560] {logging_mixin.py:104} INFO - [2021-04-25 10:24:13,560] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:24:14,290] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:24:14,315] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:24:14,326] {logging_mixin.py:104} INFO - [2021-04-25 10:24:14,325] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:24:14,341] {logging_mixin.py:104} INFO - [2021-04-25 10:24:14,341] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:24:14,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.798 seconds
[2021-04-25 10:24:44,497] {scheduler_job.py:182} INFO - Started process (PID=219) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:24:44,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:24:44,501] {logging_mixin.py:104} INFO - [2021-04-25 10:24:44,501] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:24:45,420] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:24:45,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:24:45,484] {logging_mixin.py:104} INFO - [2021-04-25 10:24:45,481] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:24:45,546] {logging_mixin.py:104} INFO - [2021-04-25 10:24:45,546] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:24:45,574] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.084 seconds
[2021-04-25 10:25:15,705] {scheduler_job.py:182} INFO - Started process (PID=221) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:25:15,708] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:25:15,710] {logging_mixin.py:104} INFO - [2021-04-25 10:25:15,709] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:25:16,387] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:25:16,418] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:25:16,428] {logging_mixin.py:104} INFO - [2021-04-25 10:25:16,427] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:25:16,445] {logging_mixin.py:104} INFO - [2021-04-25 10:25:16,445] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:25:16,455] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.760 seconds
[2021-04-25 10:25:46,641] {scheduler_job.py:182} INFO - Started process (PID=223) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:25:46,645] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:25:46,647] {logging_mixin.py:104} INFO - [2021-04-25 10:25:46,647] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:25:47,326] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:25:47,355] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:25:47,366] {logging_mixin.py:104} INFO - [2021-04-25 10:25:47,365] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:25:47,387] {logging_mixin.py:104} INFO - [2021-04-25 10:25:47,387] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:25:47,398] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.764 seconds
[2021-04-25 10:26:17,665] {scheduler_job.py:182} INFO - Started process (PID=225) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:26:17,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:26:17,676] {logging_mixin.py:104} INFO - [2021-04-25 10:26:17,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:26:18,734] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:26:18,764] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:26:18,779] {logging_mixin.py:104} INFO - [2021-04-25 10:26:18,777] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:26:18,797] {logging_mixin.py:104} INFO - [2021-04-25 10:26:18,797] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:26:18,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.153 seconds
[2021-04-25 10:26:48,946] {scheduler_job.py:182} INFO - Started process (PID=227) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:26:48,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:26:48,951] {logging_mixin.py:104} INFO - [2021-04-25 10:26:48,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:26:49,630] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:26:49,660] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:26:49,673] {logging_mixin.py:104} INFO - [2021-04-25 10:26:49,672] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:26:49,689] {logging_mixin.py:104} INFO - [2021-04-25 10:26:49,689] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:26:49,697] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.758 seconds
[2021-04-25 10:27:19,822] {scheduler_job.py:182} INFO - Started process (PID=229) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:27:19,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:27:19,826] {logging_mixin.py:104} INFO - [2021-04-25 10:27:19,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:27:20,448] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:27:20,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:27:20,488] {logging_mixin.py:104} INFO - [2021-04-25 10:27:20,487] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:27:20,506] {logging_mixin.py:104} INFO - [2021-04-25 10:27:20,506] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:27:20,513] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.698 seconds
[2021-04-25 10:27:50,620] {scheduler_job.py:182} INFO - Started process (PID=231) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:27:50,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:27:50,623] {logging_mixin.py:104} INFO - [2021-04-25 10:27:50,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:27:51,321] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:27:51,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:27:51,371] {logging_mixin.py:104} INFO - [2021-04-25 10:27:51,369] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:27:51,388] {logging_mixin.py:104} INFO - [2021-04-25 10:27:51,388] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:27:51,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.795 seconds
[2021-04-25 10:28:21,510] {scheduler_job.py:182} INFO - Started process (PID=233) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:28:21,513] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:28:21,515] {logging_mixin.py:104} INFO - [2021-04-25 10:28:21,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:28:22,404] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:28:22,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:28:22,505] {logging_mixin.py:104} INFO - [2021-04-25 10:28:22,501] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:28:22,554] {logging_mixin.py:104} INFO - [2021-04-25 10:28:22,554] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:28:22,568] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.065 seconds
[2021-04-25 10:28:52,716] {scheduler_job.py:182} INFO - Started process (PID=235) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:28:52,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:28:52,727] {logging_mixin.py:104} INFO - [2021-04-25 10:28:52,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:28:53,477] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:28:53,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:28:53,523] {logging_mixin.py:104} INFO - [2021-04-25 10:28:53,522] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:28:53,552] {logging_mixin.py:104} INFO - [2021-04-25 10:28:53,552] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:28:53,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.863 seconds
[2021-04-25 10:29:23,670] {scheduler_job.py:182} INFO - Started process (PID=237) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:29:23,672] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:29:23,673] {logging_mixin.py:104} INFO - [2021-04-25 10:29:23,673] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:29:24,340] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:29:24,379] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:29:24,394] {logging_mixin.py:104} INFO - [2021-04-25 10:29:24,392] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:29:24,415] {logging_mixin.py:104} INFO - [2021-04-25 10:29:24,415] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:29:24,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.760 seconds
[2021-04-25 10:29:54,553] {scheduler_job.py:182} INFO - Started process (PID=239) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:29:54,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:29:54,558] {logging_mixin.py:104} INFO - [2021-04-25 10:29:54,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:29:55,215] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:29:55,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:29:55,260] {logging_mixin.py:104} INFO - [2021-04-25 10:29:55,259] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:29:55,277] {logging_mixin.py:104} INFO - [2021-04-25 10:29:55,277] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:29:55,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.738 seconds
[2021-04-25 10:30:25,394] {scheduler_job.py:182} INFO - Started process (PID=241) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:30:25,397] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:30:25,401] {logging_mixin.py:104} INFO - [2021-04-25 10:30:25,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:30:26,427] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:30:26,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:30:26,506] {logging_mixin.py:104} INFO - [2021-04-25 10:30:26,505] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:30:26,534] {logging_mixin.py:104} INFO - [2021-04-25 10:30:26,534] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:30:26,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.164 seconds
[2021-04-25 10:30:56,682] {scheduler_job.py:182} INFO - Started process (PID=243) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:30:56,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:30:56,686] {logging_mixin.py:104} INFO - [2021-04-25 10:30:56,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:30:57,481] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:30:57,508] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:30:57,522] {logging_mixin.py:104} INFO - [2021-04-25 10:30:57,521] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:30:57,539] {logging_mixin.py:104} INFO - [2021-04-25 10:30:57,538] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:30:57,549] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.871 seconds
[2021-04-25 10:31:27,826] {scheduler_job.py:182} INFO - Started process (PID=245) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:31:27,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:31:27,833] {logging_mixin.py:104} INFO - [2021-04-25 10:31:27,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:31:28,735] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:31:28,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:31:28,779] {logging_mixin.py:104} INFO - [2021-04-25 10:31:28,778] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:31:28,798] {logging_mixin.py:104} INFO - [2021-04-25 10:31:28,798] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:31:28,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.987 seconds
[2021-04-25 10:31:58,987] {scheduler_job.py:182} INFO - Started process (PID=247) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:31:58,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:31:58,991] {logging_mixin.py:104} INFO - [2021-04-25 10:31:58,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:31:59,586] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:31:59,626] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:31:59,638] {logging_mixin.py:104} INFO - [2021-04-25 10:31:59,637] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:31:59,653] {logging_mixin.py:104} INFO - [2021-04-25 10:31:59,653] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:31:59,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.683 seconds
[2021-04-25 10:32:29,787] {scheduler_job.py:182} INFO - Started process (PID=249) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:32:29,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:32:29,799] {logging_mixin.py:104} INFO - [2021-04-25 10:32:29,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:32:30,656] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:32:30,729] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:32:30,772] {logging_mixin.py:104} INFO - [2021-04-25 10:32:30,769] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:32:30,804] {logging_mixin.py:104} INFO - [2021-04-25 10:32:30,804] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:32:30,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.039 seconds
[2021-04-25 10:33:00,935] {scheduler_job.py:182} INFO - Started process (PID=251) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:33:00,939] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:33:00,944] {logging_mixin.py:104} INFO - [2021-04-25 10:33:00,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:33:01,575] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:33:01,600] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:33:01,613] {logging_mixin.py:104} INFO - [2021-04-25 10:33:01,612] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:33:01,627] {logging_mixin.py:104} INFO - [2021-04-25 10:33:01,627] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:33:01,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.702 seconds
[2021-04-25 10:33:31,755] {scheduler_job.py:182} INFO - Started process (PID=253) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:33:31,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:33:31,762] {logging_mixin.py:104} INFO - [2021-04-25 10:33:31,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:33:32,426] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:33:32,454] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:33:32,469] {logging_mixin.py:104} INFO - [2021-04-25 10:33:32,468] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:33:32,492] {logging_mixin.py:104} INFO - [2021-04-25 10:33:32,491] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:33:32,498] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.749 seconds
[2021-04-25 10:34:03,143] {scheduler_job.py:182} INFO - Started process (PID=255) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:34:03,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:34:03,148] {logging_mixin.py:104} INFO - [2021-04-25 10:34:03,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:34:04,039] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:34:04,085] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:34:04,109] {logging_mixin.py:104} INFO - [2021-04-25 10:34:04,107] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:34:04,134] {logging_mixin.py:104} INFO - [2021-04-25 10:34:04,134] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:34:04,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.028 seconds
[2021-04-25 10:34:34,286] {scheduler_job.py:182} INFO - Started process (PID=257) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:34:34,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:34:34,291] {logging_mixin.py:104} INFO - [2021-04-25 10:34:34,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:34:35,095] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:34:35,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:34:35,140] {logging_mixin.py:104} INFO - [2021-04-25 10:34:35,139] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:34:35,162] {logging_mixin.py:104} INFO - [2021-04-25 10:34:35,162] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:34:35,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.889 seconds
[2021-04-25 10:35:05,308] {scheduler_job.py:182} INFO - Started process (PID=259) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:35:05,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:35:05,312] {logging_mixin.py:104} INFO - [2021-04-25 10:35:05,312] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:35:06,352] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:35:06,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:35:06,415] {logging_mixin.py:104} INFO - [2021-04-25 10:35:06,414] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:35:06,437] {logging_mixin.py:104} INFO - [2021-04-25 10:35:06,437] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:35:06,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.143 seconds
[2021-04-25 10:35:36,531] {scheduler_job.py:182} INFO - Started process (PID=261) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:35:36,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:35:36,542] {logging_mixin.py:104} INFO - [2021-04-25 10:35:36,542] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:35:37,434] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:35:37,462] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:35:37,473] {logging_mixin.py:104} INFO - [2021-04-25 10:35:37,472] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:35:37,491] {logging_mixin.py:104} INFO - [2021-04-25 10:35:37,491] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:35:37,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.971 seconds
[2021-04-25 10:36:07,657] {scheduler_job.py:182} INFO - Started process (PID=263) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:36:07,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:36:07,663] {logging_mixin.py:104} INFO - [2021-04-25 10:36:07,662] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:36:08,477] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:36:08,510] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:36:08,526] {logging_mixin.py:104} INFO - [2021-04-25 10:36:08,525] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:36:08,546] {logging_mixin.py:104} INFO - [2021-04-25 10:36:08,546] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:36:08,558] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.909 seconds
[2021-04-25 10:36:38,681] {scheduler_job.py:182} INFO - Started process (PID=265) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:36:38,688] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:36:38,691] {logging_mixin.py:104} INFO - [2021-04-25 10:36:38,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:36:39,479] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:36:39,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:36:39,527] {logging_mixin.py:104} INFO - [2021-04-25 10:36:39,526] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:36:39,545] {logging_mixin.py:104} INFO - [2021-04-25 10:36:39,545] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:36:39,554] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.878 seconds
[2021-04-25 10:37:09,680] {scheduler_job.py:182} INFO - Started process (PID=267) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:37:09,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:37:09,687] {logging_mixin.py:104} INFO - [2021-04-25 10:37:09,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:37:10,541] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:37:10,567] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:37:10,583] {logging_mixin.py:104} INFO - [2021-04-25 10:37:10,582] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:37:10,603] {logging_mixin.py:104} INFO - [2021-04-25 10:37:10,603] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:37:10,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.939 seconds
[2021-04-25 10:37:40,717] {scheduler_job.py:182} INFO - Started process (PID=269) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:37:40,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:37:40,724] {logging_mixin.py:104} INFO - [2021-04-25 10:37:40,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:37:41,860] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:37:41,902] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:37:41,919] {logging_mixin.py:104} INFO - [2021-04-25 10:37:41,917] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:37:41,935] {logging_mixin.py:104} INFO - [2021-04-25 10:37:41,935] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:37:41,942] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.234 seconds
[2021-04-25 10:38:11,995] {scheduler_job.py:182} INFO - Started process (PID=271) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:38:11,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:38:12,001] {logging_mixin.py:104} INFO - [2021-04-25 10:38:12,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:38:12,809] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:38:12,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:38:12,882] {logging_mixin.py:104} INFO - [2021-04-25 10:38:12,880] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:38:12,903] {logging_mixin.py:104} INFO - [2021-04-25 10:38:12,903] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:38:12,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.927 seconds
[2021-04-25 10:38:42,965] {scheduler_job.py:182} INFO - Started process (PID=273) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:38:42,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:38:42,970] {logging_mixin.py:104} INFO - [2021-04-25 10:38:42,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:38:43,789] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:38:43,834] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:38:43,850] {logging_mixin.py:104} INFO - [2021-04-25 10:38:43,849] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:38:43,874] {logging_mixin.py:104} INFO - [2021-04-25 10:38:43,874] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:38:43,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.923 seconds
[2021-04-25 10:39:14,060] {scheduler_job.py:182} INFO - Started process (PID=275) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:39:14,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:39:14,066] {logging_mixin.py:104} INFO - [2021-04-25 10:39:14,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:39:15,303] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:39:15,344] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:39:15,363] {logging_mixin.py:104} INFO - [2021-04-25 10:39:15,362] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:39:15,386] {logging_mixin.py:104} INFO - [2021-04-25 10:39:15,386] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:39:15,397] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.343 seconds
[2021-04-25 10:39:45,539] {scheduler_job.py:182} INFO - Started process (PID=277) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:39:45,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:39:45,544] {logging_mixin.py:104} INFO - [2021-04-25 10:39:45,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:39:46,422] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:39:46,460] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:39:46,478] {logging_mixin.py:104} INFO - [2021-04-25 10:39:46,476] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:39:46,499] {logging_mixin.py:104} INFO - [2021-04-25 10:39:46,499] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:39:46,508] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.976 seconds
[2021-04-25 10:40:16,640] {scheduler_job.py:182} INFO - Started process (PID=279) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:40:16,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:40:16,644] {logging_mixin.py:104} INFO - [2021-04-25 10:40:16,643] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:40:17,265] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:40:17,292] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:40:17,302] {logging_mixin.py:104} INFO - [2021-04-25 10:40:17,301] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:40:17,321] {logging_mixin.py:104} INFO - [2021-04-25 10:40:17,321] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:40:17,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.692 seconds
[2021-04-25 10:40:47,436] {scheduler_job.py:182} INFO - Started process (PID=281) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:40:47,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:40:47,444] {logging_mixin.py:104} INFO - [2021-04-25 10:40:47,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:40:48,064] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:40:48,093] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:40:48,105] {logging_mixin.py:104} INFO - [2021-04-25 10:40:48,104] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:40:48,121] {logging_mixin.py:104} INFO - [2021-04-25 10:40:48,121] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:40:48,131] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.702 seconds
[2021-04-25 10:41:18,248] {scheduler_job.py:182} INFO - Started process (PID=283) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:41:18,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:41:18,253] {logging_mixin.py:104} INFO - [2021-04-25 10:41:18,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:41:18,898] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:41:18,932] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:41:18,947] {logging_mixin.py:104} INFO - [2021-04-25 10:41:18,946] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:41:18,969] {logging_mixin.py:104} INFO - [2021-04-25 10:41:18,969] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:41:18,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.732 seconds
[2021-04-25 10:41:49,100] {scheduler_job.py:182} INFO - Started process (PID=285) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:41:49,102] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:41:49,104] {logging_mixin.py:104} INFO - [2021-04-25 10:41:49,104] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:41:49,753] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:41:49,782] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:41:49,793] {logging_mixin.py:104} INFO - [2021-04-25 10:41:49,792] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:41:49,811] {logging_mixin.py:104} INFO - [2021-04-25 10:41:49,811] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:41:49,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.726 seconds
[2021-04-25 10:42:19,954] {scheduler_job.py:182} INFO - Started process (PID=287) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:42:19,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:42:19,958] {logging_mixin.py:104} INFO - [2021-04-25 10:42:19,958] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:42:20,642] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:42:20,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:42:20,697] {logging_mixin.py:104} INFO - [2021-04-25 10:42:20,696] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:42:20,729] {logging_mixin.py:104} INFO - [2021-04-25 10:42:20,729] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:42:20,746] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.798 seconds
[2021-04-25 10:42:50,811] {scheduler_job.py:182} INFO - Started process (PID=289) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:42:50,815] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:42:50,817] {logging_mixin.py:104} INFO - [2021-04-25 10:42:50,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:42:51,650] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:42:51,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:42:51,725] {logging_mixin.py:104} INFO - [2021-04-25 10:42:51,722] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:42:51,765] {logging_mixin.py:104} INFO - [2021-04-25 10:42:51,765] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:42:51,776] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.969 seconds
[2021-04-25 10:43:21,853] {scheduler_job.py:182} INFO - Started process (PID=291) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:43:21,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:43:21,857] {logging_mixin.py:104} INFO - [2021-04-25 10:43:21,856] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:43:22,579] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:43:22,608] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:43:22,620] {logging_mixin.py:104} INFO - [2021-04-25 10:43:22,619] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:43:22,646] {logging_mixin.py:104} INFO - [2021-04-25 10:43:22,646] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:43:22,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.808 seconds
[2021-04-25 10:43:52,790] {scheduler_job.py:182} INFO - Started process (PID=293) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:43:52,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:43:52,799] {logging_mixin.py:104} INFO - [2021-04-25 10:43:52,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:43:53,591] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:43:53,634] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:43:53,651] {logging_mixin.py:104} INFO - [2021-04-25 10:43:53,650] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:43:53,672] {logging_mixin.py:104} INFO - [2021-04-25 10:43:53,672] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:43:53,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.903 seconds
[2021-04-25 10:44:23,814] {scheduler_job.py:182} INFO - Started process (PID=295) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:44:23,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:44:23,817] {logging_mixin.py:104} INFO - [2021-04-25 10:44:23,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:44:24,570] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:44:24,601] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:44:24,620] {logging_mixin.py:104} INFO - [2021-04-25 10:44:24,619] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:44:24,638] {logging_mixin.py:104} INFO - [2021-04-25 10:44:24,638] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:44:24,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.838 seconds
[2021-04-25 10:44:54,754] {scheduler_job.py:182} INFO - Started process (PID=297) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:44:54,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:44:54,758] {logging_mixin.py:104} INFO - [2021-04-25 10:44:54,758] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:44:55,406] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:44:55,436] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:44:55,449] {logging_mixin.py:104} INFO - [2021-04-25 10:44:55,448] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:44:55,475] {logging_mixin.py:104} INFO - [2021-04-25 10:44:55,475] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:44:55,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.738 seconds
[2021-04-25 10:45:25,577] {scheduler_job.py:182} INFO - Started process (PID=299) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:45:25,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:45:25,583] {logging_mixin.py:104} INFO - [2021-04-25 10:45:25,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:45:26,368] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:45:26,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:45:26,433] {logging_mixin.py:104} INFO - [2021-04-25 10:45:26,432] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:45:26,505] {logging_mixin.py:104} INFO - [2021-04-25 10:45:26,505] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:45:26,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.947 seconds
[2021-04-25 10:45:56,689] {scheduler_job.py:182} INFO - Started process (PID=301) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:45:56,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:45:56,694] {logging_mixin.py:104} INFO - [2021-04-25 10:45:56,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:45:57,289] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:45:57,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:45:57,322] {logging_mixin.py:104} INFO - [2021-04-25 10:45:57,321] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:45:57,339] {logging_mixin.py:104} INFO - [2021-04-25 10:45:57,339] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:45:57,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.668 seconds
[2021-04-25 10:46:27,469] {scheduler_job.py:182} INFO - Started process (PID=303) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:46:27,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:46:27,474] {logging_mixin.py:104} INFO - [2021-04-25 10:46:27,474] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:46:28,136] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:46:28,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:46:28,187] {logging_mixin.py:104} INFO - [2021-04-25 10:46:28,185] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:46:28,217] {logging_mixin.py:104} INFO - [2021-04-25 10:46:28,209] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:46:28,228] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.763 seconds
[2021-04-25 10:46:58,367] {scheduler_job.py:182} INFO - Started process (PID=305) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:46:58,371] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:46:58,373] {logging_mixin.py:104} INFO - [2021-04-25 10:46:58,372] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:46:59,143] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:46:59,171] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:46:59,185] {logging_mixin.py:104} INFO - [2021-04-25 10:46:59,184] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:46:59,200] {logging_mixin.py:104} INFO - [2021-04-25 10:46:59,200] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:46:59,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.845 seconds
[2021-04-25 10:47:29,287] {scheduler_job.py:182} INFO - Started process (PID=307) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:47:29,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:47:29,292] {logging_mixin.py:104} INFO - [2021-04-25 10:47:29,292] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:47:29,877] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:47:29,928] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:47:29,944] {logging_mixin.py:104} INFO - [2021-04-25 10:47:29,943] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:47:29,969] {logging_mixin.py:104} INFO - [2021-04-25 10:47:29,969] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:47:29,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.698 seconds
[2021-04-25 10:48:00,104] {scheduler_job.py:182} INFO - Started process (PID=309) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:48:00,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:48:00,108] {logging_mixin.py:104} INFO - [2021-04-25 10:48:00,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:48:00,986] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:48:01,019] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:48:01,031] {logging_mixin.py:104} INFO - [2021-04-25 10:48:01,030] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:48:01,047] {logging_mixin.py:104} INFO - [2021-04-25 10:48:01,047] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:48:01,063] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.963 seconds
[2021-04-25 10:48:31,213] {scheduler_job.py:182} INFO - Started process (PID=311) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:48:31,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:48:31,219] {logging_mixin.py:104} INFO - [2021-04-25 10:48:31,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:48:31,834] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:48:31,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:48:31,878] {logging_mixin.py:104} INFO - [2021-04-25 10:48:31,877] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:48:31,899] {logging_mixin.py:104} INFO - [2021-04-25 10:48:31,899] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:48:31,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.705 seconds
[2021-04-25 10:49:02,066] {scheduler_job.py:182} INFO - Started process (PID=313) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:49:02,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:49:02,071] {logging_mixin.py:104} INFO - [2021-04-25 10:49:02,071] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:49:02,691] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:49:02,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:49:02,733] {logging_mixin.py:104} INFO - [2021-04-25 10:49:02,732] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:49:02,748] {logging_mixin.py:104} INFO - [2021-04-25 10:49:02,748] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:49:02,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.696 seconds
[2021-04-25 10:49:32,866] {scheduler_job.py:182} INFO - Started process (PID=315) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:49:32,870] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:49:32,872] {logging_mixin.py:104} INFO - [2021-04-25 10:49:32,872] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:49:33,473] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:49:33,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:49:33,510] {logging_mixin.py:104} INFO - [2021-04-25 10:49:33,509] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:49:33,525] {logging_mixin.py:104} INFO - [2021-04-25 10:49:33,525] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:49:33,531] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.692 seconds
[2021-04-25 10:50:03,633] {scheduler_job.py:182} INFO - Started process (PID=317) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:50:03,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:50:03,636] {logging_mixin.py:104} INFO - [2021-04-25 10:50:03,636] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:50:04,252] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:50:04,278] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:50:04,289] {logging_mixin.py:104} INFO - [2021-04-25 10:50:04,289] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:50:04,304] {logging_mixin.py:104} INFO - [2021-04-25 10:50:04,304] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:50:04,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.682 seconds
[2021-04-25 10:50:34,422] {scheduler_job.py:182} INFO - Started process (PID=319) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:50:34,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:50:34,426] {logging_mixin.py:104} INFO - [2021-04-25 10:50:34,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:50:35,043] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:50:35,079] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:50:35,094] {logging_mixin.py:104} INFO - [2021-04-25 10:50:35,092] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:50:35,111] {logging_mixin.py:104} INFO - [2021-04-25 10:50:35,110] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:50:35,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.702 seconds
[2021-04-25 10:51:05,227] {scheduler_job.py:182} INFO - Started process (PID=321) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:51:05,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:51:05,231] {logging_mixin.py:104} INFO - [2021-04-25 10:51:05,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:51:05,808] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:51:05,834] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:51:05,845] {logging_mixin.py:104} INFO - [2021-04-25 10:51:05,844] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:51:05,860] {logging_mixin.py:104} INFO - [2021-04-25 10:51:05,860] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:51:05,882] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.660 seconds
[2021-04-25 10:51:36,003] {scheduler_job.py:182} INFO - Started process (PID=323) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:51:36,005] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:51:36,007] {logging_mixin.py:104} INFO - [2021-04-25 10:51:36,006] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:51:36,640] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:51:36,669] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:51:36,684] {logging_mixin.py:104} INFO - [2021-04-25 10:51:36,682] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:51:36,704] {logging_mixin.py:104} INFO - [2021-04-25 10:51:36,704] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:51:36,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.713 seconds
[2021-04-25 10:52:06,784] {scheduler_job.py:182} INFO - Started process (PID=325) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:52:06,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:52:06,788] {logging_mixin.py:104} INFO - [2021-04-25 10:52:06,788] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:52:07,410] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:52:07,441] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:52:07,453] {logging_mixin.py:104} INFO - [2021-04-25 10:52:07,452] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:52:07,470] {logging_mixin.py:104} INFO - [2021-04-25 10:52:07,470] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:52:07,486] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.707 seconds
[2021-04-25 10:52:37,614] {scheduler_job.py:182} INFO - Started process (PID=327) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:52:37,617] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:52:37,619] {logging_mixin.py:104} INFO - [2021-04-25 10:52:37,619] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:52:38,312] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:52:38,344] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:52:38,357] {logging_mixin.py:104} INFO - [2021-04-25 10:52:38,357] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:52:38,390] {logging_mixin.py:104} INFO - [2021-04-25 10:52:38,389] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:52:38,399] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.788 seconds
[2021-04-25 10:53:08,527] {scheduler_job.py:182} INFO - Started process (PID=329) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:53:08,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:53:08,532] {logging_mixin.py:104} INFO - [2021-04-25 10:53:08,531] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:53:09,227] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:53:09,256] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:53:09,271] {logging_mixin.py:104} INFO - [2021-04-25 10:53:09,269] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:53:09,294] {logging_mixin.py:104} INFO - [2021-04-25 10:53:09,293] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:53:09,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.783 seconds
[2021-04-25 10:53:39,441] {scheduler_job.py:182} INFO - Started process (PID=331) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:53:39,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:53:39,446] {logging_mixin.py:104} INFO - [2021-04-25 10:53:39,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:53:40,038] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:53:40,065] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:53:40,075] {logging_mixin.py:104} INFO - [2021-04-25 10:53:40,074] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:53:40,089] {logging_mixin.py:104} INFO - [2021-04-25 10:53:40,089] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:53:40,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.660 seconds
[2021-04-25 10:54:10,257] {scheduler_job.py:182} INFO - Started process (PID=333) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:54:10,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:54:10,261] {logging_mixin.py:104} INFO - [2021-04-25 10:54:10,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:54:10,855] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:54:10,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:54:10,901] {logging_mixin.py:104} INFO - [2021-04-25 10:54:10,900] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:54:10,917] {logging_mixin.py:104} INFO - [2021-04-25 10:54:10,917] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:54:10,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.672 seconds
[2021-04-25 10:54:41,044] {scheduler_job.py:182} INFO - Started process (PID=335) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:54:41,047] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:54:41,048] {logging_mixin.py:104} INFO - [2021-04-25 10:54:41,048] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:54:41,670] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:54:41,697] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:54:41,707] {logging_mixin.py:104} INFO - [2021-04-25 10:54:41,706] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:54:41,721] {logging_mixin.py:104} INFO - [2021-04-25 10:54:41,721] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:54:41,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.690 seconds
[2021-04-25 10:55:11,879] {scheduler_job.py:182} INFO - Started process (PID=337) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:55:11,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:55:11,884] {logging_mixin.py:104} INFO - [2021-04-25 10:55:11,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:55:12,487] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:55:12,517] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:55:12,528] {logging_mixin.py:104} INFO - [2021-04-25 10:55:12,527] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:55:12,545] {logging_mixin.py:104} INFO - [2021-04-25 10:55:12,545] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:55:12,552] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.679 seconds
[2021-04-25 10:55:42,682] {scheduler_job.py:182} INFO - Started process (PID=339) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:55:42,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 10:55:42,688] {logging_mixin.py:104} INFO - [2021-04-25 10:55:42,687] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:55:46,399] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 10:55:46,576] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 10:55:46,639] {logging_mixin.py:104} INFO - [2021-04-25 10:55:46,637] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 10:55:46,680] {logging_mixin.py:104} INFO - [2021-04-25 10:55:46,680] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 10:55:46,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.022 seconds
[2021-04-25 11:15:48,902] {scheduler_job.py:182} INFO - Started process (PID=341) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:15:48,920] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:15:48,944] {logging_mixin.py:104} INFO - [2021-04-25 11:15:48,938] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:15:51,882] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:15:51,936] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:15:51,957] {logging_mixin.py:104} INFO - [2021-04-25 11:15:51,955] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:15:51,992] {logging_mixin.py:104} INFO - [2021-04-25 11:15:51,992] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:15:52,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.194 seconds
[2021-04-25 11:16:23,751] {scheduler_job.py:182} INFO - Started process (PID=343) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:16:23,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:16:23,913] {logging_mixin.py:104} INFO - [2021-04-25 11:16:23,908] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:16:54,288] {logging_mixin.py:104} INFO - [2021-04-25 11:16:54,270] {timeout.py:36} ERROR - Process timed out, PID: 343
[2021-04-25 11:16:54,378] {logging_mixin.py:104} INFO - [2021-04-25 11:16:54,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/recent_played_ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/recent_played_ingestion.py", line 5, in <module>
    from airflow.providers.google.cloud.operators.dataproc import DataprocCreateClusterOperator, \
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 43, in <module>
    from airflow.providers.google.cloud.hooks.dataproc import DataprocHook, DataProcJobBuilder
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/dataproc.py", line 44, in <module>
    from airflow.providers.google.common.hooks.base_google import GoogleBaseHook
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/common/hooks/base_google.py", line 38, in <module>
    from googleapiclient import discovery
  File "/home/airflow/.local/lib/python3.6/site-packages/googleapiclient/discovery.py", line 62, in <module>
    from googleapiclient.errors import HttpError
  File "/home/airflow/.local/lib/python3.6/site-packages/googleapiclient/errors.py", line 113, in <module>
    class UnacceptableMimeTypeError(Error):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/recent_played_ingestion.py after 30.0s, PID: 343
[2021-04-25 11:16:54,598] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:16:58,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 35.196 seconds
[2021-04-25 11:44:58,573] {scheduler_job.py:182} INFO - Started process (PID=345) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:44:58,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:44:58,623] {logging_mixin.py:104} INFO - [2021-04-25 11:44:58,622] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:45:01,470] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:45:01,516] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:45:01,547] {scheduler_job.py:596} INFO - Executed failure callback for <TaskInstance: recent_played_ingestion.create_cluster_dataproc 2021-04-25 10:00:00+00:00 [failed]> in state failed
[2021-04-25 11:45:01,575] {logging_mixin.py:104} INFO - [2021-04-25 11:45:01,570] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:45:01,616] {logging_mixin.py:104} INFO - [2021-04-25 11:45:01,616] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:45:01,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.069 seconds
[2021-04-25 11:45:31,772] {scheduler_job.py:182} INFO - Started process (PID=348) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:45:31,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:45:31,788] {logging_mixin.py:104} INFO - [2021-04-25 11:45:31,788] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:45:32,979] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:45:33,015] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:45:33,026] {logging_mixin.py:104} INFO - [2021-04-25 11:45:33,025] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:45:33,045] {logging_mixin.py:104} INFO - [2021-04-25 11:45:33,044] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:45:33,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.293 seconds
[2021-04-25 11:46:03,231] {scheduler_job.py:182} INFO - Started process (PID=349) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:46:03,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:46:03,238] {logging_mixin.py:104} INFO - [2021-04-25 11:46:03,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:46:03,979] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:46:04,020] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:46:04,035] {logging_mixin.py:104} INFO - [2021-04-25 11:46:04,034] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:46:04,062] {logging_mixin.py:104} INFO - [2021-04-25 11:46:04,062] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:46:04,078] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.853 seconds
[2021-04-25 11:46:34,332] {scheduler_job.py:182} INFO - Started process (PID=351) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:46:34,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:46:34,356] {logging_mixin.py:104} INFO - [2021-04-25 11:46:34,355] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:46:36,672] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:46:36,738] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:46:36,782] {logging_mixin.py:104} INFO - [2021-04-25 11:46:36,769] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:46:36,829] {logging_mixin.py:104} INFO - [2021-04-25 11:46:36,829] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:46:36,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.530 seconds
[2021-04-25 11:47:07,067] {scheduler_job.py:182} INFO - Started process (PID=353) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:47:07,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:47:07,076] {logging_mixin.py:104} INFO - [2021-04-25 11:47:07,076] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:47:08,287] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:47:08,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:47:08,401] {logging_mixin.py:104} INFO - [2021-04-25 11:47:08,398] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:47:08,437] {logging_mixin.py:104} INFO - [2021-04-25 11:47:08,437] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:47:08,449] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.391 seconds
[2021-04-25 11:47:38,594] {scheduler_job.py:182} INFO - Started process (PID=355) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:47:38,599] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:47:38,602] {logging_mixin.py:104} INFO - [2021-04-25 11:47:38,602] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:47:39,396] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:47:39,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:47:39,472] {logging_mixin.py:104} INFO - [2021-04-25 11:47:39,471] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:47:39,496] {logging_mixin.py:104} INFO - [2021-04-25 11:47:39,495] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:47:39,508] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.924 seconds
[2021-04-25 11:48:09,637] {scheduler_job.py:182} INFO - Started process (PID=362) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:48:09,641] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:48:09,643] {logging_mixin.py:104} INFO - [2021-04-25 11:48:09,643] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:48:10,322] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:48:10,352] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:48:10,378] {logging_mixin.py:104} INFO - [2021-04-25 11:48:10,377] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:48:10,395] {logging_mixin.py:104} INFO - [2021-04-25 11:48:10,395] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:48:10,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.773 seconds
[2021-04-25 11:48:40,534] {scheduler_job.py:182} INFO - Started process (PID=364) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:48:40,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:48:40,545] {logging_mixin.py:104} INFO - [2021-04-25 11:48:40,545] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:48:41,940] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:48:41,991] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:48:42,019] {logging_mixin.py:104} INFO - [2021-04-25 11:48:42,018] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:48:42,044] {logging_mixin.py:104} INFO - [2021-04-25 11:48:42,044] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:48:42,053] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.526 seconds
[2021-04-25 11:49:12,223] {scheduler_job.py:182} INFO - Started process (PID=366) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:49:12,225] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:49:12,227] {logging_mixin.py:104} INFO - [2021-04-25 11:49:12,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:49:13,302] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:49:13,346] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:49:13,370] {logging_mixin.py:104} INFO - [2021-04-25 11:49:13,369] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:49:13,407] {logging_mixin.py:104} INFO - [2021-04-25 11:49:13,407] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:49:13,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.203 seconds
[2021-04-25 11:49:43,504] {scheduler_job.py:182} INFO - Started process (PID=368) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:49:43,509] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:49:43,513] {logging_mixin.py:104} INFO - [2021-04-25 11:49:43,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:49:44,192] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:49:44,226] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:49:44,250] {logging_mixin.py:104} INFO - [2021-04-25 11:49:44,249] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:49:44,270] {logging_mixin.py:104} INFO - [2021-04-25 11:49:44,269] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:49:44,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.783 seconds
[2021-04-25 11:50:14,429] {scheduler_job.py:182} INFO - Started process (PID=370) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:50:14,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:50:14,434] {logging_mixin.py:104} INFO - [2021-04-25 11:50:14,434] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:50:15,153] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:50:15,182] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:50:15,205] {logging_mixin.py:104} INFO - [2021-04-25 11:50:15,203] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:50:15,264] {logging_mixin.py:104} INFO - [2021-04-25 11:50:15,264] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:50:15,296] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.871 seconds
[2021-04-25 11:50:45,569] {scheduler_job.py:182} INFO - Started process (PID=372) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:50:45,578] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:50:45,582] {logging_mixin.py:104} INFO - [2021-04-25 11:50:45,581] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:50:46,333] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:50:46,362] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:50:46,375] {logging_mixin.py:104} INFO - [2021-04-25 11:50:46,374] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:50:46,398] {logging_mixin.py:104} INFO - [2021-04-25 11:50:46,398] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:50:46,417] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.853 seconds
[2021-04-25 11:51:16,555] {scheduler_job.py:182} INFO - Started process (PID=374) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:51:16,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:51:16,561] {logging_mixin.py:104} INFO - [2021-04-25 11:51:16,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:51:17,349] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:51:17,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:51:17,401] {logging_mixin.py:104} INFO - [2021-04-25 11:51:17,400] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:51:17,426] {logging_mixin.py:104} INFO - [2021-04-25 11:51:17,426] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:51:17,435] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.887 seconds
[2021-04-25 11:51:47,624] {scheduler_job.py:182} INFO - Started process (PID=376) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:51:47,629] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:51:47,633] {logging_mixin.py:104} INFO - [2021-04-25 11:51:47,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:51:48,334] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:51:48,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:51:48,412] {logging_mixin.py:104} INFO - [2021-04-25 11:51:48,408] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:51:48,446] {logging_mixin.py:104} INFO - [2021-04-25 11:51:48,446] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:51:48,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.850 seconds
[2021-04-25 11:52:18,567] {scheduler_job.py:182} INFO - Started process (PID=378) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:52:18,575] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:52:18,582] {logging_mixin.py:104} INFO - [2021-04-25 11:52:18,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:52:19,778] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:52:19,826] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:52:19,854] {logging_mixin.py:104} INFO - [2021-04-25 11:52:19,853] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:52:19,903] {logging_mixin.py:104} INFO - [2021-04-25 11:52:19,903] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:52:19,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.355 seconds
[2021-04-25 11:52:50,039] {scheduler_job.py:182} INFO - Started process (PID=380) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:52:50,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:52:50,046] {logging_mixin.py:104} INFO - [2021-04-25 11:52:50,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:52:51,045] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:52:51,095] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:52:51,138] {logging_mixin.py:104} INFO - [2021-04-25 11:52:51,133] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:52:51,181] {logging_mixin.py:104} INFO - [2021-04-25 11:52:51,181] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 11:52:51,205] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.173 seconds
[2021-04-25 11:53:21,395] {scheduler_job.py:182} INFO - Started process (PID=382) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:53:21,399] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:53:21,401] {logging_mixin.py:104} INFO - [2021-04-25 11:53:21,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:53:22,350] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:53:22,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:53:22,422] {logging_mixin.py:104} INFO - [2021-04-25 11:53:22,421] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:53:22,449] {logging_mixin.py:104} INFO - [2021-04-25 11:53:22,448] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:53:22,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.070 seconds
[2021-04-25 11:53:52,523] {scheduler_job.py:182} INFO - Started process (PID=384) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:53:52,528] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:53:52,533] {logging_mixin.py:104} INFO - [2021-04-25 11:53:52,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:53:53,693] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:53:53,745] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:53:53,764] {logging_mixin.py:104} INFO - [2021-04-25 11:53:53,762] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:53:53,791] {logging_mixin.py:104} INFO - [2021-04-25 11:53:53,791] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:53:53,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.287 seconds
[2021-04-25 11:54:23,881] {scheduler_job.py:182} INFO - Started process (PID=386) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:54:23,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:54:23,894] {logging_mixin.py:104} INFO - [2021-04-25 11:54:23,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:54:24,902] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:54:24,952] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:54:24,981] {logging_mixin.py:104} INFO - [2021-04-25 11:54:24,979] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:54:25,019] {logging_mixin.py:104} INFO - [2021-04-25 11:54:25,019] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:54:25,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.167 seconds
[2021-04-25 11:54:55,244] {scheduler_job.py:182} INFO - Started process (PID=388) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:54:55,247] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:54:55,250] {logging_mixin.py:104} INFO - [2021-04-25 11:54:55,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:54:56,091] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:54:56,124] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:54:56,139] {logging_mixin.py:104} INFO - [2021-04-25 11:54:56,137] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:54:56,156] {logging_mixin.py:104} INFO - [2021-04-25 11:54:56,156] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:54:56,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.929 seconds
[2021-04-25 11:55:26,435] {scheduler_job.py:182} INFO - Started process (PID=390) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:55:26,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:55:26,442] {logging_mixin.py:104} INFO - [2021-04-25 11:55:26,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:55:27,763] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:55:27,815] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:55:27,848] {logging_mixin.py:104} INFO - [2021-04-25 11:55:27,846] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:55:27,875] {logging_mixin.py:104} INFO - [2021-04-25 11:55:27,875] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:55:27,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.491 seconds
[2021-04-25 11:55:57,970] {scheduler_job.py:182} INFO - Started process (PID=392) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:55:57,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:55:57,975] {logging_mixin.py:104} INFO - [2021-04-25 11:55:57,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:55:58,755] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:55:58,787] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:55:58,801] {logging_mixin.py:104} INFO - [2021-04-25 11:55:58,800] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:55:58,821] {logging_mixin.py:104} INFO - [2021-04-25 11:55:58,821] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:55:58,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.863 seconds
[2021-04-25 11:56:28,953] {scheduler_job.py:182} INFO - Started process (PID=394) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:56:28,972] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:56:28,973] {logging_mixin.py:104} INFO - [2021-04-25 11:56:28,973] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:56:29,668] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:56:29,706] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:56:29,723] {logging_mixin.py:104} INFO - [2021-04-25 11:56:29,722] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:56:29,746] {logging_mixin.py:104} INFO - [2021-04-25 11:56:29,746] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:56:29,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.807 seconds
[2021-04-25 11:57:00,023] {scheduler_job.py:182} INFO - Started process (PID=396) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:57:00,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:57:00,028] {logging_mixin.py:104} INFO - [2021-04-25 11:57:00,028] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:57:00,974] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:57:01,019] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:57:01,036] {logging_mixin.py:104} INFO - [2021-04-25 11:57:01,035] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:57:01,060] {logging_mixin.py:104} INFO - [2021-04-25 11:57:01,060] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:57:01,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.054 seconds
[2021-04-25 11:57:31,233] {scheduler_job.py:182} INFO - Started process (PID=398) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:57:31,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:57:31,241] {logging_mixin.py:104} INFO - [2021-04-25 11:57:31,241] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:57:32,136] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:57:32,177] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:57:32,196] {logging_mixin.py:104} INFO - [2021-04-25 11:57:32,194] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:57:32,227] {logging_mixin.py:104} INFO - [2021-04-25 11:57:32,227] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:57:32,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.015 seconds
[2021-04-25 11:58:02,693] {scheduler_job.py:182} INFO - Started process (PID=400) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:58:02,697] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:58:02,712] {logging_mixin.py:104} INFO - [2021-04-25 11:58:02,712] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:58:04,916] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:58:04,963] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:58:04,991] {logging_mixin.py:104} INFO - [2021-04-25 11:58:04,987] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:58:05,019] {logging_mixin.py:104} INFO - [2021-04-25 11:58:05,019] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:58:05,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.349 seconds
[2021-04-25 11:58:35,219] {scheduler_job.py:182} INFO - Started process (PID=402) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:58:35,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:58:35,227] {logging_mixin.py:104} INFO - [2021-04-25 11:58:35,226] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:58:36,294] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:58:36,347] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:58:36,372] {logging_mixin.py:104} INFO - [2021-04-25 11:58:36,370] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:58:36,395] {logging_mixin.py:104} INFO - [2021-04-25 11:58:36,395] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:58:36,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.197 seconds
[2021-04-25 11:59:06,615] {scheduler_job.py:182} INFO - Started process (PID=404) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:59:06,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:59:06,626] {logging_mixin.py:104} INFO - [2021-04-25 11:59:06,625] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:59:07,997] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:59:08,042] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:59:08,055] {logging_mixin.py:104} INFO - [2021-04-25 11:59:08,054] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:59:08,072] {logging_mixin.py:104} INFO - [2021-04-25 11:59:08,072] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:59:08,080] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.480 seconds
[2021-04-25 11:59:38,401] {scheduler_job.py:182} INFO - Started process (PID=406) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:59:38,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 11:59:38,405] {logging_mixin.py:104} INFO - [2021-04-25 11:59:38,405] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:59:39,661] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 11:59:39,759] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 11:59:39,878] {logging_mixin.py:104} INFO - [2021-04-25 11:59:39,872] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 11:59:39,949] {logging_mixin.py:104} INFO - [2021-04-25 11:59:39,948] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 11:59:39,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.588 seconds
[2021-04-25 12:00:10,119] {scheduler_job.py:182} INFO - Started process (PID=408) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:00:10,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:00:10,125] {logging_mixin.py:104} INFO - [2021-04-25 12:00:10,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:00:12,536] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:00:12,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:00:12,623] {logging_mixin.py:104} INFO - [2021-04-25 12:00:12,621] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:00:12,648] {logging_mixin.py:104} INFO - [2021-04-25 12:00:12,647] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:00:12,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.553 seconds
[2021-04-25 12:00:42,766] {scheduler_job.py:182} INFO - Started process (PID=410) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:00:42,770] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:00:42,773] {logging_mixin.py:104} INFO - [2021-04-25 12:00:42,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:00:44,800] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:00:44,864] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:00:44,890] {logging_mixin.py:104} INFO - [2021-04-25 12:00:44,888] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:00:44,909] {logging_mixin.py:104} INFO - [2021-04-25 12:00:44,909] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:00:44,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.160 seconds
[2021-04-25 12:01:15,014] {scheduler_job.py:182} INFO - Started process (PID=413) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:01:15,018] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:01:15,022] {logging_mixin.py:104} INFO - [2021-04-25 12:01:15,022] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:01:15,858] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:01:15,893] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:01:15,907] {logging_mixin.py:104} INFO - [2021-04-25 12:01:15,906] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:01:15,923] {logging_mixin.py:104} INFO - [2021-04-25 12:01:15,923] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:01:15,932] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.926 seconds
[2021-04-25 12:01:45,989] {scheduler_job.py:182} INFO - Started process (PID=414) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:01:45,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:01:45,996] {logging_mixin.py:104} INFO - [2021-04-25 12:01:45,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:01:46,724] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:01:46,763] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:01:46,779] {logging_mixin.py:104} INFO - [2021-04-25 12:01:46,777] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:01:46,808] {logging_mixin.py:104} INFO - [2021-04-25 12:01:46,807] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:01:46,816] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.833 seconds
[2021-04-25 12:02:16,970] {scheduler_job.py:182} INFO - Started process (PID=416) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:02:16,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:02:16,993] {logging_mixin.py:104} INFO - [2021-04-25 12:02:16,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:02:17,930] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:02:17,964] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:02:17,976] {logging_mixin.py:104} INFO - [2021-04-25 12:02:17,975] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:02:18,003] {logging_mixin.py:104} INFO - [2021-04-25 12:02:18,003] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:02:18,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.062 seconds
[2021-04-25 12:02:48,205] {scheduler_job.py:182} INFO - Started process (PID=418) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:02:48,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:02:48,213] {logging_mixin.py:104} INFO - [2021-04-25 12:02:48,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:02:49,072] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:02:49,122] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:02:49,144] {logging_mixin.py:104} INFO - [2021-04-25 12:02:49,141] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:02:49,169] {logging_mixin.py:104} INFO - [2021-04-25 12:02:49,169] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:02:49,182] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.992 seconds
[2021-04-25 12:03:19,363] {scheduler_job.py:182} INFO - Started process (PID=420) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:03:19,367] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:03:19,369] {logging_mixin.py:104} INFO - [2021-04-25 12:03:19,368] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:03:20,494] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:03:20,569] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:03:20,598] {logging_mixin.py:104} INFO - [2021-04-25 12:03:20,597] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:03:20,691] {logging_mixin.py:104} INFO - [2021-04-25 12:03:20,691] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:03:20,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.361 seconds
[2021-04-25 12:03:50,833] {scheduler_job.py:182} INFO - Started process (PID=423) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:03:50,836] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:03:50,839] {logging_mixin.py:104} INFO - [2021-04-25 12:03:50,839] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:03:51,522] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:03:51,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:03:51,569] {logging_mixin.py:104} INFO - [2021-04-25 12:03:51,568] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:03:51,592] {logging_mixin.py:104} INFO - [2021-04-25 12:03:51,591] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:03:51,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.774 seconds
[2021-04-25 12:04:10,241] {scheduler_job.py:182} INFO - Started process (PID=424) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:04:10,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:04:10,257] {logging_mixin.py:104} INFO - [2021-04-25 12:04:10,257] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:04:11,355] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:04:11,423] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:04:11,451] {logging_mixin.py:104} INFO - [2021-04-25 12:04:11,449] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:04:11,474] {logging_mixin.py:104} INFO - [2021-04-25 12:04:11,473] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:04:11,505] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.280 seconds
[2021-04-25 12:04:42,370] {scheduler_job.py:182} INFO - Started process (PID=426) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:04:42,375] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:04:42,384] {logging_mixin.py:104} INFO - [2021-04-25 12:04:42,384] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:04:44,433] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:04:44,492] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:04:44,511] {logging_mixin.py:104} INFO - [2021-04-25 12:04:44,510] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:04:44,549] {logging_mixin.py:104} INFO - [2021-04-25 12:04:44,549] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:04:44,568] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.206 seconds
[2021-04-25 12:05:14,681] {scheduler_job.py:182} INFO - Started process (PID=428) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:05:14,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:05:14,685] {logging_mixin.py:104} INFO - [2021-04-25 12:05:14,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:05:15,326] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:05:15,353] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:05:15,364] {logging_mixin.py:104} INFO - [2021-04-25 12:05:15,363] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:05:15,382] {logging_mixin.py:104} INFO - [2021-04-25 12:05:15,382] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:05:15,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.714 seconds
[2021-04-25 12:05:45,550] {scheduler_job.py:182} INFO - Started process (PID=430) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:05:45,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:05:45,563] {logging_mixin.py:104} INFO - [2021-04-25 12:05:45,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:05:46,370] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:05:46,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:05:46,416] {logging_mixin.py:104} INFO - [2021-04-25 12:05:46,415] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:05:46,436] {logging_mixin.py:104} INFO - [2021-04-25 12:05:46,436] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:05:46,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.907 seconds
[2021-04-25 12:06:16,624] {scheduler_job.py:182} INFO - Started process (PID=432) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:16,628] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:06:16,633] {logging_mixin.py:104} INFO - [2021-04-25 12:06:16,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:17,570] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:06:17,693] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:17,765] {logging_mixin.py:104} INFO - [2021-04-25 12:06:17,762] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:06:17,801] {logging_mixin.py:104} INFO - [2021-04-25 12:06:17,800] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:06:17,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.211 seconds
[2021-04-25 12:06:47,960] {scheduler_job.py:182} INFO - Started process (PID=434) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:47,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:06:47,967] {logging_mixin.py:104} INFO - [2021-04-25 12:06:47,967] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:48,944] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:06:48,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:48,989] {logging_mixin.py:104} INFO - [2021-04-25 12:06:48,988] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:06:49,007] {logging_mixin.py:104} INFO - [2021-04-25 12:06:49,007] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:06:49,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.071 seconds
[2021-04-25 12:06:58,161] {scheduler_job.py:182} INFO - Started process (PID=436) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:58,165] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:06:58,168] {logging_mixin.py:104} INFO - [2021-04-25 12:06:58,168] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:58,993] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:06:59,023] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:06:59,033] {logging_mixin.py:104} INFO - [2021-04-25 12:06:59,032] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:06:59,049] {logging_mixin.py:104} INFO - [2021-04-25 12:06:59,049] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:06:59,057] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.904 seconds
[2021-04-25 12:07:29,175] {scheduler_job.py:182} INFO - Started process (PID=438) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:07:29,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:07:29,183] {logging_mixin.py:104} INFO - [2021-04-25 12:07:29,182] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:07:29,860] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:07:29,892] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:07:29,906] {logging_mixin.py:104} INFO - [2021-04-25 12:07:29,904] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:07:29,926] {logging_mixin.py:104} INFO - [2021-04-25 12:07:29,926] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:07:29,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.767 seconds
[2021-04-25 12:08:00,036] {scheduler_job.py:182} INFO - Started process (PID=440) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:08:00,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:08:00,040] {logging_mixin.py:104} INFO - [2021-04-25 12:08:00,040] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:08:00,729] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:08:00,754] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:08:00,765] {logging_mixin.py:104} INFO - [2021-04-25 12:08:00,764] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:08:00,781] {logging_mixin.py:104} INFO - [2021-04-25 12:08:00,781] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:08:00,789] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.756 seconds
[2021-04-25 12:08:30,896] {scheduler_job.py:182} INFO - Started process (PID=442) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:08:30,902] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:08:30,904] {logging_mixin.py:104} INFO - [2021-04-25 12:08:30,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:08:31,656] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:08:31,684] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:08:31,697] {logging_mixin.py:104} INFO - [2021-04-25 12:08:31,696] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:08:31,714] {logging_mixin.py:104} INFO - [2021-04-25 12:08:31,714] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:08:31,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.840 seconds
[2021-04-25 12:09:01,810] {scheduler_job.py:182} INFO - Started process (PID=444) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:09:01,815] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:09:01,818] {logging_mixin.py:104} INFO - [2021-04-25 12:09:01,818] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:09:02,747] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:09:02,788] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:09:02,802] {logging_mixin.py:104} INFO - [2021-04-25 12:09:02,801] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:09:02,827] {logging_mixin.py:104} INFO - [2021-04-25 12:09:02,827] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:09:02,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.035 seconds
[2021-04-25 12:09:32,973] {scheduler_job.py:182} INFO - Started process (PID=446) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:09:32,977] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:09:32,980] {logging_mixin.py:104} INFO - [2021-04-25 12:09:32,980] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:09:33,915] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:09:33,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:09:33,966] {logging_mixin.py:104} INFO - [2021-04-25 12:09:33,965] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:09:33,989] {logging_mixin.py:104} INFO - [2021-04-25 12:09:33,989] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:09:34,018] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.050 seconds
[2021-04-25 12:10:04,160] {scheduler_job.py:182} INFO - Started process (PID=448) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:04,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:10:04,165] {logging_mixin.py:104} INFO - [2021-04-25 12:10:04,165] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:05,190] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:10:05,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:05,265] {logging_mixin.py:104} INFO - [2021-04-25 12:10:05,263] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:10:05,298] {logging_mixin.py:104} INFO - [2021-04-25 12:10:05,298] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:10:05,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.155 seconds
[2021-04-25 12:10:35,472] {scheduler_job.py:182} INFO - Started process (PID=449) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:35,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:10:35,483] {logging_mixin.py:104} INFO - [2021-04-25 12:10:35,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:37,406] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:10:37,474] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:37,500] {logging_mixin.py:104} INFO - [2021-04-25 12:10:37,498] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:10:37,527] {logging_mixin.py:104} INFO - [2021-04-25 12:10:37,527] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:10:37,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.081 seconds
[2021-04-25 12:10:50,050] {scheduler_job.py:182} INFO - Started process (PID=451) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:50,056] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:10:50,059] {logging_mixin.py:104} INFO - [2021-04-25 12:10:50,058] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:50,939] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:10:50,985] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:10:51,005] {logging_mixin.py:104} INFO - [2021-04-25 12:10:51,004] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:10:51,023] {logging_mixin.py:104} INFO - [2021-04-25 12:10:51,023] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:10:51,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.994 seconds
[2021-04-25 12:11:21,124] {scheduler_job.py:182} INFO - Started process (PID=453) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:11:21,126] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:11:21,128] {logging_mixin.py:104} INFO - [2021-04-25 12:11:21,128] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:11:21,889] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:11:21,933] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:11:21,947] {logging_mixin.py:104} INFO - [2021-04-25 12:11:21,946] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:11:21,970] {logging_mixin.py:104} INFO - [2021-04-25 12:11:21,970] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:11:21,982] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.863 seconds
[2021-04-25 12:11:52,109] {scheduler_job.py:182} INFO - Started process (PID=455) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:11:52,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:11:52,113] {logging_mixin.py:104} INFO - [2021-04-25 12:11:52,113] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:11:52,772] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:11:52,800] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:11:52,811] {logging_mixin.py:104} INFO - [2021-04-25 12:11:52,810] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:11:52,829] {logging_mixin.py:104} INFO - [2021-04-25 12:11:52,829] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:11:52,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.735 seconds
[2021-04-25 12:12:22,996] {scheduler_job.py:182} INFO - Started process (PID=457) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:12:23,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:12:23,005] {logging_mixin.py:104} INFO - [2021-04-25 12:12:23,005] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:12:24,077] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:12:24,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:12:24,142] {logging_mixin.py:104} INFO - [2021-04-25 12:12:24,141] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:12:24,172] {logging_mixin.py:104} INFO - [2021-04-25 12:12:24,172] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:12:24,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.198 seconds
[2021-04-25 12:12:54,449] {scheduler_job.py:182} INFO - Started process (PID=459) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:12:54,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:12:54,455] {logging_mixin.py:104} INFO - [2021-04-25 12:12:54,454] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:12:55,123] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:12:55,173] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:12:55,186] {logging_mixin.py:104} INFO - [2021-04-25 12:12:55,185] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:12:55,202] {logging_mixin.py:104} INFO - [2021-04-25 12:12:55,202] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:12:55,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.767 seconds
[2021-04-25 12:13:25,572] {scheduler_job.py:182} INFO - Started process (PID=461) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:13:25,575] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:13:25,578] {logging_mixin.py:104} INFO - [2021-04-25 12:13:25,578] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:13:27,168] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:13:27,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:13:27,234] {logging_mixin.py:104} INFO - [2021-04-25 12:13:27,230] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:13:27,267] {logging_mixin.py:104} INFO - [2021-04-25 12:13:27,267] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:13:27,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.774 seconds
[2021-04-25 12:13:57,746] {scheduler_job.py:182} INFO - Started process (PID=463) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:13:57,750] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:13:57,752] {logging_mixin.py:104} INFO - [2021-04-25 12:13:57,752] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:13:58,559] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:13:58,594] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:13:58,607] {logging_mixin.py:104} INFO - [2021-04-25 12:13:58,606] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:13:58,629] {logging_mixin.py:104} INFO - [2021-04-25 12:13:58,628] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:13:58,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.902 seconds
[2021-04-25 12:14:29,241] {scheduler_job.py:182} INFO - Started process (PID=465) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:14:29,245] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:14:29,249] {logging_mixin.py:104} INFO - [2021-04-25 12:14:29,248] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:14:29,901] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:14:29,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:14:29,970] {logging_mixin.py:104} INFO - [2021-04-25 12:14:29,968] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:14:30,001] {logging_mixin.py:104} INFO - [2021-04-25 12:14:30,001] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:14:30,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.788 seconds
[2021-04-25 12:15:00,123] {scheduler_job.py:182} INFO - Started process (PID=467) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:15:00,126] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:15:00,128] {logging_mixin.py:104} INFO - [2021-04-25 12:15:00,128] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:15:01,516] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:15:01,831] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:15:01,914] {logging_mixin.py:104} INFO - [2021-04-25 12:15:01,912] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:15:01,983] {logging_mixin.py:104} INFO - [2021-04-25 12:15:01,983] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:15:02,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.976 seconds
[2021-04-25 12:15:32,646] {scheduler_job.py:182} INFO - Started process (PID=469) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:15:32,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:15:32,657] {logging_mixin.py:104} INFO - [2021-04-25 12:15:32,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:15:34,789] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:15:34,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:15:34,906] {logging_mixin.py:104} INFO - [2021-04-25 12:15:34,905] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:15:34,945] {logging_mixin.py:104} INFO - [2021-04-25 12:15:34,945] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:15:35,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.530 seconds
[2021-04-25 12:16:05,417] {scheduler_job.py:182} INFO - Started process (PID=471) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:16:05,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:16:05,422] {logging_mixin.py:104} INFO - [2021-04-25 12:16:05,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:16:06,036] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:16:06,065] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:16:06,077] {logging_mixin.py:104} INFO - [2021-04-25 12:16:06,076] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:16:06,094] {logging_mixin.py:104} INFO - [2021-04-25 12:16:06,094] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:16:06,105] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.693 seconds
[2021-04-25 12:16:36,217] {scheduler_job.py:182} INFO - Started process (PID=473) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:16:36,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:16:36,224] {logging_mixin.py:104} INFO - [2021-04-25 12:16:36,224] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:16:37,793] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:16:37,825] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:16:37,836] {logging_mixin.py:104} INFO - [2021-04-25 12:16:37,835] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:16:37,872] {logging_mixin.py:104} INFO - [2021-04-25 12:16:37,872] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:16:37,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.671 seconds
[2021-04-25 12:17:07,978] {scheduler_job.py:182} INFO - Started process (PID=475) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:17:07,983] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:17:07,985] {logging_mixin.py:104} INFO - [2021-04-25 12:17:07,985] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:17:08,661] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:17:08,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:17:08,709] {logging_mixin.py:104} INFO - [2021-04-25 12:17:08,708] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:17:08,724] {logging_mixin.py:104} INFO - [2021-04-25 12:17:08,724] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:17:08,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.757 seconds
[2021-04-25 12:17:38,870] {scheduler_job.py:182} INFO - Started process (PID=477) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:17:38,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:17:38,879] {logging_mixin.py:104} INFO - [2021-04-25 12:17:38,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:17:39,604] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:17:39,641] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:17:39,654] {logging_mixin.py:104} INFO - [2021-04-25 12:17:39,653] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:17:39,673] {logging_mixin.py:104} INFO - [2021-04-25 12:17:39,673] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:17:39,683] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.817 seconds
[2021-04-25 12:18:09,781] {scheduler_job.py:182} INFO - Started process (PID=479) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:18:09,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:18:09,784] {logging_mixin.py:104} INFO - [2021-04-25 12:18:09,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:18:10,394] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:18:10,434] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:18:10,447] {logging_mixin.py:104} INFO - [2021-04-25 12:18:10,446] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:18:10,466] {logging_mixin.py:104} INFO - [2021-04-25 12:18:10,465] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:18:10,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.700 seconds
[2021-04-25 12:18:40,591] {scheduler_job.py:182} INFO - Started process (PID=481) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:18:40,594] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:18:40,596] {logging_mixin.py:104} INFO - [2021-04-25 12:18:40,596] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:18:41,260] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:18:41,289] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:18:41,301] {logging_mixin.py:104} INFO - [2021-04-25 12:18:41,300] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:18:41,319] {logging_mixin.py:104} INFO - [2021-04-25 12:18:41,319] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:18:41,330] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.742 seconds
[2021-04-25 12:19:11,438] {scheduler_job.py:182} INFO - Started process (PID=483) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:19:11,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:19:11,443] {logging_mixin.py:104} INFO - [2021-04-25 12:19:11,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:19:12,102] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:19:12,131] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:19:12,144] {logging_mixin.py:104} INFO - [2021-04-25 12:19:12,143] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:19:12,164] {logging_mixin.py:104} INFO - [2021-04-25 12:19:12,163] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:19:12,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.742 seconds
[2021-04-25 12:19:42,282] {scheduler_job.py:182} INFO - Started process (PID=485) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:19:42,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:19:42,286] {logging_mixin.py:104} INFO - [2021-04-25 12:19:42,286] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:19:42,912] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:19:42,940] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:19:42,951] {logging_mixin.py:104} INFO - [2021-04-25 12:19:42,950] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:19:42,968] {logging_mixin.py:104} INFO - [2021-04-25 12:19:42,968] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:19:42,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.699 seconds
[2021-04-25 12:20:13,140] {scheduler_job.py:182} INFO - Started process (PID=487) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:20:13,143] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:20:13,144] {logging_mixin.py:104} INFO - [2021-04-25 12:20:13,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:20:13,860] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:20:13,896] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:20:13,907] {logging_mixin.py:104} INFO - [2021-04-25 12:20:13,906] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:20:13,922] {logging_mixin.py:104} INFO - [2021-04-25 12:20:13,921] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:20:13,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-25 12:20:44,027] {scheduler_job.py:182} INFO - Started process (PID=489) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:20:44,030] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:20:44,032] {logging_mixin.py:104} INFO - [2021-04-25 12:20:44,031] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:20:44,636] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:20:44,669] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:20:44,681] {logging_mixin.py:104} INFO - [2021-04-25 12:20:44,680] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:20:44,698] {logging_mixin.py:104} INFO - [2021-04-25 12:20:44,698] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:20:44,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.684 seconds
[2021-04-25 12:21:14,812] {scheduler_job.py:182} INFO - Started process (PID=491) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:21:14,814] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:21:14,816] {logging_mixin.py:104} INFO - [2021-04-25 12:21:14,816] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:21:15,417] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:21:15,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:21:15,454] {logging_mixin.py:104} INFO - [2021-04-25 12:21:15,453] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:21:15,470] {logging_mixin.py:104} INFO - [2021-04-25 12:21:15,470] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:21:15,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.671 seconds
[2021-04-25 12:21:45,584] {scheduler_job.py:182} INFO - Started process (PID=493) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:21:45,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:21:45,588] {logging_mixin.py:104} INFO - [2021-04-25 12:21:45,588] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:21:46,242] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:21:46,269] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:21:46,281] {logging_mixin.py:104} INFO - [2021-04-25 12:21:46,280] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:21:46,297] {logging_mixin.py:104} INFO - [2021-04-25 12:21:46,297] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:21:46,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.727 seconds
[2021-04-25 12:22:16,428] {scheduler_job.py:182} INFO - Started process (PID=495) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:22:16,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:22:16,436] {logging_mixin.py:104} INFO - [2021-04-25 12:22:16,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:22:17,257] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:22:17,302] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:22:17,319] {logging_mixin.py:104} INFO - [2021-04-25 12:22:17,317] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:22:17,344] {logging_mixin.py:104} INFO - [2021-04-25 12:22:17,344] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:22:17,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.938 seconds
[2021-04-25 12:22:47,580] {scheduler_job.py:182} INFO - Started process (PID=497) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:22:47,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:22:47,590] {logging_mixin.py:104} INFO - [2021-04-25 12:22:47,589] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:22:48,514] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:22:48,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:22:48,561] {logging_mixin.py:104} INFO - [2021-04-25 12:22:48,559] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:22:48,582] {logging_mixin.py:104} INFO - [2021-04-25 12:22:48,582] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:22:48,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.019 seconds
[2021-04-25 12:23:18,918] {scheduler_job.py:182} INFO - Started process (PID=499) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:23:18,922] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:23:18,925] {logging_mixin.py:104} INFO - [2021-04-25 12:23:18,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:23:19,846] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:23:19,890] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:23:19,906] {logging_mixin.py:104} INFO - [2021-04-25 12:23:19,904] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:23:19,934] {logging_mixin.py:104} INFO - [2021-04-25 12:23:19,933] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:23:19,946] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.033 seconds
[2021-04-25 12:23:50,007] {scheduler_job.py:182} INFO - Started process (PID=501) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:23:50,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:23:50,015] {logging_mixin.py:104} INFO - [2021-04-25 12:23:50,015] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:23:50,696] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:23:50,723] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:23:50,736] {logging_mixin.py:104} INFO - [2021-04-25 12:23:50,735] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:23:50,752] {logging_mixin.py:104} INFO - [2021-04-25 12:23:50,752] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:23:50,762] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.758 seconds
[2021-04-25 12:24:20,887] {scheduler_job.py:182} INFO - Started process (PID=503) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:24:20,890] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:24:20,891] {logging_mixin.py:104} INFO - [2021-04-25 12:24:20,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:24:22,149] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:24:22,208] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:24:22,226] {logging_mixin.py:104} INFO - [2021-04-25 12:24:22,224] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:24:22,265] {logging_mixin.py:104} INFO - [2021-04-25 12:24:22,265] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:24:22,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.403 seconds
[2021-04-25 12:24:52,396] {scheduler_job.py:182} INFO - Started process (PID=505) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:24:52,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:24:52,403] {logging_mixin.py:104} INFO - [2021-04-25 12:24:52,402] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:24:53,143] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:24:53,178] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:24:53,192] {logging_mixin.py:104} INFO - [2021-04-25 12:24:53,191] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:24:53,212] {logging_mixin.py:104} INFO - [2021-04-25 12:24:53,212] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:24:53,223] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.832 seconds
[2021-04-25 12:25:23,377] {scheduler_job.py:182} INFO - Started process (PID=507) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:25:23,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:25:23,388] {logging_mixin.py:104} INFO - [2021-04-25 12:25:23,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:25:24,154] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:25:24,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:25:24,204] {logging_mixin.py:104} INFO - [2021-04-25 12:25:24,203] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:25:24,221] {logging_mixin.py:104} INFO - [2021-04-25 12:25:24,221] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:25:24,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.857 seconds
[2021-04-25 12:25:54,314] {scheduler_job.py:182} INFO - Started process (PID=509) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:25:54,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:25:54,318] {logging_mixin.py:104} INFO - [2021-04-25 12:25:54,318] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:25:55,199] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:25:55,228] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:25:55,241] {logging_mixin.py:104} INFO - [2021-04-25 12:25:55,239] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:25:55,257] {logging_mixin.py:104} INFO - [2021-04-25 12:25:55,256] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:25:55,265] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.989 seconds
[2021-04-25 12:26:25,415] {scheduler_job.py:182} INFO - Started process (PID=511) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:26:25,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:26:25,421] {logging_mixin.py:104} INFO - [2021-04-25 12:26:25,421] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:26:26,438] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:26:26,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:26:26,495] {logging_mixin.py:104} INFO - [2021-04-25 12:26:26,494] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:26:26,514] {logging_mixin.py:104} INFO - [2021-04-25 12:26:26,514] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:26:26,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.128 seconds
[2021-04-25 12:26:56,627] {scheduler_job.py:182} INFO - Started process (PID=513) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:26:56,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:26:56,632] {logging_mixin.py:104} INFO - [2021-04-25 12:26:56,631] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:26:57,530] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:26:57,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:26:57,591] {logging_mixin.py:104} INFO - [2021-04-25 12:26:57,589] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:26:57,616] {logging_mixin.py:104} INFO - [2021-04-25 12:26:57,616] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:26:57,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.005 seconds
[2021-04-25 12:27:27,743] {scheduler_job.py:182} INFO - Started process (PID=515) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:27:27,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:27:27,752] {logging_mixin.py:104} INFO - [2021-04-25 12:27:27,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:27:28,667] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:27:28,720] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:27:28,734] {logging_mixin.py:104} INFO - [2021-04-25 12:27:28,733] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:27:28,752] {logging_mixin.py:104} INFO - [2021-04-25 12:27:28,752] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:27:28,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.028 seconds
[2021-04-25 12:27:58,990] {scheduler_job.py:182} INFO - Started process (PID=517) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:27:58,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:27:58,999] {logging_mixin.py:104} INFO - [2021-04-25 12:27:58,999] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:28:00,722] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:28:00,774] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:28:00,796] {logging_mixin.py:104} INFO - [2021-04-25 12:28:00,794] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:28:00,830] {logging_mixin.py:104} INFO - [2021-04-25 12:28:00,830] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:28:00,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.866 seconds
[2021-04-25 12:28:31,008] {scheduler_job.py:182} INFO - Started process (PID=519) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:28:31,032] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:28:31,036] {logging_mixin.py:104} INFO - [2021-04-25 12:28:31,035] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:28:32,233] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:28:32,270] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:28:32,282] {logging_mixin.py:104} INFO - [2021-04-25 12:28:32,281] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:28:32,304] {logging_mixin.py:104} INFO - [2021-04-25 12:28:32,303] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:28:32,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.316 seconds
[2021-04-25 12:29:02,418] {scheduler_job.py:182} INFO - Started process (PID=521) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:29:02,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:29:02,426] {logging_mixin.py:104} INFO - [2021-04-25 12:29:02,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:29:03,876] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:29:03,947] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:29:03,973] {logging_mixin.py:104} INFO - [2021-04-25 12:29:03,971] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:29:04,008] {logging_mixin.py:104} INFO - [2021-04-25 12:29:04,008] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:29:04,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.614 seconds
[2021-04-25 12:29:34,475] {scheduler_job.py:182} INFO - Started process (PID=523) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:29:34,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:29:34,479] {logging_mixin.py:104} INFO - [2021-04-25 12:29:34,479] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:29:35,151] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:29:35,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:29:35,197] {logging_mixin.py:104} INFO - [2021-04-25 12:29:35,196] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:29:35,217] {logging_mixin.py:104} INFO - [2021-04-25 12:29:35,216] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:29:35,230] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.759 seconds
[2021-04-25 12:30:05,385] {scheduler_job.py:182} INFO - Started process (PID=525) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:30:05,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:30:05,395] {logging_mixin.py:104} INFO - [2021-04-25 12:30:05,395] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:30:06,050] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:30:06,085] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:30:06,099] {logging_mixin.py:104} INFO - [2021-04-25 12:30:06,098] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:30:06,115] {logging_mixin.py:104} INFO - [2021-04-25 12:30:06,115] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:30:06,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.745 seconds
[2021-04-25 12:30:36,204] {scheduler_job.py:182} INFO - Started process (PID=527) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:30:36,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:30:36,209] {logging_mixin.py:104} INFO - [2021-04-25 12:30:36,209] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:30:36,842] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:30:36,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:30:36,881] {logging_mixin.py:104} INFO - [2021-04-25 12:30:36,880] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:30:36,897] {logging_mixin.py:104} INFO - [2021-04-25 12:30:36,897] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:30:36,905] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.705 seconds
[2021-04-25 12:31:07,120] {scheduler_job.py:182} INFO - Started process (PID=529) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:07,129] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:31:07,140] {logging_mixin.py:104} INFO - [2021-04-25 12:31:07,139] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:08,817] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:31:08,889] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:08,928] {logging_mixin.py:104} INFO - [2021-04-25 12:31:08,925] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:31:08,973] {logging_mixin.py:104} INFO - [2021-04-25 12:31:08,972] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:31:08,988] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.889 seconds
[2021-04-25 12:31:39,829] {scheduler_job.py:182} INFO - Started process (PID=531) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:39,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:31:39,837] {logging_mixin.py:104} INFO - [2021-04-25 12:31:39,837] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:41,115] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:31:41,214] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:41,301] {logging_mixin.py:104} INFO - [2021-04-25 12:31:41,297] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:31:41,374] {logging_mixin.py:104} INFO - [2021-04-25 12:31:41,374] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:31:41,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.588 seconds
[2021-04-25 12:31:48,828] {scheduler_job.py:182} INFO - Started process (PID=532) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:48,832] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:31:48,840] {logging_mixin.py:104} INFO - [2021-04-25 12:31:48,840] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:50,056] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:31:50,094] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:31:50,116] {logging_mixin.py:104} INFO - [2021-04-25 12:31:50,115] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:31:50,132] {logging_mixin.py:104} INFO - [2021-04-25 12:31:50,132] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:31:50,142] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.320 seconds
[2021-04-25 12:32:20,269] {scheduler_job.py:182} INFO - Started process (PID=534) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:32:20,272] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:32:20,276] {logging_mixin.py:104} INFO - [2021-04-25 12:32:20,275] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:32:21,023] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:32:21,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:32:21,094] {logging_mixin.py:104} INFO - [2021-04-25 12:32:21,093] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:32:21,112] {logging_mixin.py:104} INFO - [2021-04-25 12:32:21,112] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:32:21,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.858 seconds
[2021-04-25 12:32:51,229] {scheduler_job.py:182} INFO - Started process (PID=536) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:32:51,233] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:32:51,235] {logging_mixin.py:104} INFO - [2021-04-25 12:32:51,235] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:32:52,345] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:32:52,395] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:32:52,414] {logging_mixin.py:104} INFO - [2021-04-25 12:32:52,413] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:32:52,449] {logging_mixin.py:104} INFO - [2021-04-25 12:32:52,449] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:32:52,463] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.238 seconds
[2021-04-25 12:33:01,286] {scheduler_job.py:182} INFO - Started process (PID=538) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:01,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:33:01,293] {logging_mixin.py:104} INFO - [2021-04-25 12:33:01,293] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:01,967] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:33:01,998] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:02,034] {logging_mixin.py:104} INFO - [2021-04-25 12:33:02,033] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:33:02,053] {logging_mixin.py:104} INFO - [2021-04-25 12:33:02,053] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:33:02,063] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.781 seconds
[2021-04-25 12:33:32,638] {scheduler_job.py:182} INFO - Started process (PID=540) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:32,649] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:33:32,652] {logging_mixin.py:104} INFO - [2021-04-25 12:33:32,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:33,853] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:33:33,897] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:33,912] {logging_mixin.py:104} INFO - [2021-04-25 12:33:33,911] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:33:33,930] {logging_mixin.py:104} INFO - [2021-04-25 12:33:33,930] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:33:33,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.318 seconds
[2021-04-25 12:33:46,526] {scheduler_job.py:182} INFO - Started process (PID=541) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:46,537] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:33:46,543] {logging_mixin.py:104} INFO - [2021-04-25 12:33:46,543] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:47,453] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:33:47,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:47,506] {logging_mixin.py:104} INFO - [2021-04-25 12:33:47,505] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:33:47,525] {logging_mixin.py:104} INFO - [2021-04-25 12:33:47,525] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:33:47,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.026 seconds
[2021-04-25 12:33:52,541] {scheduler_job.py:182} INFO - Started process (PID=542) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:52,545] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:33:52,548] {logging_mixin.py:104} INFO - [2021-04-25 12:33:52,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:53,209] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:33:53,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:33:53,287] {logging_mixin.py:104} INFO - [2021-04-25 12:33:53,286] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:33:53,307] {logging_mixin.py:104} INFO - [2021-04-25 12:33:53,307] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:33:53,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.786 seconds
[2021-04-25 12:34:23,723] {scheduler_job.py:182} INFO - Started process (PID=544) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:34:23,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:34:23,732] {logging_mixin.py:104} INFO - [2021-04-25 12:34:23,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:34:24,699] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:34:24,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:34:24,746] {logging_mixin.py:104} INFO - [2021-04-25 12:34:24,745] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:34:24,770] {logging_mixin.py:104} INFO - [2021-04-25 12:34:24,770] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:34:24,785] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.102 seconds
[2021-04-25 12:34:50,468] {scheduler_job.py:182} INFO - Started process (PID=546) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:34:50,471] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:34:50,473] {logging_mixin.py:104} INFO - [2021-04-25 12:34:50,473] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:34:51,497] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:34:51,566] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:34:51,609] {logging_mixin.py:104} INFO - [2021-04-25 12:34:51,603] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:34:51,638] {logging_mixin.py:104} INFO - [2021-04-25 12:34:51,638] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:34:51,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.192 seconds
[2021-04-25 12:35:21,755] {scheduler_job.py:182} INFO - Started process (PID=548) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:35:21,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:35:21,760] {logging_mixin.py:104} INFO - [2021-04-25 12:35:21,759] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:35:22,608] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:35:22,658] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:35:22,679] {logging_mixin.py:104} INFO - [2021-04-25 12:35:22,678] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:35:22,705] {logging_mixin.py:104} INFO - [2021-04-25 12:35:22,705] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T09:00:00+00:00
[2021-04-25 12:35:22,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.969 seconds
[2021-04-25 12:35:52,962] {scheduler_job.py:182} INFO - Started process (PID=550) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:35:52,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:35:52,971] {logging_mixin.py:104} INFO - [2021-04-25 12:35:52,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:35:55,763] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:35:55,916] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:35:55,939] {logging_mixin.py:104} INFO - [2021-04-25 12:35:55,937] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:35:55,970] {logging_mixin.py:104} INFO - [2021-04-25 12:35:55,969] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:35:55,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.072 seconds
[2021-04-25 12:36:26,139] {scheduler_job.py:182} INFO - Started process (PID=552) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:36:26,142] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:36:26,144] {logging_mixin.py:104} INFO - [2021-04-25 12:36:26,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:36:26,956] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:36:27,017] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:36:27,044] {logging_mixin.py:104} INFO - [2021-04-25 12:36:27,043] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:36:27,086] {logging_mixin.py:104} INFO - [2021-04-25 12:36:27,086] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:36:27,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.967 seconds
[2021-04-25 12:36:57,230] {scheduler_job.py:182} INFO - Started process (PID=554) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:36:57,233] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:36:57,238] {logging_mixin.py:104} INFO - [2021-04-25 12:36:57,237] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:36:58,027] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:36:58,082] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:36:58,096] {logging_mixin.py:104} INFO - [2021-04-25 12:36:58,095] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:36:58,115] {logging_mixin.py:104} INFO - [2021-04-25 12:36:58,115] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:36:58,124] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.898 seconds
[2021-04-25 12:37:28,467] {scheduler_job.py:182} INFO - Started process (PID=556) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:37:28,471] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:37:28,475] {logging_mixin.py:104} INFO - [2021-04-25 12:37:28,474] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:37:29,483] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:37:29,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:37:29,534] {logging_mixin.py:104} INFO - [2021-04-25 12:37:29,533] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:37:29,562] {logging_mixin.py:104} INFO - [2021-04-25 12:37:29,561] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:37:29,572] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.110 seconds
[2021-04-25 12:37:59,693] {scheduler_job.py:182} INFO - Started process (PID=558) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:37:59,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:37:59,698] {logging_mixin.py:104} INFO - [2021-04-25 12:37:59,698] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:38:00,451] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:38:00,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:38:00,502] {logging_mixin.py:104} INFO - [2021-04-25 12:38:00,500] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:38:00,522] {logging_mixin.py:104} INFO - [2021-04-25 12:38:00,522] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:38:00,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.845 seconds
[2021-04-25 12:38:30,747] {scheduler_job.py:182} INFO - Started process (PID=560) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:38:30,749] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:38:30,751] {logging_mixin.py:104} INFO - [2021-04-25 12:38:30,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:38:31,634] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:38:31,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:38:31,676] {logging_mixin.py:104} INFO - [2021-04-25 12:38:31,675] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:38:31,696] {logging_mixin.py:104} INFO - [2021-04-25 12:38:31,696] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:38:31,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.966 seconds
[2021-04-25 12:39:01,827] {scheduler_job.py:182} INFO - Started process (PID=562) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:39:01,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:39:01,838] {logging_mixin.py:104} INFO - [2021-04-25 12:39:01,837] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:39:02,762] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:39:02,795] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:39:02,807] {logging_mixin.py:104} INFO - [2021-04-25 12:39:02,806] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:39:02,827] {logging_mixin.py:104} INFO - [2021-04-25 12:39:02,827] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:39:02,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.024 seconds
[2021-04-25 12:39:33,012] {scheduler_job.py:182} INFO - Started process (PID=564) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:39:33,019] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:39:33,021] {logging_mixin.py:104} INFO - [2021-04-25 12:39:33,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:39:33,920] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:39:33,955] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:39:33,971] {logging_mixin.py:104} INFO - [2021-04-25 12:39:33,970] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:39:33,993] {logging_mixin.py:104} INFO - [2021-04-25 12:39:33,993] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:39:34,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.003 seconds
[2021-04-25 12:40:04,189] {scheduler_job.py:182} INFO - Started process (PID=566) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:40:04,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:40:04,211] {logging_mixin.py:104} INFO - [2021-04-25 12:40:04,210] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:40:05,960] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:40:06,040] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:40:06,081] {logging_mixin.py:104} INFO - [2021-04-25 12:40:06,079] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:40:06,121] {logging_mixin.py:104} INFO - [2021-04-25 12:40:06,121] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:40:06,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.962 seconds
[2021-04-25 12:40:36,244] {scheduler_job.py:182} INFO - Started process (PID=568) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:40:36,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:40:36,253] {logging_mixin.py:104} INFO - [2021-04-25 12:40:36,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:40:37,201] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:40:37,287] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:40:37,308] {logging_mixin.py:104} INFO - [2021-04-25 12:40:37,307] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:40:37,357] {logging_mixin.py:104} INFO - [2021-04-25 12:40:37,357] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T10:00:00+00:00
[2021-04-25 12:40:37,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.135 seconds
[2021-04-25 12:41:08,310] {scheduler_job.py:182} INFO - Started process (PID=570) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:41:08,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:41:08,314] {logging_mixin.py:104} INFO - [2021-04-25 12:41:08,314] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:41:09,291] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:41:09,324] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:41:09,336] {logging_mixin.py:104} INFO - [2021-04-25 12:41:09,335] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:41:09,359] {logging_mixin.py:104} INFO - [2021-04-25 12:41:09,358] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:41:09,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.063 seconds
[2021-04-25 12:41:40,172] {scheduler_job.py:182} INFO - Started process (PID=572) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:41:40,175] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:41:40,176] {logging_mixin.py:104} INFO - [2021-04-25 12:41:40,176] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:41:40,864] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:41:40,898] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:41:40,913] {logging_mixin.py:104} INFO - [2021-04-25 12:41:40,911] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:41:40,943] {logging_mixin.py:104} INFO - [2021-04-25 12:41:40,943] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:41:40,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.784 seconds
[2021-04-25 12:42:11,071] {scheduler_job.py:182} INFO - Started process (PID=574) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:42:11,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:42:11,076] {logging_mixin.py:104} INFO - [2021-04-25 12:42:11,076] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:42:11,808] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:42:11,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:42:11,859] {logging_mixin.py:104} INFO - [2021-04-25 12:42:11,857] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:42:11,878] {logging_mixin.py:104} INFO - [2021-04-25 12:42:11,878] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:42:11,888] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.822 seconds
[2021-04-25 12:42:41,991] {scheduler_job.py:182} INFO - Started process (PID=576) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:42:41,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:42:41,995] {logging_mixin.py:104} INFO - [2021-04-25 12:42:41,995] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:42:42,665] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:42:42,698] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:42:42,712] {logging_mixin.py:104} INFO - [2021-04-25 12:42:42,711] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:42:42,729] {logging_mixin.py:104} INFO - [2021-04-25 12:42:42,728] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:42:42,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.752 seconds
[2021-04-25 12:43:13,340] {scheduler_job.py:182} INFO - Started process (PID=578) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:43:13,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:43:13,346] {logging_mixin.py:104} INFO - [2021-04-25 12:43:13,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:43:14,087] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:43:14,117] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:43:14,129] {logging_mixin.py:104} INFO - [2021-04-25 12:43:14,128] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:43:14,148] {logging_mixin.py:104} INFO - [2021-04-25 12:43:14,148] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:43:14,158] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.826 seconds
[2021-04-25 12:43:44,700] {scheduler_job.py:182} INFO - Started process (PID=580) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:43:44,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:43:44,708] {logging_mixin.py:104} INFO - [2021-04-25 12:43:44,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:43:45,813] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:43:45,886] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:43:45,915] {logging_mixin.py:104} INFO - [2021-04-25 12:43:45,914] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:43:45,952] {logging_mixin.py:104} INFO - [2021-04-25 12:43:45,952] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:43:45,971] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.277 seconds
[2021-04-25 12:44:16,076] {scheduler_job.py:182} INFO - Started process (PID=582) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:44:16,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:44:16,084] {logging_mixin.py:104} INFO - [2021-04-25 12:44:16,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:44:17,236] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:44:17,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:44:17,297] {logging_mixin.py:104} INFO - [2021-04-25 12:44:17,296] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:44:17,322] {logging_mixin.py:104} INFO - [2021-04-25 12:44:17,321] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:44:17,333] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.263 seconds
[2021-04-25 12:44:47,513] {scheduler_job.py:182} INFO - Started process (PID=584) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:44:47,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:44:47,520] {logging_mixin.py:104} INFO - [2021-04-25 12:44:47,520] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:44:48,634] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:44:48,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:44:48,708] {logging_mixin.py:104} INFO - [2021-04-25 12:44:48,707] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:44:48,729] {logging_mixin.py:104} INFO - [2021-04-25 12:44:48,729] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:44:48,740] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.232 seconds
[2021-04-25 12:45:18,931] {scheduler_job.py:182} INFO - Started process (PID=586) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:45:18,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:45:18,941] {logging_mixin.py:104} INFO - [2021-04-25 12:45:18,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:45:19,741] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:45:19,769] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:45:19,783] {logging_mixin.py:104} INFO - [2021-04-25 12:45:19,781] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:45:19,799] {logging_mixin.py:104} INFO - [2021-04-25 12:45:19,798] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:45:19,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.893 seconds
[2021-04-25 12:45:49,894] {scheduler_job.py:182} INFO - Started process (PID=588) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:45:49,899] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:45:49,900] {logging_mixin.py:104} INFO - [2021-04-25 12:45:49,900] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:45:50,534] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:45:50,564] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:45:50,577] {logging_mixin.py:104} INFO - [2021-04-25 12:45:50,576] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:45:50,594] {logging_mixin.py:104} INFO - [2021-04-25 12:45:50,593] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:45:50,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.713 seconds
[2021-04-25 12:46:20,801] {scheduler_job.py:182} INFO - Started process (PID=590) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:46:20,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:46:20,806] {logging_mixin.py:104} INFO - [2021-04-25 12:46:20,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:46:21,509] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:46:21,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:46:21,567] {logging_mixin.py:104} INFO - [2021-04-25 12:46:21,566] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:46:21,585] {logging_mixin.py:104} INFO - [2021-04-25 12:46:21,585] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:46:21,594] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.798 seconds
[2021-04-25 12:46:52,454] {scheduler_job.py:182} INFO - Started process (PID=592) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:46:52,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:46:52,463] {logging_mixin.py:104} INFO - [2021-04-25 12:46:52,463] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:46:53,203] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:46:53,238] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:46:53,253] {logging_mixin.py:104} INFO - [2021-04-25 12:46:53,252] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:46:53,272] {logging_mixin.py:104} INFO - [2021-04-25 12:46:53,272] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:46:53,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.836 seconds
[2021-04-25 12:47:23,485] {scheduler_job.py:182} INFO - Started process (PID=594) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:47:23,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:47:23,490] {logging_mixin.py:104} INFO - [2021-04-25 12:47:23,490] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:47:24,143] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:47:24,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:47:24,190] {logging_mixin.py:104} INFO - [2021-04-25 12:47:24,189] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:47:24,209] {logging_mixin.py:104} INFO - [2021-04-25 12:47:24,208] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:47:24,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.772 seconds
[2021-04-25 12:47:54,584] {scheduler_job.py:182} INFO - Started process (PID=596) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:47:54,590] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:47:54,593] {logging_mixin.py:104} INFO - [2021-04-25 12:47:54,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:47:55,416] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:47:55,448] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:47:55,461] {logging_mixin.py:104} INFO - [2021-04-25 12:47:55,460] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:47:55,480] {logging_mixin.py:104} INFO - [2021-04-25 12:47:55,480] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:47:55,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.920 seconds
[2021-04-25 12:48:26,217] {scheduler_job.py:182} INFO - Started process (PID=598) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:48:26,219] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:48:26,221] {logging_mixin.py:104} INFO - [2021-04-25 12:48:26,221] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:48:26,978] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:48:27,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:48:27,021] {logging_mixin.py:104} INFO - [2021-04-25 12:48:27,020] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:48:27,039] {logging_mixin.py:104} INFO - [2021-04-25 12:48:27,039] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:48:27,050] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.838 seconds
[2021-04-25 12:48:57,526] {scheduler_job.py:182} INFO - Started process (PID=600) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:48:57,529] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:48:57,534] {logging_mixin.py:104} INFO - [2021-04-25 12:48:57,531] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:48:58,295] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:48:58,351] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:48:58,368] {logging_mixin.py:104} INFO - [2021-04-25 12:48:58,366] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:48:58,388] {logging_mixin.py:104} INFO - [2021-04-25 12:48:58,388] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:48:58,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.875 seconds
[2021-04-25 12:49:28,828] {scheduler_job.py:182} INFO - Started process (PID=602) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:49:28,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:49:28,833] {logging_mixin.py:104} INFO - [2021-04-25 12:49:28,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:49:29,587] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:49:29,621] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:49:29,635] {logging_mixin.py:104} INFO - [2021-04-25 12:49:29,634] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:49:29,656] {logging_mixin.py:104} INFO - [2021-04-25 12:49:29,656] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:49:29,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.841 seconds
[2021-04-25 12:49:59,789] {scheduler_job.py:182} INFO - Started process (PID=604) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:49:59,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:49:59,794] {logging_mixin.py:104} INFO - [2021-04-25 12:49:59,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:50:00,666] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:50:00,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:50:00,716] {logging_mixin.py:104} INFO - [2021-04-25 12:50:00,715] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:50:00,733] {logging_mixin.py:104} INFO - [2021-04-25 12:50:00,733] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:50:00,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.960 seconds
[2021-04-25 12:50:30,957] {scheduler_job.py:182} INFO - Started process (PID=606) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:50:30,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:50:30,964] {logging_mixin.py:104} INFO - [2021-04-25 12:50:30,964] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:50:31,693] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:50:31,725] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:50:31,738] {logging_mixin.py:104} INFO - [2021-04-25 12:50:31,737] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:50:31,756] {logging_mixin.py:104} INFO - [2021-04-25 12:50:31,756] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T11:00:00+00:00
[2021-04-25 12:50:31,768] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.816 seconds
[2021-04-25 12:51:01,858] {scheduler_job.py:182} INFO - Started process (PID=608) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:51:01,864] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:51:01,867] {logging_mixin.py:104} INFO - [2021-04-25 12:51:01,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:51:02,506] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:51:02,548] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:51:02,562] {logging_mixin.py:104} INFO - [2021-04-25 12:51:02,561] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:51:02,580] {logging_mixin.py:104} INFO - [2021-04-25 12:51:02,580] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:51:02,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-25 12:51:32,667] {scheduler_job.py:182} INFO - Started process (PID=610) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:51:32,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:51:32,671] {logging_mixin.py:104} INFO - [2021-04-25 12:51:32,671] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:51:33,276] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:51:33,307] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:51:33,319] {logging_mixin.py:104} INFO - [2021-04-25 12:51:33,318] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:51:33,335] {logging_mixin.py:104} INFO - [2021-04-25 12:51:33,335] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:51:33,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.681 seconds
[2021-04-25 12:52:03,755] {scheduler_job.py:182} INFO - Started process (PID=612) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:52:03,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:52:03,760] {logging_mixin.py:104} INFO - [2021-04-25 12:52:03,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:52:04,467] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:52:04,505] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:52:04,520] {logging_mixin.py:104} INFO - [2021-04-25 12:52:04,519] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:52:04,539] {logging_mixin.py:104} INFO - [2021-04-25 12:52:04,539] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:52:04,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.798 seconds
[2021-04-25 12:52:34,652] {scheduler_job.py:182} INFO - Started process (PID=614) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:52:34,657] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:52:34,659] {logging_mixin.py:104} INFO - [2021-04-25 12:52:34,659] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:52:35,567] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:52:35,605] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:52:35,623] {logging_mixin.py:104} INFO - [2021-04-25 12:52:35,622] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:52:35,647] {logging_mixin.py:104} INFO - [2021-04-25 12:52:35,647] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:52:35,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.013 seconds
[2021-04-25 12:53:05,741] {scheduler_job.py:182} INFO - Started process (PID=616) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:53:05,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:53:05,748] {logging_mixin.py:104} INFO - [2021-04-25 12:53:05,748] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:53:06,393] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:53:06,424] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:53:06,436] {logging_mixin.py:104} INFO - [2021-04-25 12:53:06,435] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:53:06,453] {logging_mixin.py:104} INFO - [2021-04-25 12:53:06,453] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:53:06,462] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.725 seconds
[2021-04-25 12:53:36,827] {scheduler_job.py:182} INFO - Started process (PID=618) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:53:36,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:53:36,832] {logging_mixin.py:104} INFO - [2021-04-25 12:53:36,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:53:37,485] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:53:37,517] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:53:37,535] {logging_mixin.py:104} INFO - [2021-04-25 12:53:37,534] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:53:37,557] {logging_mixin.py:104} INFO - [2021-04-25 12:53:37,557] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:53:37,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.752 seconds
[2021-04-25 12:54:08,040] {scheduler_job.py:182} INFO - Started process (PID=620) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:54:08,042] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:54:08,044] {logging_mixin.py:104} INFO - [2021-04-25 12:54:08,043] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:54:08,838] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:54:08,881] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:54:08,898] {logging_mixin.py:104} INFO - [2021-04-25 12:54:08,896] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:54:08,928] {logging_mixin.py:104} INFO - [2021-04-25 12:54:08,928] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:54:08,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.905 seconds
[2021-04-25 12:54:39,435] {scheduler_job.py:182} INFO - Started process (PID=622) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:54:39,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:54:39,441] {logging_mixin.py:104} INFO - [2021-04-25 12:54:39,441] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:54:40,509] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:54:40,562] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:54:40,585] {logging_mixin.py:104} INFO - [2021-04-25 12:54:40,584] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:54:40,609] {logging_mixin.py:104} INFO - [2021-04-25 12:54:40,609] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:54:40,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.193 seconds
[2021-04-25 12:55:10,884] {scheduler_job.py:182} INFO - Started process (PID=624) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:55:10,887] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:55:10,889] {logging_mixin.py:104} INFO - [2021-04-25 12:55:10,889] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:55:11,609] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:55:11,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:55:11,650] {logging_mixin.py:104} INFO - [2021-04-25 12:55:11,649] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:55:11,666] {logging_mixin.py:104} INFO - [2021-04-25 12:55:11,666] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:55:11,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.794 seconds
[2021-04-25 12:55:41,788] {scheduler_job.py:182} INFO - Started process (PID=626) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:55:41,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:55:41,794] {logging_mixin.py:104} INFO - [2021-04-25 12:55:41,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:55:42,517] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:55:42,545] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:55:42,557] {logging_mixin.py:104} INFO - [2021-04-25 12:55:42,556] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:55:42,575] {logging_mixin.py:104} INFO - [2021-04-25 12:55:42,574] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:55:42,583] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.799 seconds
[2021-04-25 12:56:12,738] {scheduler_job.py:182} INFO - Started process (PID=628) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:56:12,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:56:12,749] {logging_mixin.py:104} INFO - [2021-04-25 12:56:12,749] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:56:13,647] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:56:13,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:56:13,697] {logging_mixin.py:104} INFO - [2021-04-25 12:56:13,696] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:56:13,718] {logging_mixin.py:104} INFO - [2021-04-25 12:56:13,718] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:56:13,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.014 seconds
[2021-04-25 12:56:43,868] {scheduler_job.py:182} INFO - Started process (PID=630) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:56:43,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:56:43,879] {logging_mixin.py:104} INFO - [2021-04-25 12:56:43,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:56:44,675] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:56:44,715] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:56:44,729] {logging_mixin.py:104} INFO - [2021-04-25 12:56:44,727] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:56:44,745] {logging_mixin.py:104} INFO - [2021-04-25 12:56:44,745] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:56:44,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.892 seconds
[2021-04-25 12:57:14,931] {scheduler_job.py:182} INFO - Started process (PID=632) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:57:14,934] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:57:14,936] {logging_mixin.py:104} INFO - [2021-04-25 12:57:14,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:57:15,866] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:57:15,935] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:57:15,956] {logging_mixin.py:104} INFO - [2021-04-25 12:57:15,955] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:57:15,992] {logging_mixin.py:104} INFO - [2021-04-25 12:57:15,991] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:57:16,008] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.081 seconds
[2021-04-25 12:57:47,047] {scheduler_job.py:182} INFO - Started process (PID=634) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:57:47,049] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:57:47,051] {logging_mixin.py:104} INFO - [2021-04-25 12:57:47,051] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:57:47,691] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:57:47,729] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:57:47,740] {logging_mixin.py:104} INFO - [2021-04-25 12:57:47,739] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:57:47,763] {logging_mixin.py:104} INFO - [2021-04-25 12:57:47,763] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:57:47,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.731 seconds
[2021-04-25 12:58:17,923] {scheduler_job.py:182} INFO - Started process (PID=636) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:58:17,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:58:17,944] {logging_mixin.py:104} INFO - [2021-04-25 12:58:17,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:58:19,850] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:58:19,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:58:19,979] {logging_mixin.py:104} INFO - [2021-04-25 12:58:19,976] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:58:20,078] {logging_mixin.py:104} INFO - [2021-04-25 12:58:20,076] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:58:20,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.256 seconds
[2021-04-25 12:58:51,440] {scheduler_job.py:182} INFO - Started process (PID=638) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:58:51,446] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:58:51,452] {logging_mixin.py:104} INFO - [2021-04-25 12:58:51,452] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:58:52,731] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:58:52,787] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:58:52,823] {logging_mixin.py:104} INFO - [2021-04-25 12:58:52,820] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:58:52,887] {logging_mixin.py:104} INFO - [2021-04-25 12:58:52,886] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:58:52,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.488 seconds
[2021-04-25 12:59:23,077] {scheduler_job.py:182} INFO - Started process (PID=640) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:59:23,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:59:23,082] {logging_mixin.py:104} INFO - [2021-04-25 12:59:23,082] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:59:23,662] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:59:23,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:59:23,702] {logging_mixin.py:104} INFO - [2021-04-25 12:59:23,701] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:59:23,719] {logging_mixin.py:104} INFO - [2021-04-25 12:59:23,719] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:59:23,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.685 seconds
[2021-04-25 12:59:53,832] {scheduler_job.py:182} INFO - Started process (PID=642) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:59:53,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 12:59:53,837] {logging_mixin.py:104} INFO - [2021-04-25 12:59:53,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:59:54,494] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 12:59:54,534] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 12:59:54,552] {logging_mixin.py:104} INFO - [2021-04-25 12:59:54,551] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 12:59:54,570] {logging_mixin.py:104} INFO - [2021-04-25 12:59:54,570] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T12:00:00+00:00
[2021-04-25 12:59:54,580] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.753 seconds
[2021-04-25 13:00:24,668] {scheduler_job.py:182} INFO - Started process (PID=644) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:00:24,672] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:00:24,674] {logging_mixin.py:104} INFO - [2021-04-25 13:00:24,674] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:00:25,356] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:00:25,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:00:25,412] {logging_mixin.py:104} INFO - [2021-04-25 13:00:25,411] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:00:25,433] {logging_mixin.py:104} INFO - [2021-04-25 13:00:25,433] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:00:25,444] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.782 seconds
[2021-04-25 13:00:55,761] {scheduler_job.py:182} INFO - Started process (PID=646) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:00:55,768] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:00:55,773] {logging_mixin.py:104} INFO - [2021-04-25 13:00:55,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:00:56,605] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:00:56,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:00:56,654] {logging_mixin.py:104} INFO - [2021-04-25 13:00:56,653] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:00:56,671] {logging_mixin.py:104} INFO - [2021-04-25 13:00:56,671] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:00:56,680] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.930 seconds
[2021-04-25 13:01:26,785] {scheduler_job.py:182} INFO - Started process (PID=648) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:01:26,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:01:26,790] {logging_mixin.py:104} INFO - [2021-04-25 13:01:26,790] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:01:27,493] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:01:27,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:01:27,537] {logging_mixin.py:104} INFO - [2021-04-25 13:01:27,535] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:01:27,555] {logging_mixin.py:104} INFO - [2021-04-25 13:01:27,555] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:01:27,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.786 seconds
[2021-04-25 13:01:57,934] {scheduler_job.py:182} INFO - Started process (PID=650) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:01:57,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:01:57,956] {logging_mixin.py:104} INFO - [2021-04-25 13:01:57,956] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:02:00,722] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:02:00,777] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:02:00,800] {logging_mixin.py:104} INFO - [2021-04-25 13:02:00,798] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:02:00,844] {logging_mixin.py:104} INFO - [2021-04-25 13:02:00,844] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:02:00,873] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.962 seconds
[2021-04-25 13:02:31,083] {scheduler_job.py:182} INFO - Started process (PID=652) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:02:31,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:02:31,088] {logging_mixin.py:104} INFO - [2021-04-25 13:02:31,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:02:32,251] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:02:32,308] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:02:32,338] {logging_mixin.py:104} INFO - [2021-04-25 13:02:32,335] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:02:32,384] {logging_mixin.py:104} INFO - [2021-04-25 13:02:32,384] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:02:32,397] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.319 seconds
[2021-04-25 13:03:02,483] {scheduler_job.py:182} INFO - Started process (PID=654) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:03:02,486] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:03:02,487] {logging_mixin.py:104} INFO - [2021-04-25 13:03:02,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:03:03,216] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:03:03,249] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:03:03,264] {logging_mixin.py:104} INFO - [2021-04-25 13:03:03,263] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:03:03,289] {logging_mixin.py:104} INFO - [2021-04-25 13:03:03,289] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:03:03,301] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.821 seconds
[2021-04-25 13:03:33,342] {scheduler_job.py:182} INFO - Started process (PID=656) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:03:33,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:03:33,346] {logging_mixin.py:104} INFO - [2021-04-25 13:03:33,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:03:34,221] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:03:34,255] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:03:34,270] {logging_mixin.py:104} INFO - [2021-04-25 13:03:34,269] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:03:34,292] {logging_mixin.py:104} INFO - [2021-04-25 13:03:34,292] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:03:34,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.967 seconds
[2021-04-25 13:04:05,013] {scheduler_job.py:182} INFO - Started process (PID=658) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:04:05,016] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:04:05,017] {logging_mixin.py:104} INFO - [2021-04-25 13:04:05,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:04:05,705] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:04:05,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:04:05,765] {logging_mixin.py:104} INFO - [2021-04-25 13:04:05,764] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:04:05,789] {logging_mixin.py:104} INFO - [2021-04-25 13:04:05,789] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:04:05,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-25 13:04:36,210] {scheduler_job.py:182} INFO - Started process (PID=660) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:04:36,214] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:04:36,215] {logging_mixin.py:104} INFO - [2021-04-25 13:04:36,215] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:04:36,975] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:04:37,009] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:04:37,020] {logging_mixin.py:104} INFO - [2021-04-25 13:04:37,019] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:04:37,039] {logging_mixin.py:104} INFO - [2021-04-25 13:04:37,039] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:04:37,050] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.845 seconds
[2021-04-25 13:05:07,604] {scheduler_job.py:182} INFO - Started process (PID=662) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:05:07,613] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:05:07,616] {logging_mixin.py:104} INFO - [2021-04-25 13:05:07,616] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:05:08,406] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:05:08,437] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:05:08,449] {logging_mixin.py:104} INFO - [2021-04-25 13:05:08,448] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:05:08,468] {logging_mixin.py:104} INFO - [2021-04-25 13:05:08,467] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:05:08,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.883 seconds
[2021-04-25 13:05:38,603] {scheduler_job.py:182} INFO - Started process (PID=664) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:05:38,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:05:38,613] {logging_mixin.py:104} INFO - [2021-04-25 13:05:38,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:05:39,826] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:05:39,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:05:39,884] {logging_mixin.py:104} INFO - [2021-04-25 13:05:39,883] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:05:39,912] {logging_mixin.py:104} INFO - [2021-04-25 13:05:39,912] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:05:39,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.346 seconds
[2021-04-25 13:06:10,026] {scheduler_job.py:182} INFO - Started process (PID=666) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:06:10,031] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:06:10,034] {logging_mixin.py:104} INFO - [2021-04-25 13:06:10,034] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:06:10,809] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:06:10,838] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:06:10,850] {logging_mixin.py:104} INFO - [2021-04-25 13:06:10,849] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:06:10,873] {logging_mixin.py:104} INFO - [2021-04-25 13:06:10,873] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:06:10,882] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.861 seconds
[2021-04-25 13:06:41,059] {scheduler_job.py:182} INFO - Started process (PID=668) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:06:41,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:06:41,067] {logging_mixin.py:104} INFO - [2021-04-25 13:06:41,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:06:42,098] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:06:42,132] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:06:42,147] {logging_mixin.py:104} INFO - [2021-04-25 13:06:42,145] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:06:42,168] {logging_mixin.py:104} INFO - [2021-04-25 13:06:42,167] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:06:42,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.127 seconds
[2021-04-25 13:07:12,269] {scheduler_job.py:182} INFO - Started process (PID=670) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:07:12,272] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:07:12,273] {logging_mixin.py:104} INFO - [2021-04-25 13:07:12,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:07:12,989] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:07:13,018] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:07:13,031] {logging_mixin.py:104} INFO - [2021-04-25 13:07:13,029] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:07:13,051] {logging_mixin.py:104} INFO - [2021-04-25 13:07:13,051] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:07:13,058] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-25 13:07:43,169] {scheduler_job.py:182} INFO - Started process (PID=672) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:07:43,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:07:43,175] {logging_mixin.py:104} INFO - [2021-04-25 13:07:43,175] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:07:43,986] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:07:44,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:07:44,055] {logging_mixin.py:104} INFO - [2021-04-25 13:07:44,053] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:07:44,081] {logging_mixin.py:104} INFO - [2021-04-25 13:07:44,081] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:07:44,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.929 seconds
[2021-04-25 13:08:14,214] {scheduler_job.py:182} INFO - Started process (PID=674) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:08:14,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:08:14,219] {logging_mixin.py:104} INFO - [2021-04-25 13:08:14,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:08:15,135] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:08:15,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:08:15,289] {logging_mixin.py:104} INFO - [2021-04-25 13:08:15,283] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:08:15,345] {logging_mixin.py:104} INFO - [2021-04-25 13:08:15,344] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:08:15,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.164 seconds
[2021-04-25 13:08:45,512] {scheduler_job.py:182} INFO - Started process (PID=676) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:08:45,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:08:45,529] {logging_mixin.py:104} INFO - [2021-04-25 13:08:45,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:08:46,606] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:08:46,690] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:08:46,724] {logging_mixin.py:104} INFO - [2021-04-25 13:08:46,721] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:08:46,756] {logging_mixin.py:104} INFO - [2021-04-25 13:08:46,756] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:08:46,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.264 seconds
[2021-04-25 13:09:16,915] {scheduler_job.py:182} INFO - Started process (PID=678) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:09:16,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:09:16,921] {logging_mixin.py:104} INFO - [2021-04-25 13:09:16,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:09:17,661] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:09:17,689] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:09:17,702] {logging_mixin.py:104} INFO - [2021-04-25 13:09:17,701] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:09:17,719] {logging_mixin.py:104} INFO - [2021-04-25 13:09:17,719] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:09:17,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.817 seconds
[2021-04-25 13:09:47,800] {scheduler_job.py:182} INFO - Started process (PID=680) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:09:47,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:09:47,804] {logging_mixin.py:104} INFO - [2021-04-25 13:09:47,804] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:09:48,420] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:09:48,450] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:09:48,463] {logging_mixin.py:104} INFO - [2021-04-25 13:09:48,462] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:09:48,479] {logging_mixin.py:104} INFO - [2021-04-25 13:09:48,479] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:09:48,488] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.693 seconds
[2021-04-25 13:10:18,580] {scheduler_job.py:182} INFO - Started process (PID=682) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:10:18,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:10:18,588] {logging_mixin.py:104} INFO - [2021-04-25 13:10:18,588] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:10:19,252] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:10:19,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:10:19,295] {logging_mixin.py:104} INFO - [2021-04-25 13:10:19,294] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:10:19,314] {logging_mixin.py:104} INFO - [2021-04-25 13:10:19,314] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:10:19,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.750 seconds
[2021-04-25 13:10:49,845] {scheduler_job.py:182} INFO - Started process (PID=684) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:10:49,849] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:10:49,851] {logging_mixin.py:104} INFO - [2021-04-25 13:10:49,850] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:10:50,513] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:10:50,544] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:10:50,557] {logging_mixin.py:104} INFO - [2021-04-25 13:10:50,556] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:10:50,575] {logging_mixin.py:104} INFO - [2021-04-25 13:10:50,575] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:10:50,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.746 seconds
[2021-04-25 13:11:20,684] {scheduler_job.py:182} INFO - Started process (PID=686) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:11:20,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:11:20,689] {logging_mixin.py:104} INFO - [2021-04-25 13:11:20,689] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:11:21,463] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:11:21,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:11:21,530] {logging_mixin.py:104} INFO - [2021-04-25 13:11:21,528] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:11:21,564] {logging_mixin.py:104} INFO - [2021-04-25 13:11:21,564] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:11:21,578] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.899 seconds
[2021-04-25 13:11:52,227] {scheduler_job.py:182} INFO - Started process (PID=688) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:11:52,231] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:11:52,233] {logging_mixin.py:104} INFO - [2021-04-25 13:11:52,233] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:11:52,825] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:11:52,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:11:52,871] {logging_mixin.py:104} INFO - [2021-04-25 13:11:52,870] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:11:52,889] {logging_mixin.py:104} INFO - [2021-04-25 13:11:52,889] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:11:52,900] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.713 seconds
[2021-04-25 13:12:23,027] {scheduler_job.py:182} INFO - Started process (PID=690) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:12:23,030] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:12:23,032] {logging_mixin.py:104} INFO - [2021-04-25 13:12:23,031] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:12:23,789] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:12:23,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:12:23,864] {logging_mixin.py:104} INFO - [2021-04-25 13:12:23,863] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:12:23,882] {logging_mixin.py:104} INFO - [2021-04-25 13:12:23,882] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:12:23,895] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.872 seconds
[2021-04-25 13:12:53,973] {scheduler_job.py:182} INFO - Started process (PID=692) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:12:53,977] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:12:53,978] {logging_mixin.py:104} INFO - [2021-04-25 13:12:53,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:12:54,562] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:12:54,593] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:12:54,606] {logging_mixin.py:104} INFO - [2021-04-25 13:12:54,606] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:12:54,623] {logging_mixin.py:104} INFO - [2021-04-25 13:12:54,623] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:12:54,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.662 seconds
[2021-04-25 13:13:24,757] {scheduler_job.py:182} INFO - Started process (PID=694) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:13:24,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:13:24,762] {logging_mixin.py:104} INFO - [2021-04-25 13:13:24,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:13:25,360] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:13:25,393] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:13:25,409] {logging_mixin.py:104} INFO - [2021-04-25 13:13:25,408] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:13:25,431] {logging_mixin.py:104} INFO - [2021-04-25 13:13:25,431] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:13:25,445] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.692 seconds
[2021-04-25 13:13:56,150] {scheduler_job.py:182} INFO - Started process (PID=696) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:13:56,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:13:56,155] {logging_mixin.py:104} INFO - [2021-04-25 13:13:56,155] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:13:56,815] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:13:56,842] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:13:56,857] {logging_mixin.py:104} INFO - [2021-04-25 13:13:56,855] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:13:56,882] {logging_mixin.py:104} INFO - [2021-04-25 13:13:56,881] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:13:56,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.758 seconds
[2021-04-25 13:14:27,078] {scheduler_job.py:182} INFO - Started process (PID=698) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:14:27,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:14:27,083] {logging_mixin.py:104} INFO - [2021-04-25 13:14:27,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:14:27,681] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:14:27,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:14:27,735] {logging_mixin.py:104} INFO - [2021-04-25 13:14:27,734] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:14:27,754] {logging_mixin.py:104} INFO - [2021-04-25 13:14:27,754] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:14:27,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.689 seconds
[2021-04-25 13:14:58,009] {scheduler_job.py:182} INFO - Started process (PID=700) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:14:58,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:14:58,014] {logging_mixin.py:104} INFO - [2021-04-25 13:14:58,014] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:14:58,724] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:14:58,757] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:14:58,770] {logging_mixin.py:104} INFO - [2021-04-25 13:14:58,769] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:14:58,792] {logging_mixin.py:104} INFO - [2021-04-25 13:14:58,792] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:14:58,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.802 seconds
[2021-04-25 13:15:28,894] {scheduler_job.py:182} INFO - Started process (PID=702) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:15:28,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:15:28,903] {logging_mixin.py:104} INFO - [2021-04-25 13:15:28,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:15:29,891] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:15:29,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:15:29,935] {logging_mixin.py:104} INFO - [2021-04-25 13:15:29,934] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:15:29,954] {logging_mixin.py:104} INFO - [2021-04-25 13:15:29,954] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:15:29,963] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.076 seconds
[2021-04-25 13:16:00,112] {scheduler_job.py:182} INFO - Started process (PID=704) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:16:00,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:16:00,136] {logging_mixin.py:104} INFO - [2021-04-25 13:16:00,128] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:16:02,282] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:16:02,345] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:16:02,372] {logging_mixin.py:104} INFO - [2021-04-25 13:16:02,370] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:16:02,403] {logging_mixin.py:104} INFO - [2021-04-25 13:16:02,402] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:16:02,415] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.327 seconds
[2021-04-25 13:16:32,516] {scheduler_job.py:182} INFO - Started process (PID=706) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:16:32,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:16:32,521] {logging_mixin.py:104} INFO - [2021-04-25 13:16:32,521] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:16:33,206] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:16:33,243] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:16:33,261] {logging_mixin.py:104} INFO - [2021-04-25 13:16:33,259] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:16:33,281] {logging_mixin.py:104} INFO - [2021-04-25 13:16:33,281] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:16:33,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.781 seconds
[2021-04-25 13:17:03,392] {scheduler_job.py:182} INFO - Started process (PID=708) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:17:03,395] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:17:03,397] {logging_mixin.py:104} INFO - [2021-04-25 13:17:03,397] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:17:04,568] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:17:04,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:17:04,671] {logging_mixin.py:104} INFO - [2021-04-25 13:17:04,669] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:17:04,699] {logging_mixin.py:104} INFO - [2021-04-25 13:17:04,698] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:17:04,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.324 seconds
[2021-04-25 13:17:36,543] {scheduler_job.py:182} INFO - Started process (PID=710) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:17:36,591] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:17:36,680] {logging_mixin.py:104} INFO - [2021-04-25 13:17:36,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:17:41,069] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:17:41,138] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:17:41,167] {logging_mixin.py:104} INFO - [2021-04-25 13:17:41,165] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:17:41,251] {logging_mixin.py:104} INFO - [2021-04-25 13:17:41,251] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:17:41,281] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.775 seconds
[2021-04-25 13:18:11,479] {scheduler_job.py:182} INFO - Started process (PID=712) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:18:11,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:18:11,502] {logging_mixin.py:104} INFO - [2021-04-25 13:18:11,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:18:12,452] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:18:12,529] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:18:12,547] {logging_mixin.py:104} INFO - [2021-04-25 13:18:12,546] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:18:12,574] {logging_mixin.py:104} INFO - [2021-04-25 13:18:12,573] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:18:12,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.117 seconds
[2021-04-25 13:18:42,689] {scheduler_job.py:182} INFO - Started process (PID=714) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:18:42,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:18:42,694] {logging_mixin.py:104} INFO - [2021-04-25 13:18:42,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:18:43,340] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:18:43,377] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:18:43,397] {logging_mixin.py:104} INFO - [2021-04-25 13:18:43,395] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:18:43,419] {logging_mixin.py:104} INFO - [2021-04-25 13:18:43,419] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:18:43,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.744 seconds
[2021-04-25 13:19:13,578] {scheduler_job.py:182} INFO - Started process (PID=716) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:19:13,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:19:13,590] {logging_mixin.py:104} INFO - [2021-04-25 13:19:13,590] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:19:14,509] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:19:14,551] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:19:14,572] {logging_mixin.py:104} INFO - [2021-04-25 13:19:14,570] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:19:14,594] {logging_mixin.py:104} INFO - [2021-04-25 13:19:14,594] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:19:14,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.042 seconds
[2021-04-25 13:19:44,928] {scheduler_job.py:182} INFO - Started process (PID=718) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:19:44,930] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:19:44,932] {logging_mixin.py:104} INFO - [2021-04-25 13:19:44,932] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:19:45,828] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:19:45,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:19:45,894] {logging_mixin.py:104} INFO - [2021-04-25 13:19:45,892] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:19:45,919] {logging_mixin.py:104} INFO - [2021-04-25 13:19:45,919] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:19:45,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.007 seconds
[2021-04-25 13:20:16,107] {scheduler_job.py:182} INFO - Started process (PID=720) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:20:16,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:20:16,115] {logging_mixin.py:104} INFO - [2021-04-25 13:20:16,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:20:16,945] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:20:16,987] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:20:16,999] {logging_mixin.py:104} INFO - [2021-04-25 13:20:16,998] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:20:17,018] {logging_mixin.py:104} INFO - [2021-04-25 13:20:17,018] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:20:17,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.927 seconds
[2021-04-25 13:20:47,131] {scheduler_job.py:182} INFO - Started process (PID=722) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:20:47,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:20:47,135] {logging_mixin.py:104} INFO - [2021-04-25 13:20:47,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:20:47,776] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:20:47,824] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:20:47,845] {logging_mixin.py:104} INFO - [2021-04-25 13:20:47,843] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:20:47,874] {logging_mixin.py:104} INFO - [2021-04-25 13:20:47,873] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:20:47,886] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.759 seconds
[2021-04-25 13:21:17,970] {scheduler_job.py:182} INFO - Started process (PID=724) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:21:17,975] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:21:17,977] {logging_mixin.py:104} INFO - [2021-04-25 13:21:17,977] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:21:18,596] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:21:18,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:21:18,651] {logging_mixin.py:104} INFO - [2021-04-25 13:21:18,649] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:21:18,669] {logging_mixin.py:104} INFO - [2021-04-25 13:21:18,669] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:21:18,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.715 seconds
[2021-04-25 13:21:48,830] {scheduler_job.py:182} INFO - Started process (PID=726) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:21:48,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:21:48,834] {logging_mixin.py:104} INFO - [2021-04-25 13:21:48,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:21:49,482] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:21:49,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:21:49,535] {logging_mixin.py:104} INFO - [2021-04-25 13:21:49,534] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:21:49,551] {logging_mixin.py:104} INFO - [2021-04-25 13:21:49,551] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:21:49,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.735 seconds
[2021-04-25 13:22:19,650] {scheduler_job.py:182} INFO - Started process (PID=728) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:22:19,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:22:19,655] {logging_mixin.py:104} INFO - [2021-04-25 13:22:19,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:22:20,280] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:22:20,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:22:20,326] {logging_mixin.py:104} INFO - [2021-04-25 13:22:20,324] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:22:20,342] {logging_mixin.py:104} INFO - [2021-04-25 13:22:20,341] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:22:20,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.710 seconds
[2021-04-25 13:22:50,426] {scheduler_job.py:182} INFO - Started process (PID=730) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:22:50,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:22:50,431] {logging_mixin.py:104} INFO - [2021-04-25 13:22:50,430] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:22:51,042] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:22:51,088] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:22:51,106] {logging_mixin.py:104} INFO - [2021-04-25 13:22:51,105] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:22:51,124] {logging_mixin.py:104} INFO - [2021-04-25 13:22:51,124] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:22:51,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.714 seconds
[2021-04-25 13:23:21,261] {scheduler_job.py:182} INFO - Started process (PID=732) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:23:21,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:23:21,269] {logging_mixin.py:104} INFO - [2021-04-25 13:23:21,269] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:23:22,325] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:23:22,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:23:22,392] {logging_mixin.py:104} INFO - [2021-04-25 13:23:22,390] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:23:22,417] {logging_mixin.py:104} INFO - [2021-04-25 13:23:22,416] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:23:22,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.204 seconds
[2021-04-25 13:23:52,515] {scheduler_job.py:182} INFO - Started process (PID=734) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:23:52,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:23:52,519] {logging_mixin.py:104} INFO - [2021-04-25 13:23:52,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:23:53,307] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:23:53,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:23:53,344] {logging_mixin.py:104} INFO - [2021-04-25 13:23:53,343] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:23:53,359] {logging_mixin.py:104} INFO - [2021-04-25 13:23:53,359] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:23:53,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.860 seconds
[2021-04-25 13:24:23,448] {scheduler_job.py:182} INFO - Started process (PID=736) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:24:23,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:24:23,452] {logging_mixin.py:104} INFO - [2021-04-25 13:24:23,452] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:24:24,221] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:24:24,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:24:24,277] {logging_mixin.py:104} INFO - [2021-04-25 13:24:24,276] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:24:24,298] {logging_mixin.py:104} INFO - [2021-04-25 13:24:24,297] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:24:24,306] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.863 seconds
[2021-04-25 13:24:54,411] {scheduler_job.py:182} INFO - Started process (PID=738) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:24:54,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:24:54,416] {logging_mixin.py:104} INFO - [2021-04-25 13:24:54,416] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:24:55,257] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:24:55,291] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:24:55,315] {logging_mixin.py:104} INFO - [2021-04-25 13:24:55,314] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:24:55,338] {logging_mixin.py:104} INFO - [2021-04-25 13:24:55,338] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:24:55,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.946 seconds
[2021-04-25 13:25:25,512] {scheduler_job.py:182} INFO - Started process (PID=740) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:25:25,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:25:25,522] {logging_mixin.py:104} INFO - [2021-04-25 13:25:25,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:25:26,526] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:25:26,564] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:25:26,584] {logging_mixin.py:104} INFO - [2021-04-25 13:25:26,582] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:25:26,608] {logging_mixin.py:104} INFO - [2021-04-25 13:25:26,607] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:25:26,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.115 seconds
[2021-04-25 13:25:56,748] {scheduler_job.py:182} INFO - Started process (PID=742) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:25:56,755] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:25:56,761] {logging_mixin.py:104} INFO - [2021-04-25 13:25:56,761] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:25:57,656] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:25:57,688] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:25:57,705] {logging_mixin.py:104} INFO - [2021-04-25 13:25:57,704] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:25:57,723] {logging_mixin.py:104} INFO - [2021-04-25 13:25:57,723] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:25:57,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.006 seconds
[2021-04-25 13:26:28,270] {scheduler_job.py:182} INFO - Started process (PID=744) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:26:28,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:26:28,280] {logging_mixin.py:104} INFO - [2021-04-25 13:26:28,279] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:26:29,736] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:26:29,806] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:26:29,825] {logging_mixin.py:104} INFO - [2021-04-25 13:26:29,823] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:26:29,846] {logging_mixin.py:104} INFO - [2021-04-25 13:26:29,846] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:26:29,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.605 seconds
[2021-04-25 13:27:00,038] {scheduler_job.py:182} INFO - Started process (PID=746) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:27:00,042] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:27:00,044] {logging_mixin.py:104} INFO - [2021-04-25 13:27:00,044] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:27:00,729] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:27:00,764] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:27:00,782] {logging_mixin.py:104} INFO - [2021-04-25 13:27:00,780] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:27:00,807] {logging_mixin.py:104} INFO - [2021-04-25 13:27:00,807] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:27:00,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.789 seconds
[2021-04-25 13:27:31,346] {scheduler_job.py:182} INFO - Started process (PID=748) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:27:31,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:27:31,360] {logging_mixin.py:104} INFO - [2021-04-25 13:27:31,359] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:27:32,828] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:27:32,893] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:27:32,934] {logging_mixin.py:104} INFO - [2021-04-25 13:27:32,927] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:27:32,977] {logging_mixin.py:104} INFO - [2021-04-25 13:27:32,977] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:27:33,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.674 seconds
[2021-04-25 13:28:03,184] {scheduler_job.py:182} INFO - Started process (PID=750) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:28:03,187] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:28:03,189] {logging_mixin.py:104} INFO - [2021-04-25 13:28:03,189] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:28:03,987] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:28:04,022] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:28:04,040] {logging_mixin.py:104} INFO - [2021-04-25 13:28:04,039] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:28:04,061] {logging_mixin.py:104} INFO - [2021-04-25 13:28:04,061] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:28:04,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.892 seconds
[2021-04-25 13:28:34,304] {scheduler_job.py:182} INFO - Started process (PID=752) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:28:34,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:28:34,309] {logging_mixin.py:104} INFO - [2021-04-25 13:28:34,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:28:34,995] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:28:35,026] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:28:35,037] {logging_mixin.py:104} INFO - [2021-04-25 13:28:35,036] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:28:35,054] {logging_mixin.py:104} INFO - [2021-04-25 13:28:35,054] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:28:35,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.762 seconds
[2021-04-25 13:29:05,159] {scheduler_job.py:182} INFO - Started process (PID=754) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:29:05,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:29:05,165] {logging_mixin.py:104} INFO - [2021-04-25 13:29:05,165] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:29:05,852] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:29:05,882] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:29:05,899] {logging_mixin.py:104} INFO - [2021-04-25 13:29:05,898] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:29:05,922] {logging_mixin.py:104} INFO - [2021-04-25 13:29:05,922] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:29:05,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.778 seconds
[2021-04-25 13:29:36,026] {scheduler_job.py:182} INFO - Started process (PID=756) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:29:36,029] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:29:36,031] {logging_mixin.py:104} INFO - [2021-04-25 13:29:36,031] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:29:36,787] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:29:36,821] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:29:36,833] {logging_mixin.py:104} INFO - [2021-04-25 13:29:36,832] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:29:36,850] {logging_mixin.py:104} INFO - [2021-04-25 13:29:36,850] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:29:36,861] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.839 seconds
[2021-04-25 13:30:07,867] {scheduler_job.py:182} INFO - Started process (PID=758) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:30:07,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:30:07,873] {logging_mixin.py:104} INFO - [2021-04-25 13:30:07,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:30:08,530] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:30:08,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:30:08,568] {logging_mixin.py:104} INFO - [2021-04-25 13:30:08,567] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:30:08,587] {logging_mixin.py:104} INFO - [2021-04-25 13:30:08,586] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:30:08,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.734 seconds
[2021-04-25 13:30:38,696] {scheduler_job.py:182} INFO - Started process (PID=760) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:30:38,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:30:38,700] {logging_mixin.py:104} INFO - [2021-04-25 13:30:38,700] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:30:39,378] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:30:39,409] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:30:39,422] {logging_mixin.py:104} INFO - [2021-04-25 13:30:39,421] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:30:39,439] {logging_mixin.py:104} INFO - [2021-04-25 13:30:39,439] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:30:39,449] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.758 seconds
[2021-04-25 13:31:09,988] {scheduler_job.py:182} INFO - Started process (PID=762) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:31:09,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:31:09,993] {logging_mixin.py:104} INFO - [2021-04-25 13:31:09,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:31:10,655] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:31:10,690] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:31:10,702] {logging_mixin.py:104} INFO - [2021-04-25 13:31:10,701] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:31:10,726] {logging_mixin.py:104} INFO - [2021-04-25 13:31:10,725] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:31:10,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.753 seconds
[2021-04-25 13:31:40,851] {scheduler_job.py:182} INFO - Started process (PID=764) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:31:40,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:31:40,858] {logging_mixin.py:104} INFO - [2021-04-25 13:31:40,857] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:31:41,509] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:31:41,548] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:31:41,561] {logging_mixin.py:104} INFO - [2021-04-25 13:31:41,560] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:31:41,586] {logging_mixin.py:104} INFO - [2021-04-25 13:31:41,586] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:31:41,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.750 seconds
[2021-04-25 13:32:11,699] {scheduler_job.py:182} INFO - Started process (PID=766) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:32:11,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:32:11,707] {logging_mixin.py:104} INFO - [2021-04-25 13:32:11,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:32:12,419] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:32:12,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:32:12,478] {logging_mixin.py:104} INFO - [2021-04-25 13:32:12,477] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:32:12,496] {logging_mixin.py:104} INFO - [2021-04-25 13:32:12,496] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:32:12,506] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.811 seconds
[2021-04-25 13:32:42,616] {scheduler_job.py:182} INFO - Started process (PID=768) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:32:42,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:32:42,625] {logging_mixin.py:104} INFO - [2021-04-25 13:32:42,625] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:32:43,401] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:32:43,432] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:32:43,445] {logging_mixin.py:104} INFO - [2021-04-25 13:32:43,444] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:32:43,465] {logging_mixin.py:104} INFO - [2021-04-25 13:32:43,465] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:32:43,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.869 seconds
[2021-04-25 13:33:13,620] {scheduler_job.py:182} INFO - Started process (PID=770) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:33:13,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:33:13,626] {logging_mixin.py:104} INFO - [2021-04-25 13:33:13,626] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:33:14,428] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:33:14,457] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:33:14,470] {logging_mixin.py:104} INFO - [2021-04-25 13:33:14,469] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:33:14,487] {logging_mixin.py:104} INFO - [2021-04-25 13:33:14,487] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:33:14,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.881 seconds
[2021-04-25 13:33:44,630] {scheduler_job.py:182} INFO - Started process (PID=772) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:33:44,636] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:33:44,640] {logging_mixin.py:104} INFO - [2021-04-25 13:33:44,639] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:33:48,656] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:33:48,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:33:48,743] {logging_mixin.py:104} INFO - [2021-04-25 13:33:48,741] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:33:48,769] {logging_mixin.py:104} INFO - [2021-04-25 13:33:48,769] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:33:48,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.159 seconds
[2021-04-25 13:34:18,924] {scheduler_job.py:182} INFO - Started process (PID=774) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:34:18,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:34:18,944] {logging_mixin.py:104} INFO - [2021-04-25 13:34:18,943] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:34:21,002] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:34:21,064] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:34:21,090] {logging_mixin.py:104} INFO - [2021-04-25 13:34:21,087] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:34:21,122] {logging_mixin.py:104} INFO - [2021-04-25 13:34:21,122] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:34:21,139] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.236 seconds
[2021-04-25 13:34:51,272] {scheduler_job.py:182} INFO - Started process (PID=776) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:34:51,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:34:51,277] {logging_mixin.py:104} INFO - [2021-04-25 13:34:51,277] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:34:51,877] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:34:51,908] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:34:51,920] {logging_mixin.py:104} INFO - [2021-04-25 13:34:51,919] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:34:51,939] {logging_mixin.py:104} INFO - [2021-04-25 13:34:51,938] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:34:51,948] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.714 seconds
[2021-04-25 13:35:22,108] {scheduler_job.py:182} INFO - Started process (PID=778) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:35:22,112] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:35:22,115] {logging_mixin.py:104} INFO - [2021-04-25 13:35:22,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:35:22,973] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:35:23,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:35:23,020] {logging_mixin.py:104} INFO - [2021-04-25 13:35:23,019] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:35:23,037] {logging_mixin.py:104} INFO - [2021-04-25 13:35:23,037] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:35:23,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.946 seconds
[2021-04-25 13:35:53,243] {scheduler_job.py:182} INFO - Started process (PID=780) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:35:53,247] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:35:53,253] {logging_mixin.py:104} INFO - [2021-04-25 13:35:53,252] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:35:54,305] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:35:54,401] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:35:54,454] {logging_mixin.py:104} INFO - [2021-04-25 13:35:54,444] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:35:54,509] {logging_mixin.py:104} INFO - [2021-04-25 13:35:54,509] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:35:54,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.300 seconds
[2021-04-25 13:36:25,472] {scheduler_job.py:182} INFO - Started process (PID=782) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:36:25,481] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:36:25,489] {logging_mixin.py:104} INFO - [2021-04-25 13:36:25,489] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:36:26,693] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:36:26,743] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:36:26,764] {logging_mixin.py:104} INFO - [2021-04-25 13:36:26,762] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:36:26,785] {logging_mixin.py:104} INFO - [2021-04-25 13:36:26,785] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:36:26,804] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.345 seconds
[2021-04-25 13:36:57,657] {scheduler_job.py:182} INFO - Started process (PID=784) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:36:57,661] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:36:57,662] {logging_mixin.py:104} INFO - [2021-04-25 13:36:57,662] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:36:58,291] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:36:58,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:36:58,332] {logging_mixin.py:104} INFO - [2021-04-25 13:36:58,331] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:36:58,352] {logging_mixin.py:104} INFO - [2021-04-25 13:36:58,352] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:36:58,366] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.716 seconds
[2021-04-25 13:37:28,464] {scheduler_job.py:182} INFO - Started process (PID=786) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:37:28,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:37:28,468] {logging_mixin.py:104} INFO - [2021-04-25 13:37:28,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:37:29,248] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:37:29,301] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:37:29,334] {logging_mixin.py:104} INFO - [2021-04-25 13:37:29,332] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:37:29,370] {logging_mixin.py:104} INFO - [2021-04-25 13:37:29,370] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:37:29,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.949 seconds
[2021-04-25 13:37:59,807] {scheduler_job.py:182} INFO - Started process (PID=788) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:37:59,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:37:59,812] {logging_mixin.py:104} INFO - [2021-04-25 13:37:59,811] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:38:00,425] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:38:00,458] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:38:00,471] {logging_mixin.py:104} INFO - [2021-04-25 13:38:00,469] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:38:00,488] {logging_mixin.py:104} INFO - [2021-04-25 13:38:00,488] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:38:00,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.696 seconds
[2021-04-25 13:38:30,577] {scheduler_job.py:182} INFO - Started process (PID=790) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:38:30,584] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:38:30,589] {logging_mixin.py:104} INFO - [2021-04-25 13:38:30,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:38:31,302] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:38:31,330] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:38:31,343] {logging_mixin.py:104} INFO - [2021-04-25 13:38:31,342] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:38:31,365] {logging_mixin.py:104} INFO - [2021-04-25 13:38:31,365] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:38:31,377] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.815 seconds
[2021-04-25 13:39:01,547] {scheduler_job.py:182} INFO - Started process (PID=792) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:39:01,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:39:01,556] {logging_mixin.py:104} INFO - [2021-04-25 13:39:01,556] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:39:02,220] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:39:02,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:39:02,261] {logging_mixin.py:104} INFO - [2021-04-25 13:39:02,260] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:39:02,280] {logging_mixin.py:104} INFO - [2021-04-25 13:39:02,280] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:39:02,288] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.745 seconds
[2021-04-25 13:39:32,385] {scheduler_job.py:182} INFO - Started process (PID=794) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:39:32,391] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:39:32,418] {logging_mixin.py:104} INFO - [2021-04-25 13:39:32,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:39:33,130] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:39:33,159] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:39:33,172] {logging_mixin.py:104} INFO - [2021-04-25 13:39:33,171] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:39:33,193] {logging_mixin.py:104} INFO - [2021-04-25 13:39:33,193] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:39:33,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.824 seconds
[2021-04-25 13:40:03,297] {scheduler_job.py:182} INFO - Started process (PID=796) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:40:03,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:40:03,302] {logging_mixin.py:104} INFO - [2021-04-25 13:40:03,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:40:03,908] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:40:03,934] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:40:03,946] {logging_mixin.py:104} INFO - [2021-04-25 13:40:03,944] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:40:03,962] {logging_mixin.py:104} INFO - [2021-04-25 13:40:03,962] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:40:03,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.683 seconds
[2021-04-25 13:40:34,073] {scheduler_job.py:182} INFO - Started process (PID=798) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:40:34,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:40:34,078] {logging_mixin.py:104} INFO - [2021-04-25 13:40:34,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:40:34,726] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:40:34,755] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:40:34,770] {logging_mixin.py:104} INFO - [2021-04-25 13:40:34,768] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:40:34,787] {logging_mixin.py:104} INFO - [2021-04-25 13:40:34,787] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:40:34,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.728 seconds
[2021-04-25 13:41:04,913] {scheduler_job.py:182} INFO - Started process (PID=800) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:41:04,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:41:04,925] {logging_mixin.py:104} INFO - [2021-04-25 13:41:04,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:41:06,163] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:41:06,228] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:41:06,251] {logging_mixin.py:104} INFO - [2021-04-25 13:41:06,249] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:41:06,284] {logging_mixin.py:104} INFO - [2021-04-25 13:41:06,284] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:41:06,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.404 seconds
[2021-04-25 13:41:36,429] {scheduler_job.py:182} INFO - Started process (PID=802) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:41:36,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:41:36,440] {logging_mixin.py:104} INFO - [2021-04-25 13:41:36,440] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:41:37,246] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:41:37,284] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:41:37,296] {logging_mixin.py:104} INFO - [2021-04-25 13:41:37,295] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:41:37,315] {logging_mixin.py:104} INFO - [2021-04-25 13:41:37,315] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:41:37,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.903 seconds
[2021-04-25 13:42:07,407] {scheduler_job.py:182} INFO - Started process (PID=804) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:42:07,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:42:07,415] {logging_mixin.py:104} INFO - [2021-04-25 13:42:07,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:42:08,071] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:42:08,105] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:42:08,117] {logging_mixin.py:104} INFO - [2021-04-25 13:42:08,116] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:42:08,134] {logging_mixin.py:104} INFO - [2021-04-25 13:42:08,134] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:42:08,142] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.744 seconds
[2021-04-25 13:42:38,301] {scheduler_job.py:182} INFO - Started process (PID=806) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:42:38,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:42:38,308] {logging_mixin.py:104} INFO - [2021-04-25 13:42:38,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:42:39,065] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:42:39,095] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:42:39,122] {logging_mixin.py:104} INFO - [2021-04-25 13:42:39,119] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:42:39,144] {logging_mixin.py:104} INFO - [2021-04-25 13:42:39,144] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:42:39,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.875 seconds
[2021-04-25 13:43:10,105] {scheduler_job.py:182} INFO - Started process (PID=808) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:43:10,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:43:10,114] {logging_mixin.py:104} INFO - [2021-04-25 13:43:10,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:43:11,057] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:43:11,093] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:43:11,107] {logging_mixin.py:104} INFO - [2021-04-25 13:43:11,106] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:43:11,128] {logging_mixin.py:104} INFO - [2021-04-25 13:43:11,128] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:43:11,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.037 seconds
[2021-04-25 13:43:41,238] {scheduler_job.py:182} INFO - Started process (PID=810) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:43:41,241] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:43:41,243] {logging_mixin.py:104} INFO - [2021-04-25 13:43:41,242] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:43:41,901] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:43:41,930] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:43:41,943] {logging_mixin.py:104} INFO - [2021-04-25 13:43:41,942] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:43:41,963] {logging_mixin.py:104} INFO - [2021-04-25 13:43:41,962] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:43:41,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.738 seconds
[2021-04-25 13:44:12,042] {scheduler_job.py:182} INFO - Started process (PID=812) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:44:12,045] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:44:12,046] {logging_mixin.py:104} INFO - [2021-04-25 13:44:12,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:44:12,855] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:44:12,893] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:44:12,923] {logging_mixin.py:104} INFO - [2021-04-25 13:44:12,922] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:44:12,949] {logging_mixin.py:104} INFO - [2021-04-25 13:44:12,949] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:44:12,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.928 seconds
[2021-04-25 13:44:43,111] {scheduler_job.py:182} INFO - Started process (PID=814) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:44:43,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:44:43,125] {logging_mixin.py:104} INFO - [2021-04-25 13:44:43,124] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:44:44,102] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:44:44,134] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:44:44,148] {logging_mixin.py:104} INFO - [2021-04-25 13:44:44,147] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:44:44,165] {logging_mixin.py:104} INFO - [2021-04-25 13:44:44,165] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:44:44,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.072 seconds
[2021-04-25 13:45:14,256] {scheduler_job.py:182} INFO - Started process (PID=816) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:45:14,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:45:14,266] {logging_mixin.py:104} INFO - [2021-04-25 13:45:14,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:45:15,086] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:45:15,125] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:45:15,141] {logging_mixin.py:104} INFO - [2021-04-25 13:45:15,140] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:45:15,160] {logging_mixin.py:104} INFO - [2021-04-25 13:45:15,160] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:45:15,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.921 seconds
[2021-04-25 13:45:45,754] {scheduler_job.py:182} INFO - Started process (PID=818) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:45:45,814] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:45:45,835] {logging_mixin.py:104} INFO - [2021-04-25 13:45:45,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:45:47,798] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:45:47,882] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:45:47,928] {logging_mixin.py:104} INFO - [2021-04-25 13:45:47,926] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:45:48,029] {logging_mixin.py:104} INFO - [2021-04-25 13:45:48,028] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:45:48,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.413 seconds
[2021-04-25 13:46:18,300] {scheduler_job.py:182} INFO - Started process (PID=820) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:46:18,303] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:46:18,307] {logging_mixin.py:104} INFO - [2021-04-25 13:46:18,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:46:20,086] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:46:20,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:46:20,144] {logging_mixin.py:104} INFO - [2021-04-25 13:46:20,143] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:46:20,170] {logging_mixin.py:104} INFO - [2021-04-25 13:46:20,170] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:46:20,189] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.895 seconds
[2021-04-25 13:46:50,413] {scheduler_job.py:182} INFO - Started process (PID=822) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:46:50,416] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:46:50,418] {logging_mixin.py:104} INFO - [2021-04-25 13:46:50,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:46:51,161] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:46:51,194] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:46:51,207] {logging_mixin.py:104} INFO - [2021-04-25 13:46:51,205] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:46:51,226] {logging_mixin.py:104} INFO - [2021-04-25 13:46:51,226] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:46:51,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.861 seconds
[2021-04-25 13:47:21,707] {scheduler_job.py:182} INFO - Started process (PID=824) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:47:21,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:47:21,713] {logging_mixin.py:104} INFO - [2021-04-25 13:47:21,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:47:22,528] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:47:22,569] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:47:22,585] {logging_mixin.py:104} INFO - [2021-04-25 13:47:22,584] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:47:22,609] {logging_mixin.py:104} INFO - [2021-04-25 13:47:22,608] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:47:22,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.920 seconds
[2021-04-25 13:47:52,697] {scheduler_job.py:182} INFO - Started process (PID=826) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:47:52,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:47:52,705] {logging_mixin.py:104} INFO - [2021-04-25 13:47:52,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:47:53,349] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:47:53,395] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:47:53,407] {logging_mixin.py:104} INFO - [2021-04-25 13:47:53,406] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:47:53,423] {logging_mixin.py:104} INFO - [2021-04-25 13:47:53,423] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:47:53,432] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-25 13:48:23,904] {scheduler_job.py:182} INFO - Started process (PID=828) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:48:23,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:48:23,909] {logging_mixin.py:104} INFO - [2021-04-25 13:48:23,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:48:24,615] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:48:24,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:48:24,663] {logging_mixin.py:104} INFO - [2021-04-25 13:48:24,662] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:48:24,679] {logging_mixin.py:104} INFO - [2021-04-25 13:48:24,679] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:48:24,692] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.793 seconds
[2021-04-25 13:48:55,140] {scheduler_job.py:182} INFO - Started process (PID=830) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:48:55,143] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:48:55,144] {logging_mixin.py:104} INFO - [2021-04-25 13:48:55,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:48:55,997] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:48:56,047] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:48:56,069] {logging_mixin.py:104} INFO - [2021-04-25 13:48:56,066] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:48:56,098] {logging_mixin.py:104} INFO - [2021-04-25 13:48:56,098] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:48:56,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.979 seconds
[2021-04-25 13:49:26,788] {scheduler_job.py:182} INFO - Started process (PID=832) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:49:26,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:49:26,794] {logging_mixin.py:104} INFO - [2021-04-25 13:49:26,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:49:27,466] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:49:27,495] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:49:27,508] {logging_mixin.py:104} INFO - [2021-04-25 13:49:27,507] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:49:27,526] {logging_mixin.py:104} INFO - [2021-04-25 13:49:27,526] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:49:27,534] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.752 seconds
[2021-04-25 13:49:57,898] {scheduler_job.py:182} INFO - Started process (PID=834) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:49:57,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:49:57,906] {logging_mixin.py:104} INFO - [2021-04-25 13:49:57,906] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:49:58,904] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:49:58,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:49:58,960] {logging_mixin.py:104} INFO - [2021-04-25 13:49:58,959] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:49:58,979] {logging_mixin.py:104} INFO - [2021-04-25 13:49:58,979] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:49:58,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.105 seconds
[2021-04-25 13:50:29,340] {scheduler_job.py:182} INFO - Started process (PID=836) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:50:29,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:50:29,567] {logging_mixin.py:104} INFO - [2021-04-25 13:50:29,567] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:50:33,344] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:50:33,457] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:50:33,525] {logging_mixin.py:104} INFO - [2021-04-25 13:50:33,513] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:50:33,611] {logging_mixin.py:104} INFO - [2021-04-25 13:50:33,611] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:50:33,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.409 seconds
[2021-04-25 13:51:03,944] {scheduler_job.py:182} INFO - Started process (PID=838) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:51:03,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:51:03,952] {logging_mixin.py:104} INFO - [2021-04-25 13:51:03,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:51:05,409] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:51:05,450] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:51:05,464] {logging_mixin.py:104} INFO - [2021-04-25 13:51:05,462] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:51:05,518] {logging_mixin.py:104} INFO - [2021-04-25 13:51:05,518] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:51:05,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.603 seconds
[2021-04-25 13:51:35,708] {scheduler_job.py:182} INFO - Started process (PID=840) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:51:35,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:51:35,713] {logging_mixin.py:104} INFO - [2021-04-25 13:51:35,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:51:36,408] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:51:36,436] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:51:36,452] {logging_mixin.py:104} INFO - [2021-04-25 13:51:36,449] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:51:36,471] {logging_mixin.py:104} INFO - [2021-04-25 13:51:36,471] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:51:36,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.776 seconds
[2021-04-25 13:52:06,834] {scheduler_job.py:182} INFO - Started process (PID=842) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:52:06,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:52:06,839] {logging_mixin.py:104} INFO - [2021-04-25 13:52:06,839] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:52:07,761] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:52:07,816] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:52:07,832] {logging_mixin.py:104} INFO - [2021-04-25 13:52:07,831] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:52:07,854] {logging_mixin.py:104} INFO - [2021-04-25 13:52:07,853] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:52:07,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.035 seconds
[2021-04-25 13:52:38,075] {scheduler_job.py:182} INFO - Started process (PID=844) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:52:38,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:52:38,083] {logging_mixin.py:104} INFO - [2021-04-25 13:52:38,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:52:38,944] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:52:38,980] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:52:38,997] {logging_mixin.py:104} INFO - [2021-04-25 13:52:38,996] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:52:39,017] {logging_mixin.py:104} INFO - [2021-04-25 13:52:39,017] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:52:39,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.960 seconds
[2021-04-25 13:53:09,245] {scheduler_job.py:182} INFO - Started process (PID=846) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:53:09,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:53:09,250] {logging_mixin.py:104} INFO - [2021-04-25 13:53:09,250] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:53:10,060] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:53:10,088] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:53:10,100] {logging_mixin.py:104} INFO - [2021-04-25 13:53:10,100] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:53:10,118] {logging_mixin.py:104} INFO - [2021-04-25 13:53:10,118] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:53:10,128] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.889 seconds
[2021-04-25 13:53:40,292] {scheduler_job.py:182} INFO - Started process (PID=848) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:53:40,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:53:40,308] {logging_mixin.py:104} INFO - [2021-04-25 13:53:40,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:53:41,298] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:53:41,338] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:53:41,350] {logging_mixin.py:104} INFO - [2021-04-25 13:53:41,349] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:53:41,369] {logging_mixin.py:104} INFO - [2021-04-25 13:53:41,369] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:53:41,381] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.107 seconds
[2021-04-25 13:54:11,671] {scheduler_job.py:182} INFO - Started process (PID=850) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:54:11,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:54:11,676] {logging_mixin.py:104} INFO - [2021-04-25 13:54:11,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:54:12,563] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:54:12,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:54:12,638] {logging_mixin.py:104} INFO - [2021-04-25 13:54:12,635] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:54:12,678] {logging_mixin.py:104} INFO - [2021-04-25 13:54:12,677] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:54:12,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.029 seconds
[2021-04-25 13:54:42,832] {scheduler_job.py:182} INFO - Started process (PID=852) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:54:42,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:54:42,836] {logging_mixin.py:104} INFO - [2021-04-25 13:54:42,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:54:43,523] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:54:43,551] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:54:43,563] {logging_mixin.py:104} INFO - [2021-04-25 13:54:43,562] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:54:43,583] {logging_mixin.py:104} INFO - [2021-04-25 13:54:43,583] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:54:43,593] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.765 seconds
[2021-04-25 13:55:14,103] {scheduler_job.py:182} INFO - Started process (PID=854) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:55:14,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:55:14,108] {logging_mixin.py:104} INFO - [2021-04-25 13:55:14,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:55:14,863] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:55:14,920] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:55:14,954] {logging_mixin.py:104} INFO - [2021-04-25 13:55:14,953] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:55:14,996] {logging_mixin.py:104} INFO - [2021-04-25 13:55:14,996] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:55:15,008] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.912 seconds
[2021-04-25 13:55:45,328] {scheduler_job.py:182} INFO - Started process (PID=856) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:55:45,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:55:45,343] {logging_mixin.py:104} INFO - [2021-04-25 13:55:45,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:55:46,198] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:55:46,236] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:55:46,247] {logging_mixin.py:104} INFO - [2021-04-25 13:55:46,246] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:55:46,264] {logging_mixin.py:104} INFO - [2021-04-25 13:55:46,264] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:55:46,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.950 seconds
[2021-04-25 13:56:16,403] {scheduler_job.py:182} INFO - Started process (PID=858) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:56:16,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:56:16,407] {logging_mixin.py:104} INFO - [2021-04-25 13:56:16,407] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:56:17,045] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:56:17,080] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:56:17,093] {logging_mixin.py:104} INFO - [2021-04-25 13:56:17,092] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:56:17,110] {logging_mixin.py:104} INFO - [2021-04-25 13:56:17,110] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:56:17,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.721 seconds
[2021-04-25 13:56:47,253] {scheduler_job.py:182} INFO - Started process (PID=860) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:56:47,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:56:47,280] {logging_mixin.py:104} INFO - [2021-04-25 13:56:47,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:56:50,329] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:56:50,438] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:56:50,471] {logging_mixin.py:104} INFO - [2021-04-25 13:56:50,469] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:56:50,518] {logging_mixin.py:104} INFO - [2021-04-25 13:56:50,518] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:56:50,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.342 seconds
[2021-04-25 13:57:20,646] {scheduler_job.py:182} INFO - Started process (PID=862) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:57:20,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:57:20,655] {logging_mixin.py:104} INFO - [2021-04-25 13:57:20,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:57:21,493] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:57:21,537] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:57:21,557] {logging_mixin.py:104} INFO - [2021-04-25 13:57:21,555] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:57:21,582] {logging_mixin.py:104} INFO - [2021-04-25 13:57:21,582] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:57:21,598] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.961 seconds
[2021-04-25 13:57:52,478] {scheduler_job.py:182} INFO - Started process (PID=864) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:57:52,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:57:52,504] {logging_mixin.py:104} INFO - [2021-04-25 13:57:52,504] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:57:54,358] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:57:54,404] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:57:54,423] {logging_mixin.py:104} INFO - [2021-04-25 13:57:54,422] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:57:54,458] {logging_mixin.py:104} INFO - [2021-04-25 13:57:54,458] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:57:54,471] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.999 seconds
[2021-04-25 13:58:24,603] {scheduler_job.py:182} INFO - Started process (PID=866) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:58:24,606] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:58:24,609] {logging_mixin.py:104} INFO - [2021-04-25 13:58:24,609] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:58:25,356] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:58:25,387] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:58:25,407] {logging_mixin.py:104} INFO - [2021-04-25 13:58:25,406] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:58:25,426] {logging_mixin.py:104} INFO - [2021-04-25 13:58:25,426] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:58:25,437] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.839 seconds
[2021-04-25 13:58:55,511] {scheduler_job.py:182} INFO - Started process (PID=868) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:58:55,514] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:58:55,516] {logging_mixin.py:104} INFO - [2021-04-25 13:58:55,516] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:58:56,262] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:58:56,293] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:58:56,306] {logging_mixin.py:104} INFO - [2021-04-25 13:58:56,305] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:58:56,324] {logging_mixin.py:104} INFO - [2021-04-25 13:58:56,324] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:58:56,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.837 seconds
[2021-04-25 13:59:26,486] {scheduler_job.py:182} INFO - Started process (PID=870) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:59:26,489] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:59:26,492] {logging_mixin.py:104} INFO - [2021-04-25 13:59:26,492] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:59:27,686] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:59:27,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:59:27,748] {logging_mixin.py:104} INFO - [2021-04-25 13:59:27,746] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:59:27,772] {logging_mixin.py:104} INFO - [2021-04-25 13:59:27,772] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:59:27,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.303 seconds
[2021-04-25 13:59:57,875] {scheduler_job.py:182} INFO - Started process (PID=872) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:59:57,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 13:59:57,882] {logging_mixin.py:104} INFO - [2021-04-25 13:59:57,882] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:59:58,751] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 13:59:58,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 13:59:58,807] {logging_mixin.py:104} INFO - [2021-04-25 13:59:58,805] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 13:59:58,827] {logging_mixin.py:104} INFO - [2021-04-25 13:59:58,827] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T13:00:00+00:00
[2021-04-25 13:59:58,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.969 seconds
[2021-04-25 14:00:29,066] {scheduler_job.py:182} INFO - Started process (PID=874) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:00:29,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:00:29,082] {logging_mixin.py:104} INFO - [2021-04-25 14:00:29,082] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:00:30,976] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:00:31,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:00:31,037] {logging_mixin.py:104} INFO - [2021-04-25 14:00:31,036] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:00:31,064] {logging_mixin.py:104} INFO - [2021-04-25 14:00:31,064] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:00:31,082] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.038 seconds
[2021-04-25 14:01:01,183] {scheduler_job.py:182} INFO - Started process (PID=876) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:01:01,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:01:01,193] {logging_mixin.py:104} INFO - [2021-04-25 14:01:01,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:01:02,432] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:01:02,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:01:02,573] {logging_mixin.py:104} INFO - [2021-04-25 14:01:02,572] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:01:02,606] {logging_mixin.py:104} INFO - [2021-04-25 14:01:02,606] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:01:02,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.451 seconds
[2021-04-25 14:01:33,310] {scheduler_job.py:182} INFO - Started process (PID=878) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:01:33,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:01:33,319] {logging_mixin.py:104} INFO - [2021-04-25 14:01:33,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:01:34,667] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:01:34,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:01:34,739] {logging_mixin.py:104} INFO - [2021-04-25 14:01:34,738] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:01:34,763] {logging_mixin.py:104} INFO - [2021-04-25 14:01:34,762] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:01:34,781] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.482 seconds
[2021-04-25 14:02:04,901] {scheduler_job.py:182} INFO - Started process (PID=880) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:02:04,905] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:02:04,908] {logging_mixin.py:104} INFO - [2021-04-25 14:02:04,908] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:02:06,609] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:02:06,656] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:02:06,675] {logging_mixin.py:104} INFO - [2021-04-25 14:02:06,673] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:02:06,698] {logging_mixin.py:104} INFO - [2021-04-25 14:02:06,698] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:02:06,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.817 seconds
[2021-04-25 14:02:36,890] {scheduler_job.py:182} INFO - Started process (PID=882) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:02:36,908] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:02:36,917] {logging_mixin.py:104} INFO - [2021-04-25 14:02:36,916] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:02:38,195] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:02:38,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:02:38,251] {logging_mixin.py:104} INFO - [2021-04-25 14:02:38,250] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:02:38,275] {logging_mixin.py:104} INFO - [2021-04-25 14:02:38,275] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:02:38,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.411 seconds
[2021-04-25 14:03:08,441] {scheduler_job.py:182} INFO - Started process (PID=884) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:03:08,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:03:08,447] {logging_mixin.py:104} INFO - [2021-04-25 14:03:08,447] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:03:09,079] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:03:09,108] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:03:09,120] {logging_mixin.py:104} INFO - [2021-04-25 14:03:09,119] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:03:09,135] {logging_mixin.py:104} INFO - [2021-04-25 14:03:09,135] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:03:09,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.711 seconds
[2021-04-25 14:03:39,248] {scheduler_job.py:182} INFO - Started process (PID=886) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:03:39,252] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:03:39,255] {logging_mixin.py:104} INFO - [2021-04-25 14:03:39,255] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:03:39,967] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:03:39,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:03:40,013] {logging_mixin.py:104} INFO - [2021-04-25 14:03:40,012] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:03:40,033] {logging_mixin.py:104} INFO - [2021-04-25 14:03:40,032] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:03:40,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.802 seconds
[2021-04-25 14:04:10,777] {scheduler_job.py:182} INFO - Started process (PID=888) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:04:10,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:04:10,782] {logging_mixin.py:104} INFO - [2021-04-25 14:04:10,782] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:04:11,483] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:04:11,515] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:04:11,527] {logging_mixin.py:104} INFO - [2021-04-25 14:04:11,526] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:04:11,544] {logging_mixin.py:104} INFO - [2021-04-25 14:04:11,544] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:04:11,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.784 seconds
[2021-04-25 14:04:41,662] {scheduler_job.py:182} INFO - Started process (PID=890) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:04:41,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:04:41,667] {logging_mixin.py:104} INFO - [2021-04-25 14:04:41,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:04:42,303] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:04:42,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:04:42,345] {logging_mixin.py:104} INFO - [2021-04-25 14:04:42,344] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:04:42,363] {logging_mixin.py:104} INFO - [2021-04-25 14:04:42,363] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:04:42,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.718 seconds
[2021-04-25 14:05:13,058] {scheduler_job.py:182} INFO - Started process (PID=892) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:05:13,061] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:05:13,062] {logging_mixin.py:104} INFO - [2021-04-25 14:05:13,062] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:05:13,692] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:05:13,720] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:05:13,735] {logging_mixin.py:104} INFO - [2021-04-25 14:05:13,734] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:05:13,753] {logging_mixin.py:104} INFO - [2021-04-25 14:05:13,753] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:05:13,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.710 seconds
[2021-04-25 14:05:43,838] {scheduler_job.py:182} INFO - Started process (PID=894) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:05:43,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:05:43,842] {logging_mixin.py:104} INFO - [2021-04-25 14:05:43,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:05:44,556] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:05:44,587] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:05:44,600] {logging_mixin.py:104} INFO - [2021-04-25 14:05:44,599] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:05:44,616] {logging_mixin.py:104} INFO - [2021-04-25 14:05:44,616] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:05:44,625] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.791 seconds
[2021-04-25 14:06:14,881] {scheduler_job.py:182} INFO - Started process (PID=896) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:06:14,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:06:14,892] {logging_mixin.py:104} INFO - [2021-04-25 14:06:14,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:06:17,717] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:06:17,798] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:06:17,834] {logging_mixin.py:104} INFO - [2021-04-25 14:06:17,832] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:06:17,902] {logging_mixin.py:104} INFO - [2021-04-25 14:06:17,902] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:06:17,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.077 seconds
[2021-04-25 14:06:48,048] {scheduler_job.py:182} INFO - Started process (PID=898) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:06:48,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:06:48,057] {logging_mixin.py:104} INFO - [2021-04-25 14:06:48,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:06:49,539] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:06:49,627] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:06:49,677] {logging_mixin.py:104} INFO - [2021-04-25 14:06:49,673] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:06:49,704] {logging_mixin.py:104} INFO - [2021-04-25 14:06:49,704] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:06:49,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.712 seconds
[2021-04-25 14:07:19,839] {scheduler_job.py:182} INFO - Started process (PID=900) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:07:19,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:07:19,843] {logging_mixin.py:104} INFO - [2021-04-25 14:07:19,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:07:20,500] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:07:20,545] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:07:20,558] {logging_mixin.py:104} INFO - [2021-04-25 14:07:20,557] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:07:20,574] {logging_mixin.py:104} INFO - [2021-04-25 14:07:20,574] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:07:20,584] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.748 seconds
[2021-04-25 14:07:51,075] {scheduler_job.py:182} INFO - Started process (PID=902) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:07:51,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:07:51,086] {logging_mixin.py:104} INFO - [2021-04-25 14:07:51,086] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:07:51,786] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:07:51,816] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:07:51,829] {logging_mixin.py:104} INFO - [2021-04-25 14:07:51,827] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:07:51,855] {logging_mixin.py:104} INFO - [2021-04-25 14:07:51,855] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:07:51,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.804 seconds
[2021-04-25 14:08:21,987] {scheduler_job.py:182} INFO - Started process (PID=904) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:08:21,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:08:21,993] {logging_mixin.py:104} INFO - [2021-04-25 14:08:21,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:08:22,799] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:08:22,832] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:08:22,844] {logging_mixin.py:104} INFO - [2021-04-25 14:08:22,843] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:08:22,859] {logging_mixin.py:104} INFO - [2021-04-25 14:08:22,859] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:08:22,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.889 seconds
[2021-04-25 14:08:52,967] {scheduler_job.py:182} INFO - Started process (PID=906) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:08:52,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:08:52,972] {logging_mixin.py:104} INFO - [2021-04-25 14:08:52,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:08:53,660] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:08:53,687] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:08:53,699] {logging_mixin.py:104} INFO - [2021-04-25 14:08:53,698] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:08:53,715] {logging_mixin.py:104} INFO - [2021-04-25 14:08:53,715] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:08:53,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.764 seconds
[2021-04-25 14:09:23,866] {scheduler_job.py:182} INFO - Started process (PID=908) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:09:23,870] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:09:23,873] {logging_mixin.py:104} INFO - [2021-04-25 14:09:23,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:09:24,680] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:09:24,712] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:09:24,727] {logging_mixin.py:104} INFO - [2021-04-25 14:09:24,725] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:09:24,743] {logging_mixin.py:104} INFO - [2021-04-25 14:09:24,743] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:09:24,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.895 seconds
[2021-04-25 14:09:54,946] {scheduler_job.py:182} INFO - Started process (PID=910) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:09:54,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:09:54,950] {logging_mixin.py:104} INFO - [2021-04-25 14:09:54,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:09:55,615] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:09:55,658] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:09:55,676] {logging_mixin.py:104} INFO - [2021-04-25 14:09:55,675] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:09:55,702] {logging_mixin.py:104} INFO - [2021-04-25 14:09:55,702] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:09:55,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.813 seconds
[2021-04-25 14:10:25,854] {scheduler_job.py:182} INFO - Started process (PID=912) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:10:25,857] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:10:25,859] {logging_mixin.py:104} INFO - [2021-04-25 14:10:25,858] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:10:26,474] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:10:26,506] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:10:26,518] {logging_mixin.py:104} INFO - [2021-04-25 14:10:26,517] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:10:26,534] {logging_mixin.py:104} INFO - [2021-04-25 14:10:26,534] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:10:26,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.694 seconds
[2021-04-25 14:10:56,934] {scheduler_job.py:182} INFO - Started process (PID=914) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:10:56,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:10:56,940] {logging_mixin.py:104} INFO - [2021-04-25 14:10:56,940] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:10:57,697] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:10:57,727] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:10:57,739] {logging_mixin.py:104} INFO - [2021-04-25 14:10:57,738] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:10:57,757] {logging_mixin.py:104} INFO - [2021-04-25 14:10:57,757] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:10:57,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.839 seconds
[2021-04-25 14:11:28,525] {scheduler_job.py:182} INFO - Started process (PID=916) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:11:28,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:11:28,534] {logging_mixin.py:104} INFO - [2021-04-25 14:11:28,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:11:29,250] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:11:29,290] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:11:29,308] {logging_mixin.py:104} INFO - [2021-04-25 14:11:29,306] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:11:29,329] {logging_mixin.py:104} INFO - [2021-04-25 14:11:29,329] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:11:29,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.821 seconds
[2021-04-25 14:11:59,704] {scheduler_job.py:182} INFO - Started process (PID=918) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:11:59,707] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:11:59,709] {logging_mixin.py:104} INFO - [2021-04-25 14:11:59,709] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:12:00,548] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:12:00,594] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:12:00,610] {logging_mixin.py:104} INFO - [2021-04-25 14:12:00,609] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:12:00,631] {logging_mixin.py:104} INFO - [2021-04-25 14:12:00,631] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:12:00,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.944 seconds
[2021-04-25 14:12:31,132] {scheduler_job.py:182} INFO - Started process (PID=920) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:12:31,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:12:31,138] {logging_mixin.py:104} INFO - [2021-04-25 14:12:31,138] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:12:31,930] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:12:31,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:12:31,981] {logging_mixin.py:104} INFO - [2021-04-25 14:12:31,980] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:12:31,997] {logging_mixin.py:104} INFO - [2021-04-25 14:12:31,997] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:12:32,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.888 seconds
[2021-04-25 14:13:02,283] {scheduler_job.py:182} INFO - Started process (PID=922) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:13:02,288] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:13:02,291] {logging_mixin.py:104} INFO - [2021-04-25 14:13:02,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:13:03,119] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:13:03,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:13:03,159] {logging_mixin.py:104} INFO - [2021-04-25 14:13:03,159] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:13:03,177] {logging_mixin.py:104} INFO - [2021-04-25 14:13:03,176] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:13:03,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.910 seconds
[2021-04-25 14:13:33,823] {scheduler_job.py:182} INFO - Started process (PID=924) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:13:33,827] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:13:33,829] {logging_mixin.py:104} INFO - [2021-04-25 14:13:33,828] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:13:34,840] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:13:34,894] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:13:34,917] {logging_mixin.py:104} INFO - [2021-04-25 14:13:34,916] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:13:34,947] {logging_mixin.py:104} INFO - [2021-04-25 14:13:34,947] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:13:34,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.150 seconds
[2021-04-25 14:14:05,062] {scheduler_job.py:182} INFO - Started process (PID=926) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:14:05,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:14:05,067] {logging_mixin.py:104} INFO - [2021-04-25 14:14:05,067] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:14:06,444] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:14:06,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:14:06,570] {logging_mixin.py:104} INFO - [2021-04-25 14:14:06,559] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:14:06,614] {logging_mixin.py:104} INFO - [2021-04-25 14:14:06,614] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:14:06,630] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.573 seconds
[2021-04-25 14:14:36,876] {scheduler_job.py:182} INFO - Started process (PID=928) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:14:36,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:14:36,886] {logging_mixin.py:104} INFO - [2021-04-25 14:14:36,886] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:14:38,033] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:14:38,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:14:38,088] {logging_mixin.py:104} INFO - [2021-04-25 14:14:38,087] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:14:38,111] {logging_mixin.py:104} INFO - [2021-04-25 14:14:38,111] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:14:38,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.257 seconds
[2021-04-25 14:15:08,309] {scheduler_job.py:182} INFO - Started process (PID=930) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:15:08,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:15:08,327] {logging_mixin.py:104} INFO - [2021-04-25 14:15:08,327] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:15:11,049] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:15:11,109] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:15:11,125] {logging_mixin.py:104} INFO - [2021-04-25 14:15:11,124] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:15:11,146] {logging_mixin.py:104} INFO - [2021-04-25 14:15:11,146] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:15:11,158] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.872 seconds
[2021-04-25 14:15:41,271] {scheduler_job.py:182} INFO - Started process (PID=932) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:15:41,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:15:41,276] {logging_mixin.py:104} INFO - [2021-04-25 14:15:41,276] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:15:42,049] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:15:42,098] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:15:42,114] {logging_mixin.py:104} INFO - [2021-04-25 14:15:42,113] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:15:42,142] {logging_mixin.py:104} INFO - [2021-04-25 14:15:42,142] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:15:42,150] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.882 seconds
[2021-04-25 14:16:12,437] {scheduler_job.py:182} INFO - Started process (PID=934) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:16:12,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:16:12,444] {logging_mixin.py:104} INFO - [2021-04-25 14:16:12,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:16:13,241] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:16:13,291] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:16:13,310] {logging_mixin.py:104} INFO - [2021-04-25 14:16:13,309] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:16:13,330] {logging_mixin.py:104} INFO - [2021-04-25 14:16:13,330] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:16:13,345] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.914 seconds
[2021-04-25 14:16:43,450] {scheduler_job.py:182} INFO - Started process (PID=936) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:16:43,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:16:43,457] {logging_mixin.py:104} INFO - [2021-04-25 14:16:43,457] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:16:44,119] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:16:44,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:16:44,184] {logging_mixin.py:104} INFO - [2021-04-25 14:16:44,183] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:16:44,204] {logging_mixin.py:104} INFO - [2021-04-25 14:16:44,204] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:16:44,213] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.768 seconds
[2021-04-25 14:17:14,304] {scheduler_job.py:182} INFO - Started process (PID=938) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:17:14,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:17:14,312] {logging_mixin.py:104} INFO - [2021-04-25 14:17:14,312] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:17:15,330] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:17:15,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:17:15,403] {logging_mixin.py:104} INFO - [2021-04-25 14:17:15,402] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:17:15,431] {logging_mixin.py:104} INFO - [2021-04-25 14:17:15,431] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:17:15,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.147 seconds
[2021-04-25 14:17:45,525] {scheduler_job.py:182} INFO - Started process (PID=940) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:17:45,528] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:17:45,530] {logging_mixin.py:104} INFO - [2021-04-25 14:17:45,530] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:17:46,473] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:17:46,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:17:46,524] {logging_mixin.py:104} INFO - [2021-04-25 14:17:46,523] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:17:46,541] {logging_mixin.py:104} INFO - [2021-04-25 14:17:46,541] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:17:46,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.030 seconds
[2021-04-25 14:18:16,651] {scheduler_job.py:182} INFO - Started process (PID=942) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:18:16,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:18:16,656] {logging_mixin.py:104} INFO - [2021-04-25 14:18:16,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:18:17,571] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:18:17,598] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:18:17,611] {logging_mixin.py:104} INFO - [2021-04-25 14:18:17,609] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:18:17,629] {logging_mixin.py:104} INFO - [2021-04-25 14:18:17,629] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:18:17,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.992 seconds
[2021-04-25 14:18:47,783] {scheduler_job.py:182} INFO - Started process (PID=944) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:18:47,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:18:47,792] {logging_mixin.py:104} INFO - [2021-04-25 14:18:47,792] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:18:48,524] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:18:48,565] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:18:48,580] {logging_mixin.py:104} INFO - [2021-04-25 14:18:48,579] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:18:48,599] {logging_mixin.py:104} INFO - [2021-04-25 14:18:48,599] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:18:48,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.843 seconds
[2021-04-25 14:19:18,724] {scheduler_job.py:182} INFO - Started process (PID=946) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:19:18,728] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:19:18,731] {logging_mixin.py:104} INFO - [2021-04-25 14:19:18,730] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:19:19,781] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:19:19,812] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:19:19,825] {logging_mixin.py:104} INFO - [2021-04-25 14:19:19,824] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:19:19,843] {logging_mixin.py:104} INFO - [2021-04-25 14:19:19,843] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:19:19,855] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.171 seconds
[2021-04-25 14:19:49,971] {scheduler_job.py:182} INFO - Started process (PID=948) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:19:49,975] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:19:49,978] {logging_mixin.py:104} INFO - [2021-04-25 14:19:49,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:19:50,730] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:19:50,760] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:19:50,774] {logging_mixin.py:104} INFO - [2021-04-25 14:19:50,773] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:19:50,791] {logging_mixin.py:104} INFO - [2021-04-25 14:19:50,791] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:19:50,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.836 seconds
[2021-04-25 14:20:20,885] {scheduler_job.py:182} INFO - Started process (PID=950) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:20:20,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:20:20,891] {logging_mixin.py:104} INFO - [2021-04-25 14:20:20,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:20:21,849] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:20:21,901] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:20:21,923] {logging_mixin.py:104} INFO - [2021-04-25 14:20:21,921] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:20:21,954] {logging_mixin.py:104} INFO - [2021-04-25 14:20:21,954] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:20:21,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.087 seconds
[2021-04-25 14:20:52,095] {scheduler_job.py:182} INFO - Started process (PID=952) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:20:52,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:20:52,100] {logging_mixin.py:104} INFO - [2021-04-25 14:20:52,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:20:52,801] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:20:52,843] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:20:52,861] {logging_mixin.py:104} INFO - [2021-04-25 14:20:52,859] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:20:52,884] {logging_mixin.py:104} INFO - [2021-04-25 14:20:52,884] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:20:52,898] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.808 seconds
[2021-04-25 14:21:22,996] {scheduler_job.py:182} INFO - Started process (PID=954) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:21:22,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:21:23,002] {logging_mixin.py:104} INFO - [2021-04-25 14:21:23,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:21:23,973] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:21:24,009] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:21:24,030] {logging_mixin.py:104} INFO - [2021-04-25 14:21:24,029] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:21:24,056] {logging_mixin.py:104} INFO - [2021-04-25 14:21:24,056] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:21:24,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.073 seconds
[2021-04-25 14:21:54,224] {scheduler_job.py:182} INFO - Started process (PID=956) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:21:54,227] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:21:54,229] {logging_mixin.py:104} INFO - [2021-04-25 14:21:54,229] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:21:54,921] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:21:54,953] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:21:54,967] {logging_mixin.py:104} INFO - [2021-04-25 14:21:54,966] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:21:54,985] {logging_mixin.py:104} INFO - [2021-04-25 14:21:54,985] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:21:54,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.775 seconds
[2021-04-25 14:22:25,115] {scheduler_job.py:182} INFO - Started process (PID=958) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:22:25,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:22:25,120] {logging_mixin.py:104} INFO - [2021-04-25 14:22:25,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:22:25,729] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:22:25,760] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:22:25,772] {logging_mixin.py:104} INFO - [2021-04-25 14:22:25,771] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:22:25,789] {logging_mixin.py:104} INFO - [2021-04-25 14:22:25,789] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:22:25,799] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.688 seconds
[2021-04-25 14:22:56,294] {scheduler_job.py:182} INFO - Started process (PID=960) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:22:56,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:22:56,299] {logging_mixin.py:104} INFO - [2021-04-25 14:22:56,299] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:22:57,126] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:22:57,153] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:22:57,172] {logging_mixin.py:104} INFO - [2021-04-25 14:22:57,171] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:22:57,187] {logging_mixin.py:104} INFO - [2021-04-25 14:22:57,187] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:22:57,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.906 seconds
[2021-04-25 14:23:27,373] {scheduler_job.py:182} INFO - Started process (PID=962) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:23:27,378] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:23:27,388] {logging_mixin.py:104} INFO - [2021-04-25 14:23:27,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:23:28,160] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:23:28,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:23:28,208] {logging_mixin.py:104} INFO - [2021-04-25 14:23:28,207] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:23:28,224] {logging_mixin.py:104} INFO - [2021-04-25 14:23:28,224] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:23:28,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.868 seconds
[2021-04-25 14:23:58,480] {scheduler_job.py:182} INFO - Started process (PID=964) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:23:58,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:23:58,486] {logging_mixin.py:104} INFO - [2021-04-25 14:23:58,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:23:59,085] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:23:59,114] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:23:59,128] {logging_mixin.py:104} INFO - [2021-04-25 14:23:59,127] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:23:59,146] {logging_mixin.py:104} INFO - [2021-04-25 14:23:59,145] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:23:59,156] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.681 seconds
[2021-04-25 14:24:29,232] {scheduler_job.py:182} INFO - Started process (PID=966) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:24:29,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:24:29,236] {logging_mixin.py:104} INFO - [2021-04-25 14:24:29,236] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:24:29,891] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:24:29,918] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:24:29,930] {logging_mixin.py:104} INFO - [2021-04-25 14:24:29,929] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:24:29,947] {logging_mixin.py:104} INFO - [2021-04-25 14:24:29,946] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:24:29,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.730 seconds
[2021-04-25 14:25:00,300] {scheduler_job.py:182} INFO - Started process (PID=968) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:25:00,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:25:00,304] {logging_mixin.py:104} INFO - [2021-04-25 14:25:00,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:25:00,946] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:25:00,975] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:25:00,987] {logging_mixin.py:104} INFO - [2021-04-25 14:25:00,986] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:25:01,004] {logging_mixin.py:104} INFO - [2021-04-25 14:25:01,004] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:25:01,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.717 seconds
[2021-04-25 14:25:31,077] {scheduler_job.py:182} INFO - Started process (PID=970) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:25:31,079] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:25:31,081] {logging_mixin.py:104} INFO - [2021-04-25 14:25:31,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:25:31,702] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:25:31,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:25:31,745] {logging_mixin.py:104} INFO - [2021-04-25 14:25:31,744] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:25:31,764] {logging_mixin.py:104} INFO - [2021-04-25 14:25:31,764] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:25:31,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.700 seconds
[2021-04-25 14:26:01,897] {scheduler_job.py:182} INFO - Started process (PID=972) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:26:01,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:26:01,901] {logging_mixin.py:104} INFO - [2021-04-25 14:26:01,901] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:26:02,506] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:26:02,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:26:02,549] {logging_mixin.py:104} INFO - [2021-04-25 14:26:02,548] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:26:02,565] {logging_mixin.py:104} INFO - [2021-04-25 14:26:02,565] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:26:02,574] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.681 seconds
[2021-04-25 14:26:32,959] {scheduler_job.py:182} INFO - Started process (PID=974) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:26:32,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:26:32,962] {logging_mixin.py:104} INFO - [2021-04-25 14:26:32,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:26:33,622] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:26:33,655] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:26:33,668] {logging_mixin.py:104} INFO - [2021-04-25 14:26:33,667] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:26:33,686] {logging_mixin.py:104} INFO - [2021-04-25 14:26:33,686] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:26:33,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.740 seconds
[2021-04-25 14:27:03,862] {scheduler_job.py:182} INFO - Started process (PID=976) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:27:03,866] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:27:03,869] {logging_mixin.py:104} INFO - [2021-04-25 14:27:03,869] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:27:04,521] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:27:04,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:27:04,564] {logging_mixin.py:104} INFO - [2021-04-25 14:27:04,563] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:27:04,582] {logging_mixin.py:104} INFO - [2021-04-25 14:27:04,582] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:27:04,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.734 seconds
[2021-04-25 14:27:34,880] {scheduler_job.py:182} INFO - Started process (PID=978) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:27:34,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:27:34,885] {logging_mixin.py:104} INFO - [2021-04-25 14:27:34,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:27:35,595] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:27:35,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:27:35,655] {logging_mixin.py:104} INFO - [2021-04-25 14:27:35,653] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:27:35,680] {logging_mixin.py:104} INFO - [2021-04-25 14:27:35,680] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:27:35,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.814 seconds
[2021-04-25 14:28:05,781] {scheduler_job.py:182} INFO - Started process (PID=980) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:28:05,784] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:28:05,786] {logging_mixin.py:104} INFO - [2021-04-25 14:28:05,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:28:06,395] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:28:06,424] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:28:06,436] {logging_mixin.py:104} INFO - [2021-04-25 14:28:06,435] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:28:06,460] {logging_mixin.py:104} INFO - [2021-04-25 14:28:06,459] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:28:06,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.703 seconds
[2021-04-25 14:28:36,616] {scheduler_job.py:182} INFO - Started process (PID=982) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:28:36,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:28:36,620] {logging_mixin.py:104} INFO - [2021-04-25 14:28:36,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:28:37,237] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:28:37,273] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:28:37,288] {logging_mixin.py:104} INFO - [2021-04-25 14:28:37,287] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:28:37,309] {logging_mixin.py:104} INFO - [2021-04-25 14:28:37,309] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:28:37,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.709 seconds
[2021-04-25 14:29:07,414] {scheduler_job.py:182} INFO - Started process (PID=984) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:29:07,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:29:07,419] {logging_mixin.py:104} INFO - [2021-04-25 14:29:07,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:29:08,030] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:29:08,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:29:08,082] {logging_mixin.py:104} INFO - [2021-04-25 14:29:08,081] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:29:08,099] {logging_mixin.py:104} INFO - [2021-04-25 14:29:08,099] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:29:08,108] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.698 seconds
[2021-04-25 14:29:38,215] {scheduler_job.py:182} INFO - Started process (PID=986) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:29:38,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:29:38,220] {logging_mixin.py:104} INFO - [2021-04-25 14:29:38,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:29:38,792] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:29:38,823] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:29:38,835] {logging_mixin.py:104} INFO - [2021-04-25 14:29:38,834] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:29:38,854] {logging_mixin.py:104} INFO - [2021-04-25 14:29:38,854] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:29:38,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.652 seconds
[2021-04-25 14:30:08,992] {scheduler_job.py:182} INFO - Started process (PID=988) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:30:08,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:30:08,997] {logging_mixin.py:104} INFO - [2021-04-25 14:30:08,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:30:09,600] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:30:09,629] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:30:09,642] {logging_mixin.py:104} INFO - [2021-04-25 14:30:09,641] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:30:09,659] {logging_mixin.py:104} INFO - [2021-04-25 14:30:09,659] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:30:09,667] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.679 seconds
[2021-04-25 14:30:39,773] {scheduler_job.py:182} INFO - Started process (PID=990) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:30:39,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:30:39,778] {logging_mixin.py:104} INFO - [2021-04-25 14:30:39,778] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:30:40,389] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:30:40,429] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:30:40,443] {logging_mixin.py:104} INFO - [2021-04-25 14:30:40,442] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:30:40,461] {logging_mixin.py:104} INFO - [2021-04-25 14:30:40,461] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:30:40,471] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.702 seconds
[2021-04-25 14:31:10,647] {scheduler_job.py:182} INFO - Started process (PID=992) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:31:10,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:31:10,652] {logging_mixin.py:104} INFO - [2021-04-25 14:31:10,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:31:11,241] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:31:11,278] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:31:11,291] {logging_mixin.py:104} INFO - [2021-04-25 14:31:11,290] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:31:11,312] {logging_mixin.py:104} INFO - [2021-04-25 14:31:11,312] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:31:11,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.679 seconds
[2021-04-25 14:31:41,437] {scheduler_job.py:182} INFO - Started process (PID=994) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:31:41,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:31:41,442] {logging_mixin.py:104} INFO - [2021-04-25 14:31:41,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:31:42,022] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:31:42,053] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:31:42,065] {logging_mixin.py:104} INFO - [2021-04-25 14:31:42,064] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:31:42,086] {logging_mixin.py:104} INFO - [2021-04-25 14:31:42,085] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:31:42,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.661 seconds
[2021-04-25 14:32:12,212] {scheduler_job.py:182} INFO - Started process (PID=996) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:32:12,214] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:32:12,215] {logging_mixin.py:104} INFO - [2021-04-25 14:32:12,215] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:32:12,819] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:32:12,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:32:12,865] {logging_mixin.py:104} INFO - [2021-04-25 14:32:12,864] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:32:12,884] {logging_mixin.py:104} INFO - [2021-04-25 14:32:12,883] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:32:12,893] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.685 seconds
[2021-04-25 14:32:42,994] {scheduler_job.py:182} INFO - Started process (PID=998) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:32:42,997] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:32:42,998] {logging_mixin.py:104} INFO - [2021-04-25 14:32:42,998] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:32:43,585] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:32:43,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:32:43,628] {logging_mixin.py:104} INFO - [2021-04-25 14:32:43,627] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:32:43,645] {logging_mixin.py:104} INFO - [2021-04-25 14:32:43,644] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:32:43,655] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.666 seconds
[2021-04-25 14:33:13,750] {scheduler_job.py:182} INFO - Started process (PID=1000) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:33:13,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:33:13,754] {logging_mixin.py:104} INFO - [2021-04-25 14:33:13,754] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:33:14,432] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:33:14,484] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:33:14,508] {logging_mixin.py:104} INFO - [2021-04-25 14:33:14,507] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:33:14,546] {logging_mixin.py:104} INFO - [2021-04-25 14:33:14,546] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:33:14,558] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.812 seconds
[2021-04-25 14:33:44,656] {scheduler_job.py:182} INFO - Started process (PID=1002) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:33:44,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:33:44,664] {logging_mixin.py:104} INFO - [2021-04-25 14:33:44,664] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:33:45,338] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:33:45,370] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:33:45,381] {logging_mixin.py:104} INFO - [2021-04-25 14:33:45,380] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:33:45,399] {logging_mixin.py:104} INFO - [2021-04-25 14:33:45,399] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:33:45,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.757 seconds
[2021-04-25 14:34:15,521] {scheduler_job.py:182} INFO - Started process (PID=1004) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:34:15,523] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:34:15,524] {logging_mixin.py:104} INFO - [2021-04-25 14:34:15,524] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:34:16,188] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:34:16,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:34:16,236] {logging_mixin.py:104} INFO - [2021-04-25 14:34:16,235] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:34:16,254] {logging_mixin.py:104} INFO - [2021-04-25 14:34:16,254] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:34:16,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.747 seconds
[2021-04-25 14:34:46,366] {scheduler_job.py:182} INFO - Started process (PID=1006) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:34:46,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:34:46,370] {logging_mixin.py:104} INFO - [2021-04-25 14:34:46,369] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:34:47,022] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:34:47,051] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:34:47,063] {logging_mixin.py:104} INFO - [2021-04-25 14:34:47,062] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:34:47,081] {logging_mixin.py:104} INFO - [2021-04-25 14:34:47,081] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:34:47,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.728 seconds
[2021-04-25 14:35:17,220] {scheduler_job.py:182} INFO - Started process (PID=1008) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:35:17,223] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:35:17,225] {logging_mixin.py:104} INFO - [2021-04-25 14:35:17,224] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:35:17,847] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:35:17,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:35:17,888] {logging_mixin.py:104} INFO - [2021-04-25 14:35:17,887] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:35:17,907] {logging_mixin.py:104} INFO - [2021-04-25 14:35:17,907] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:35:17,916] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.702 seconds
[2021-04-25 14:35:48,004] {scheduler_job.py:182} INFO - Started process (PID=1010) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:35:48,007] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:35:48,008] {logging_mixin.py:104} INFO - [2021-04-25 14:35:48,008] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:35:48,687] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:35:48,718] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:35:48,729] {logging_mixin.py:104} INFO - [2021-04-25 14:35:48,728] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:35:48,758] {logging_mixin.py:104} INFO - [2021-04-25 14:35:48,757] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:35:48,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.770 seconds
[2021-04-25 14:36:18,880] {scheduler_job.py:182} INFO - Started process (PID=1012) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:36:18,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:36:18,885] {logging_mixin.py:104} INFO - [2021-04-25 14:36:18,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:36:19,616] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:36:19,652] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:36:19,665] {logging_mixin.py:104} INFO - [2021-04-25 14:36:19,664] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:36:19,683] {logging_mixin.py:104} INFO - [2021-04-25 14:36:19,683] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:36:19,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.818 seconds
[2021-04-25 14:36:49,801] {scheduler_job.py:182} INFO - Started process (PID=1014) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:36:49,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:36:49,807] {logging_mixin.py:104} INFO - [2021-04-25 14:36:49,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:36:50,555] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:36:50,584] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:36:50,596] {logging_mixin.py:104} INFO - [2021-04-25 14:36:50,595] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:36:50,617] {logging_mixin.py:104} INFO - [2021-04-25 14:36:50,617] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:36:50,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.828 seconds
[2021-04-25 14:37:20,752] {scheduler_job.py:182} INFO - Started process (PID=1016) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:37:20,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:37:20,756] {logging_mixin.py:104} INFO - [2021-04-25 14:37:20,756] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:37:21,502] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:37:21,537] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:37:21,555] {logging_mixin.py:104} INFO - [2021-04-25 14:37:21,553] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:37:21,578] {logging_mixin.py:104} INFO - [2021-04-25 14:37:21,577] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:37:21,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.840 seconds
[2021-04-25 14:37:51,671] {scheduler_job.py:182} INFO - Started process (PID=1018) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:37:51,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:37:51,676] {logging_mixin.py:104} INFO - [2021-04-25 14:37:51,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:37:52,387] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:37:52,420] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:37:52,436] {logging_mixin.py:104} INFO - [2021-04-25 14:37:52,435] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:37:52,453] {logging_mixin.py:104} INFO - [2021-04-25 14:37:52,453] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:37:52,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.794 seconds
[2021-04-25 14:38:22,865] {scheduler_job.py:182} INFO - Started process (PID=1020) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:38:22,868] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:38:22,870] {logging_mixin.py:104} INFO - [2021-04-25 14:38:22,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:38:23,512] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:38:23,545] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:38:23,556] {logging_mixin.py:104} INFO - [2021-04-25 14:38:23,555] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:38:23,574] {logging_mixin.py:104} INFO - [2021-04-25 14:38:23,574] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:38:23,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.726 seconds
[2021-04-25 14:38:53,706] {scheduler_job.py:182} INFO - Started process (PID=1022) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:38:53,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:38:53,710] {logging_mixin.py:104} INFO - [2021-04-25 14:38:53,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:38:54,302] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:38:54,336] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:38:54,349] {logging_mixin.py:104} INFO - [2021-04-25 14:38:54,348] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:38:54,372] {logging_mixin.py:104} INFO - [2021-04-25 14:38:54,372] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:38:54,383] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.682 seconds
[2021-04-25 14:39:24,493] {scheduler_job.py:182} INFO - Started process (PID=1024) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:39:24,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:39:24,497] {logging_mixin.py:104} INFO - [2021-04-25 14:39:24,497] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:39:25,117] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:39:25,143] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:39:25,155] {logging_mixin.py:104} INFO - [2021-04-25 14:39:25,154] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:39:25,170] {logging_mixin.py:104} INFO - [2021-04-25 14:39:25,170] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:39:25,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.691 seconds
[2021-04-25 14:39:55,276] {scheduler_job.py:182} INFO - Started process (PID=1026) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:39:55,280] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:39:55,282] {logging_mixin.py:104} INFO - [2021-04-25 14:39:55,281] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:39:55,893] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:39:55,934] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:39:55,946] {logging_mixin.py:104} INFO - [2021-04-25 14:39:55,945] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:39:55,994] {logging_mixin.py:104} INFO - [2021-04-25 14:39:55,994] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:39:56,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.730 seconds
[2021-04-25 14:40:26,104] {scheduler_job.py:182} INFO - Started process (PID=1028) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:40:26,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:40:26,109] {logging_mixin.py:104} INFO - [2021-04-25 14:40:26,109] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:40:26,732] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:40:26,765] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:40:26,777] {logging_mixin.py:104} INFO - [2021-04-25 14:40:26,776] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:40:26,795] {logging_mixin.py:104} INFO - [2021-04-25 14:40:26,795] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:40:26,805] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.704 seconds
[2021-04-25 14:41:01,048] {scheduler_job.py:182} INFO - Started process (PID=1030) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:41:01,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:41:01,079] {logging_mixin.py:104} INFO - [2021-04-25 14:41:01,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:41:04,178] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:41:04,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:41:04,272] {logging_mixin.py:104} INFO - [2021-04-25 14:41:04,270] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:41:04,310] {logging_mixin.py:104} INFO - [2021-04-25 14:41:04,310] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:41:04,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.415 seconds
[2021-04-25 14:41:35,005] {scheduler_job.py:182} INFO - Started process (PID=1032) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:41:35,008] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:41:35,011] {logging_mixin.py:104} INFO - [2021-04-25 14:41:35,011] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:41:35,684] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:41:35,712] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:41:35,724] {logging_mixin.py:104} INFO - [2021-04-25 14:41:35,723] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:41:35,741] {logging_mixin.py:104} INFO - [2021-04-25 14:41:35,741] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:41:35,749] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.749 seconds
[2021-04-25 14:42:05,985] {scheduler_job.py:182} INFO - Started process (PID=1034) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:42:05,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:42:06,002] {logging_mixin.py:104} INFO - [2021-04-25 14:42:05,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:42:07,651] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:42:07,725] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:42:07,747] {logging_mixin.py:104} INFO - [2021-04-25 14:42:07,745] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:42:07,775] {logging_mixin.py:104} INFO - [2021-04-25 14:42:07,775] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:42:07,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.816 seconds
[2021-04-25 14:42:37,945] {scheduler_job.py:182} INFO - Started process (PID=1036) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:42:37,954] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:42:37,958] {logging_mixin.py:104} INFO - [2021-04-25 14:42:37,958] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:42:38,686] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:42:38,718] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:42:38,731] {logging_mixin.py:104} INFO - [2021-04-25 14:42:38,730] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:42:38,750] {logging_mixin.py:104} INFO - [2021-04-25 14:42:38,750] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:42:38,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.823 seconds
[2021-04-25 14:43:08,932] {scheduler_job.py:182} INFO - Started process (PID=1038) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:43:08,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:43:08,946] {logging_mixin.py:104} INFO - [2021-04-25 14:43:08,946] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:43:10,632] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:43:10,784] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:43:10,859] {logging_mixin.py:104} INFO - [2021-04-25 14:43:10,853] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:43:10,913] {logging_mixin.py:104} INFO - [2021-04-25 14:43:10,913] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:43:10,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.038 seconds
[2021-04-25 14:43:41,939] {scheduler_job.py:182} INFO - Started process (PID=1040) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:43:41,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:43:41,946] {logging_mixin.py:104} INFO - [2021-04-25 14:43:41,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:43:42,727] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:43:42,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:43:42,788] {logging_mixin.py:104} INFO - [2021-04-25 14:43:42,785] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:43:42,807] {logging_mixin.py:104} INFO - [2021-04-25 14:43:42,807] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:43:42,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.887 seconds
[2021-04-25 14:44:12,975] {scheduler_job.py:182} INFO - Started process (PID=1042) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:44:12,978] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:44:12,980] {logging_mixin.py:104} INFO - [2021-04-25 14:44:12,980] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:44:13,636] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:44:13,688] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:44:13,705] {logging_mixin.py:104} INFO - [2021-04-25 14:44:13,704] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:44:13,732] {logging_mixin.py:104} INFO - [2021-04-25 14:44:13,732] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:44:13,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.777 seconds
[2021-04-25 14:44:44,001] {scheduler_job.py:182} INFO - Started process (PID=1044) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:44:44,005] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:44:44,008] {logging_mixin.py:104} INFO - [2021-04-25 14:44:44,008] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:44:44,729] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:44:44,760] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:44:44,774] {logging_mixin.py:104} INFO - [2021-04-25 14:44:44,771] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:44:44,800] {logging_mixin.py:104} INFO - [2021-04-25 14:44:44,799] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:44:44,812] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.821 seconds
[2021-04-25 14:45:15,735] {scheduler_job.py:182} INFO - Started process (PID=1046) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:45:15,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:45:15,897] {logging_mixin.py:104} INFO - [2021-04-25 14:45:15,892] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:45:18,162] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:45:18,303] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:45:18,345] {logging_mixin.py:104} INFO - [2021-04-25 14:45:18,340] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:45:18,402] {logging_mixin.py:104} INFO - [2021-04-25 14:45:18,402] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:45:18,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.909 seconds
[2021-04-25 14:45:48,566] {scheduler_job.py:182} INFO - Started process (PID=1048) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:45:48,572] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:45:48,574] {logging_mixin.py:104} INFO - [2021-04-25 14:45:48,574] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:45:49,675] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:45:49,736] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:45:49,756] {logging_mixin.py:104} INFO - [2021-04-25 14:45:49,755] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:45:49,780] {logging_mixin.py:104} INFO - [2021-04-25 14:45:49,780] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:45:49,805] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.245 seconds
[2021-04-25 14:46:19,890] {scheduler_job.py:182} INFO - Started process (PID=1050) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:46:19,892] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:46:19,894] {logging_mixin.py:104} INFO - [2021-04-25 14:46:19,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:46:20,703] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:46:20,753] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:46:20,782] {logging_mixin.py:104} INFO - [2021-04-25 14:46:20,781] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:46:20,807] {logging_mixin.py:104} INFO - [2021-04-25 14:46:20,806] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:46:20,823] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.938 seconds
[2021-04-25 14:46:51,081] {scheduler_job.py:182} INFO - Started process (PID=1052) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:46:51,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:46:51,088] {logging_mixin.py:104} INFO - [2021-04-25 14:46:51,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:46:51,781] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:46:51,809] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:46:51,835] {logging_mixin.py:104} INFO - [2021-04-25 14:46:51,834] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:46:51,856] {logging_mixin.py:104} INFO - [2021-04-25 14:46:51,855] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:46:51,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.791 seconds
[2021-04-25 14:47:22,578] {scheduler_job.py:182} INFO - Started process (PID=1054) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:47:22,607] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:47:22,614] {logging_mixin.py:104} INFO - [2021-04-25 14:47:22,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:47:25,238] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:47:25,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:47:25,411] {logging_mixin.py:104} INFO - [2021-04-25 14:47:25,409] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:47:25,455] {logging_mixin.py:104} INFO - [2021-04-25 14:47:25,454] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:47:25,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.911 seconds
[2021-04-25 14:47:56,484] {scheduler_job.py:182} INFO - Started process (PID=1056) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:47:56,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:47:56,525] {logging_mixin.py:104} INFO - [2021-04-25 14:47:56,525] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:47:59,817] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:47:59,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:48:00,033] {logging_mixin.py:104} INFO - [2021-04-25 14:48:00,030] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:48:00,121] {logging_mixin.py:104} INFO - [2021-04-25 14:48:00,121] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:48:00,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 3.753 seconds
[2021-04-25 14:48:30,511] {scheduler_job.py:182} INFO - Started process (PID=1058) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:48:30,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:48:30,520] {logging_mixin.py:104} INFO - [2021-04-25 14:48:30,520] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:48:31,608] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:48:31,651] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:48:31,666] {logging_mixin.py:104} INFO - [2021-04-25 14:48:31,665] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:48:31,698] {logging_mixin.py:104} INFO - [2021-04-25 14:48:31,698] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:48:31,717] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.211 seconds
[2021-04-25 14:49:02,139] {scheduler_job.py:182} INFO - Started process (PID=1060) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:49:02,164] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:49:02,187] {logging_mixin.py:104} INFO - [2021-04-25 14:49:02,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:49:06,098] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:49:06,213] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:49:06,253] {logging_mixin.py:104} INFO - [2021-04-25 14:49:06,248] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:49:06,284] {logging_mixin.py:104} INFO - [2021-04-25 14:49:06,284] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:49:06,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 4.274 seconds
[2021-04-25 14:49:36,422] {scheduler_job.py:182} INFO - Started process (PID=1062) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:49:36,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:49:36,428] {logging_mixin.py:104} INFO - [2021-04-25 14:49:36,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:49:37,225] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:49:37,265] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:49:37,279] {logging_mixin.py:104} INFO - [2021-04-25 14:49:37,278] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:49:37,301] {logging_mixin.py:104} INFO - [2021-04-25 14:49:37,301] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:49:37,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.894 seconds
[2021-04-25 14:50:07,459] {scheduler_job.py:182} INFO - Started process (PID=1064) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:50:07,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:50:07,464] {logging_mixin.py:104} INFO - [2021-04-25 14:50:07,464] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:50:08,163] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:50:08,197] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:50:08,216] {logging_mixin.py:104} INFO - [2021-04-25 14:50:08,214] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:50:08,252] {logging_mixin.py:104} INFO - [2021-04-25 14:50:08,252] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:50:08,265] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.811 seconds
[2021-04-25 14:50:38,368] {scheduler_job.py:182} INFO - Started process (PID=1066) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:50:38,371] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:50:38,373] {logging_mixin.py:104} INFO - [2021-04-25 14:50:38,373] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:50:39,290] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:50:39,317] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:50:39,329] {logging_mixin.py:104} INFO - [2021-04-25 14:50:39,328] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:50:39,346] {logging_mixin.py:104} INFO - [2021-04-25 14:50:39,346] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:50:39,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.993 seconds
[2021-04-25 14:51:09,528] {scheduler_job.py:182} INFO - Started process (PID=1068) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:51:09,531] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:51:09,534] {logging_mixin.py:104} INFO - [2021-04-25 14:51:09,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:51:10,570] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:51:10,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:51:10,621] {logging_mixin.py:104} INFO - [2021-04-25 14:51:10,620] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:51:10,644] {logging_mixin.py:104} INFO - [2021-04-25 14:51:10,644] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:51:10,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.132 seconds
[2021-04-25 14:51:40,751] {scheduler_job.py:182} INFO - Started process (PID=1070) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:51:40,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:51:40,755] {logging_mixin.py:104} INFO - [2021-04-25 14:51:40,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:51:41,498] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:51:41,542] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:51:41,569] {logging_mixin.py:104} INFO - [2021-04-25 14:51:41,567] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:51:41,599] {logging_mixin.py:104} INFO - [2021-04-25 14:51:41,599] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:51:41,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.865 seconds
[2021-04-25 14:52:11,909] {scheduler_job.py:182} INFO - Started process (PID=1072) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:52:11,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:52:11,913] {logging_mixin.py:104} INFO - [2021-04-25 14:52:11,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:52:12,748] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:52:12,785] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:52:12,804] {logging_mixin.py:104} INFO - [2021-04-25 14:52:12,803] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:52:12,825] {logging_mixin.py:104} INFO - [2021-04-25 14:52:12,825] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:52:12,834] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.931 seconds
[2021-04-25 14:52:42,965] {scheduler_job.py:182} INFO - Started process (PID=1074) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:52:42,970] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:52:42,972] {logging_mixin.py:104} INFO - [2021-04-25 14:52:42,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:52:43,698] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:52:43,731] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:52:43,748] {logging_mixin.py:104} INFO - [2021-04-25 14:52:43,747] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:52:43,775] {logging_mixin.py:104} INFO - [2021-04-25 14:52:43,774] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:52:43,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.831 seconds
[2021-04-25 14:53:13,860] {scheduler_job.py:182} INFO - Started process (PID=1076) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:53:13,865] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:53:13,868] {logging_mixin.py:104} INFO - [2021-04-25 14:53:13,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:53:15,399] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:53:15,443] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:53:15,461] {logging_mixin.py:104} INFO - [2021-04-25 14:53:15,460] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:53:15,482] {logging_mixin.py:104} INFO - [2021-04-25 14:53:15,482] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:53:15,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.641 seconds
[2021-04-25 14:53:46,176] {scheduler_job.py:182} INFO - Started process (PID=1078) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:53:46,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:53:46,181] {logging_mixin.py:104} INFO - [2021-04-25 14:53:46,181] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:53:47,431] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:53:47,502] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:53:47,556] {logging_mixin.py:104} INFO - [2021-04-25 14:53:47,553] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:53:47,586] {logging_mixin.py:104} INFO - [2021-04-25 14:53:47,586] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:53:47,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 1.485 seconds
[2021-04-25 14:54:17,840] {scheduler_job.py:182} INFO - Started process (PID=1080) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:54:17,853] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:54:17,861] {logging_mixin.py:104} INFO - [2021-04-25 14:54:17,861] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:54:19,836] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:54:19,889] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:54:19,941] {logging_mixin.py:104} INFO - [2021-04-25 14:54:19,940] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:54:20,045] {logging_mixin.py:104} INFO - [2021-04-25 14:54:20,045] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:54:20,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 2.259 seconds
[2021-04-25 14:54:50,351] {scheduler_job.py:182} INFO - Started process (PID=1082) to work on /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:54:50,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/recent_played_ingestion.py for tasks to queue
[2021-04-25 14:54:50,356] {logging_mixin.py:104} INFO - [2021-04-25 14:54:50,356] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:54:50,985] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/operators/dataproc.py:1498 DeprecationWarning: The `DataprocSubmitPySparkJobOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `DataprocSubmitPySparkJobOperator` to generate dictionary representing your job and use it with the new operator.
[2021-04-25 14:54:51,012] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['recent_played_ingestion']) retrieved from /opt/airflow/dags/recent_played_ingestion.py
[2021-04-25 14:54:51,024] {logging_mixin.py:104} INFO - [2021-04-25 14:54:51,023] {dag.py:1818} INFO - Sync 1 DAGs
[2021-04-25 14:54:51,044] {logging_mixin.py:104} INFO - [2021-04-25 14:54:51,044] {dag.py:2273} INFO - Setting next_dagrun for recent_played_ingestion to 2021-04-25T14:00:00+00:00
[2021-04-25 14:54:51,053] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/recent_played_ingestion.py took 0.706 seconds
